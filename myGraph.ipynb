{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f633dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "\n",
    "# pass your API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or getpass(\n",
    "    \"Enter Google API Key: \"\n",
    ")\n",
    "# initialize our client\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a42bbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemini refers to a few different things, but most commonly it refers to **Google's large language model.** Here's a breakdown:\n",
       "\n",
       "**1. Gemini (The Google AI Model):**\n",
       "\n",
       "*   **What it is:** Gemini is a multimodal AI model developed by Google AI. It's designed to be Google's most capable and general AI model, surpassing previous models like LaMDA and PaLM.\n",
       "*   **Capabilities:** It can understand and generate text, images, audio, video, and code. This \"multimodal\" nature means it can process and understand information from various sources simultaneously. It's designed to be highly adaptable and perform well on a wide range of tasks.\n",
       "*   **Versions:** There are different versions of Gemini optimized for various use cases:\n",
       "    *   **Gemini Ultra:** The most powerful version, designed for highly complex tasks.\n",
       "    *   **Gemini Pro:** A more balanced version, suitable for a wide range of applications, including powering Google's Bard (now Gemini) chatbot.\n",
       "    *   **Gemini Nano:** A lightweight version designed to run on devices like smartphones and other edge devices.\n",
       "*   **Use Cases:** Gemini is being integrated into various Google products and services, including:\n",
       "    *   **Search:** Improving search results and providing more comprehensive answers.\n",
       "    *   **Gmail & Workspace:** Helping with email composition, summarizing documents, and generating ideas.\n",
       "    *   **Bard/Gemini Chatbot:** Providing more natural and helpful conversational AI.\n",
       "    *   **Coding:** Assisting developers with code generation, debugging, and understanding code.\n",
       "    *   **Creative Content:** Helping with writing, image generation, and other creative tasks.\n",
       "\n",
       "**2. Gemini (The Zodiac Sign):**\n",
       "\n",
       "*   In astrology, Gemini is the third sign of the zodiac, associated with people born between approximately May 21 and June 20. It's an air sign often associated with communication, curiosity, and adaptability.\n",
       "\n",
       "**3. Project Gemini (NASA):**\n",
       "\n",
       "*   In the 1960s, Project Gemini was a NASA human spaceflight program that served as a bridge between Project Mercury (the first US human spaceflight program) and Project Apollo (the program that landed humans on the Moon). Gemini developed techniques for rendezvous, docking, and spacewalking that were crucial for the success of Apollo.\n",
       "\n",
       "**In summary, when someone mentions \"Gemini\" today, they are most likely referring to the Google AI model.**  To avoid confusion, it's helpful to consider the context in which the word is used.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, contents='What is Gemini?'\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cc352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai.types import Tool, GoogleSearch\n",
    "\n",
    "search_tool = Tool(google_search=GoogleSearch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef846338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentConfig(http_options=None, system_instruction='You are a helpful assistant that provides up to date information to help the user in their research.', temperature=0.0, top_p=None, top_k=None, candidate_count=1, max_output_tokens=None, stop_sequences=None, response_logprobs=None, logprobs=None, presence_penalty=None, frequency_penalty=None, seed=None, response_mime_type=None, response_schema=None, routing_config=None, model_selection_config=None, safety_settings=None, tools=[Tool(retrieval=None, google_search=GoogleSearch(), google_search_retrieval=None, enterprise_web_search=None, google_maps=None, code_execution=None, function_declarations=None)], tool_config=None, labels=None, cached_content=None, response_modalities=['TEXT'], media_resolution=None, speech_config=None, audio_timestamp=None, automatic_function_calling=None, thinking_config=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.genai.types import GenerateContentConfig\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "config = GenerateContentConfig(\n",
    "    system_instruction=(\n",
    "        \"You are a helpful assistant that provides up to date information \"\n",
    "        \"to help the user in their research.\"\n",
    "    ),\n",
    "    tools=[search_tool],\n",
    "    response_modalities=[\"TEXT\"],\n",
    "    temperature=0.0,  # likely default\n",
    "    candidate_count=1,  # likely default\n",
    "\n",
    ")\n",
    "config\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=\"Tell me the latest news in AI\",\n",
    "    config=config\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9009a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import Field\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List, Annotated, Literal, Dict, Union, Optional \n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "import json\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    label: str = Field(\n",
    "        ...,\n",
    "        description=\"The name of the website.\",\n",
    "    )\n",
    "    source_id: str = Field(\n",
    "        ...,\n",
    "        description=\"The url of a SPECIFIC source which justifies the answer.\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        ...,\n",
    "        description=\"The VERBATIM quote from the specified source that justifies the answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and return all the sources used.\"\"\"\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources. Include any relevant sources in the answer as markdown hyperlinks. For example: 'This is a sample text ([url website](url))'\"\n",
    "    )\n",
    "    citations: List[Citation] = Field(\n",
    "        ..., description=\"Citations from the given sources that justify the answer.\"\n",
    "    )\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize Tavily Search Tool\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "structured_llm = llm.bind_tools([tavily_search_tool])\n",
    "# agent = create_react_agent(llm, [tavily_search_tool])\n",
    "\n",
    "# user_input = \"What nation hosted the Euro 2024?\"\n",
    "user_input = \"current price of 5090\"\n",
    "# formatted_prompt = web_searcher_instructions.format(\n",
    "#     current_date=get_current_date(),\n",
    "#     research_topic='price of 5090',\n",
    "# )\n",
    "\n",
    "web_searcher_instructions = \"\"\"Use your search tool to conduct targeted Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
    "\n",
    "Instructions:\n",
    "- Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
    "- Conduct multiple, diverse searches to gather comprehensive information.\n",
    "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
    "- The output should be a well-written summary or report based on your search findings. \n",
    "- Only include the information found in the search results, don't make up any information.\n",
    "\n",
    "Research Topic:\n",
    "{research_topic}\n",
    "\"\"\"\n",
    "\n",
    "formatted_prompt = web_searcher_instructions.format(\n",
    "    current_date=get_current_date(),\n",
    "    research_topic=user_input,\n",
    ") + \"\\n\\nIMPORTANT: Use the search tool provided to find the most up-to-date information, and choose the right arguments for the search tool.\"\n",
    "\n",
    "\n",
    "\n",
    "def run_tool(response_msg):\n",
    "    if \"tool_calls\" in response_msg.additional_kwargs:\n",
    "        for tool_call in response_msg.additional_kwargs[\"tool_calls\"]:\n",
    "            tool_name = tool_call[\"function\"][\"name\"]\n",
    "            arguments = tool_call[\"function\"][\"arguments\"]\n",
    "            parsed_args = json.loads(arguments)\n",
    "            if tool_name == \"tavily_search\":\n",
    "                return {\"tool_result\": tavily_search_tool.invoke(parsed_args)}\n",
    "    return {\"tool_result\": \"No tool call made.\"}\n",
    "\n",
    "# === Final LLM with structured output ===\n",
    "final_llm = llm.with_structured_output(QuotedAnswer)\n",
    "# Step 3: Combine it with the LLM output step\n",
    "chain = (\n",
    "    tool_calling_llm |\n",
    "    RunnableLambda(run_tool) |\n",
    "    (lambda inputs: final_llm.invoke(f\"Based on this search result: {inputs['tool_result']}, answer the user question.\"))\n",
    ")\n",
    "\n",
    "result = chain.invoke(formatted_prompt)\n",
    "web_research_result = result.answer + \"\\n---\\n\\n\".join([citation.source_id for citation in result.citations])\n",
    "citations_list = []\n",
    "for citation in result.citations:\n",
    "    citations_dict = {}\n",
    "    citations_dict['label'] = citation.label\n",
    "    citations_dict['short_url'] = citation.source_id\n",
    "    citations_dict['value'] = citation.quote\n",
    "    citations_list.append(citations_dict)\n",
    "\n",
    "# print(result)\n",
    "# https://github.com/tavily-ai/use-cases/blob/main/company-research/company_research.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c879192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Wccftech',\n",
       "  'short_url': 'https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/',\n",
       "  'value': 'In EU regions, we can see most RTX 5090 editions dropping into the €2,400-€2,500 range in June, which was over €2,600 in May. It is still far from the MSRP of $1999, but hopefully, we can see sub-$2500 prices in the coming weeks.'},\n",
       " {'label': 'Wccftech',\n",
       "  'short_url': 'https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/',\n",
       "  'value': 'Both the GPUs are currently listed for 398,000 Yen or US$2775, which is a roughly $275 price reduction.'},\n",
       " {'label': 'Medium',\n",
       "  'short_url': 'https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134',\n",
       "  'value': 'Mwave has Palit GeForce RTX 5090 GameRock for $5299 and ASUS TUF Gaming GeForce RTX 5090 for $5599.'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "citations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f862b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba5de9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The current price of the NVIDIA GeForce RTX 5090, as of June 16, 2025, is not yet officially announced by NVIDIA. However, industry rumors and leaks suggest a potential price range of $1,800 to $2,000 based on speculation from tech analysts. For the most accurate and up-to-date information, it is recommended to check NVIDIA's official website or trusted tech news outlets.\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a25d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "faf0e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'search_query': ['Euro 2024 winner'],\n",
    "#  'web_research_result': [\"Based on the search results, here's a summary of the Euro 2024 winner:\\n\\n**Spain won Euro 2024**, defeating England 2-1 in the final held in Berlin on July 14, 2024. [olympics](https://vertexaisearch.cloud.google.com/id/0-0) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [uefa](https://vertexaisearch.cloud.google.com/id/0-2) [uefa](https://vertexaisearch.cloud.google.com/id/0-3) This victory marks Spain's record-breaking fourth European Championship title. [uefa](https://vertexaisearch.cloud.google.com/id/0-3) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [youtube](https://vertexaisearch.cloud.google.com/id/0-5) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-6) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) Spain won all seven of their matches during the tournament. [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) England has now lost back-to-back Euro finals. [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) The final score was 2-1. [olympics](https://vertexaisearch.cloud.google.com/id/0-0) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [uefa](https://vertexaisearch.cloud.google.com/id/0-2) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-6) [soccerway](https://vertexaisearch.cloud.google.com/id/0-8) [uefa](https://vertexaisearch.cloud.google.com/id/0-3) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) Nico Williams and Mikel Oyarzabal scored for Spain in the final. [youtube](https://vertexaisearch.cloud.google.com/id/0-1)\\n\"],\n",
    "#  'sources_gathered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6f5369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Conduct targeted Google Searches to gather the most recent, credible information on \"price of 5090\" and synthesize it into a verifiable text artifact.\n",
      "\n",
      "Instructions:\n",
      "- Query should ensure that the most current information is gathered. The current date is June 20, 2025.\n",
      "- Conduct multiple, diverse searches to gather comprehensive information.\n",
      "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
      "- The output should be a well-written summary or report based on your search findings. \n",
      "- Only include the information found in the search results, don't make up any information.\n",
      "\n",
      "Research Topic:\n",
      "price of 5090\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_8040b8c7-8bb9-40ed-ad76-bb933e9bc2c5)\n",
      " Call ID: call_0_8040b8c7-8bb9-40ed-ad76-bb933e9bc2c5\n",
      "  Args:\n",
      "    query: price of NVIDIA RTX 5090 June 2025\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "  tavily_search (call_1_c8b82d98-a86c-4ec1-8ecb-376f54776755)\n",
      " Call ID: call_1_c8b82d98-a86c-4ec1-8ecb-376f54776755\n",
      "  Args:\n",
      "    query: NVIDIA RTX 5090 release date and price\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "  tavily_search (call_2_650d7b1c-d36d-43c3-a6a9-40be06b75188)\n",
      " Call ID: call_2_650d7b1c-d36d-43c3-a6a9-40be06b75188\n",
      "  Args:\n",
      "    query: RTX 5090 cost and availability June 2025\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"RTX 5090 cost and availability June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134\", \"title\": \"Nvidia RTX 5080 and RTX 5090 Prices in Australia — June 2025\", \"content\": \"<https://www.msy.com.au/search.php?keywords=rtx+5090&cat_id=1386&mystock=1-6>\\n\\n![]()\\n\\n**Mwave** has Palit GeForce RTX 5090 GameRock for **$5299** and ASUS TUF Gaming GeForce RTX 5090 for **$5599**, Right!\\n\\n<https://www.mwave.com.au/graphics-cards/geforce-rtx-5090?sortid=1&display=box&filteroptions=0%3Din-stock-at-mwave&filter=0%3Davailability>\\n\\n![]()\\n\\n**Pccasegear** has ZOTAC Gaming GeForce RTX 5090 Solid OC for **$5299** and ASUS GeForce RTX 5090 TUF Gaming for **$5549**, incredible! [...] **Centrecom** has Palit GameRock GeForce RTX 5090 for **$5299** and Asus TUF Gaming GeForce RTX 5090 for **$5399**, awesome!\\n\\n[https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101,2096](https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101%2C2096)\\n\\n![]()\\n\\n**Msy** has PNY GeForce RTX 5090 ARGB Epic-X Triple Fan OC for **$5299** and Asus TUF GeForce RTX 5090 for **$5459**, ARGB should be loking exciting! [...] # Winter time in Australia (TL;DR)\\n\\nI’m getting all this price information in Melbourne on cold dark evening in the middle of June.\\n\\nThe URLs are all here, check by yourselves, maybe something has changed.\\n\\nI observe that RTX 5080 is priced in Australian shops similar or slightly higher than Nvidia recommends — @**~$2000**.\\n\\nAnd RTX 5090 is priced in Australian shops ***coincidently*** at the same minimal price at **$5299** which is **31.2%** higher then Nvidia’s MRSP.\", \"score\": 0.91175514, \"raw_content\": null}, {\"url\": \"https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/\", \"title\": \"GeForce RTX 5090 Drops Below $2800 For The First Time In Japan\", \"content\": \"GeForce RTX 5090 Drops Below $2800 For The First Time In Japan; Sees Noticeable Price Cuts In Other Regions As Well. Sarfraz Khan • Jun 14, 2025 at 03:27pm EDT\", \"score\": 0.84918517, \"raw_content\": null}, {\"url\": \"https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy\", \"title\": \"NVIDIA RTX 50 Series GPUs at MSRP in the Most Unexpected Place\", \"content\": \"Those boxes contained multiple RTX 5070 and RTX 5080 cards, along with a single RTX 5090, all priced at their suggested MSRPs of $550, $999, and $1,999,\", \"score\": 0.7060491, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=szb-XiIfhFY\", \"title\": \"At Last: MSRP!! GPU Price Watch 2025 - June - YouTube\", \"content\": \"► TIMESTAMPS\\n0:00 Welcome to Paul’s Hardware - GPU Price Watch, June 2025\\n0:59 The “Short Version” - Full June Chart and Best Deals \\n6:50 Quick Note on Methodology\\n8:47 Current Prices: NVIDIA RTX 40 Series GPUs\\n9:34 Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090\\n11:06 Current Prices: AMD Radeon RX 9060 XT, RX 9070, RX 9070 XT, RX 7900 XT/XTX\\n11:58 Current Prices: Intel Arc B580 and B570\\n12:22 Conclusion and Overall Recommendations [...] like a 4060 Ti 8 gig even for its lowest price of   $440 is not a good buy when a 5060 Ti 8 gig is \\navailable for $380 so pretty much any 40 series   GPU among these listings is going to have a better \\noption that you can buy that's newer and has more   features with the 50 series or an AMD Radeon \\noption for that matter so that brings us down   Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090 to the 50 series and um I feel like in my quick [...] The “best” GPU deals right now – \\nOnix Odyssey Arc B580 12GB ($300, Newegg) - https://tinyurl.com/ymwf8w8t\\nRX 9060 XT 16GB ($370, Newegg) - https://tinyurl.com/y2n6zv2b \\nRX 9070 16GB ($620, Newegg) - https://tinyurl.com/yyhuxkzw \\n$300 RTX 5060 8GB - https://geni.us/NzgZ \\n$430 5060 Ti 16GB - https://www.bestbuy.com/site/gigabyte-nvidia-geforce-rtx-5060-ti-windforce-16g-gddr7-pci-express-5-0-graphics-card-black/6629370.p\", \"score\": 0.68318754, \"raw_content\": null}, {\"url\": \"https://itc.ua/en/news/this-nvidia-rtx-5090-costs-24-000-what-s-so-special-about-it/\", \"title\": \"This NVIDIA RTX 5090 costs $24,000 — what's so special about it\", \"content\": \"This NVIDIA RTX 5090 costs $24,000 — what's so special about it ... Asus RTX 5090 ROG Astral Dhahab Edition is one of the most expensive NVIDIA graphics cards,\", \"score\": 0.6342494, \"raw_content\": null}], \"response_time\": 2.66}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is a synthesized report on the current price and availability of the NVIDIA RTX 5090 as of June 2025, based on credible sources:\n",
      "\n",
      "---\n",
      "\n",
      "### **NVIDIA RTX 5090 Price and Availability Report (June 2025)**\n",
      "\n",
      "#### **Key Findings:**\n",
      "1. **Global Pricing Trends:**\n",
      "   - **Japan:** The RTX 5090 has dropped below **$2,800** for the first time, with prices around **398,000 Yen (approximately $2,775)**. This represents a significant reduction from earlier prices.  \n",
      "     - *Source:* [Wccftech](https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/)\n",
      "   - **Australia:** Prices remain high, with the RTX 5090 listed at **AUD $5,299** (approximately **$3,500 USD**), which is **31.2% above NVIDIA's MSRP**.  \n",
      "     - *Source:* [Medium](https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134)\n",
      "   - **United States:** The Founders Edition MSRP is **$1,999**, but retail prices are often inflated. For example, the Alienware Area-51 prebuilt PC with an RTX 5090 is priced at **$4,849.99**.  \n",
      "     - *Source:* [IGN](https://www.ign.com/articles/alienware-area-51-nvidia-rtx-5090-prebuilt-gaming-pc-deal-price-drop-to-under-5k-price-drop)\n",
      "\n",
      "2. **MSRP Availability:**\n",
      "   - The **US Navy Exchange (NEX)** store has been reported to sell the RTX 5090 at MSRP (**$1,999**), with discounts bringing the price down to **$1,900** for eligible buyers.  \n",
      "     - *Source:* [TechPowerUp](https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy)\n",
      "\n",
      "3. **Regional Availability:**\n",
      "   - **Japan and EU:** Prices are gradually decreasing, with some models available for **€2,400-€2,500** in Europe.  \n",
      "   - **Australia:** Retailers like Mwave, Pccasegear, and Centrecom list the RTX 5090 between **AUD $5,299 and $5,599**.  \n",
      "   - **US:** Availability is limited, with prices often exceeding **$3,000** on platforms like eBay.\n",
      "\n",
      "4. **Special Editions:**\n",
      "   - High-end custom models, such as the **Asus RTX 5090 ROG Astral Dhahab Edition**, are priced exorbitantly at **$24,000**.  \n",
      "     - *Source:* [ITC.ua](https://itc.ua/en/news/this-nvidia-rtx-5090-costs-24-000-what-s-so-special-about-it/)\n",
      "\n",
      "#### **Conclusion:**\n",
      "The NVIDIA RTX 5090 remains a premium product with significant price variations across regions. While the MSRP is **$1,999**, actual retail prices are often higher due to demand and regional markups. Shoppers in Japan and the US Navy Exchange have reported the best deals, while Australian buyers face steep premiums. \n",
      "\n",
      "For the most up-to-date pricing, checking local retailers and authorized sellers is recommended. \n",
      "\n",
      "--- \n",
      "\n",
      "This report is based on verified sources as of June 20, 2025. Let me know if you'd like further details or additional regions covered!\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "from backend.src.agent.prompts import (\n",
    "    get_current_date,\n",
    "    query_writer_instructions,\n",
    "    web_searcher_instructions,\n",
    "    reflection_instructions,\n",
    "    answer_instructions,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "# Create a ReAct agent with the web searcher system prompt and Tavily search tool\n",
    "formatted_prompt = web_searcher_instructions.format(\n",
    "    current_date=get_current_date(),\n",
    "    research_topic='price of 5090',\n",
    ")\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "# Create the agent with the formatted prompt as system message\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    [tavily_search_tool],\n",
    "    \n",
    ")\n",
    "prompt=formatted_prompt\n",
    "# Create a runnable chain from the agent\n",
    "# search_chain = agent.get_chain()\n",
    "\n",
    "# agent.invoke({\"messages\": [HumanMessage(content=\"What is the price of 5090?\")]}).pretty_print()\n",
    "\n",
    "# user_input = \"What is the price of 5090?\"\n",
    "# response = agent.invoke({\"messages\": prompt})\n",
    "for step in agent.stream(\n",
    "    {\"messages\": prompt},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d481ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"current price of RTX 5090 graphics card in Singapore dollars\"\n",
    "out = agent_exec.invoke(\n",
    "        {\n",
    "            \"research_topic\": query,\n",
    "            \"current_date\": \"20 June 2025\",\n",
    "            \"input\": query            # required by ReAct template\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # out[\"output\"] is the raw JSON string from the LLM\n",
    "    # parse it into the Pydantic model for convenience\n",
    "qa = QuotedAnswer.model_validate_json(out[\"output\"])\n",
    "print(\"\\n==== Final structured answer ====\")\n",
    "print(qa.model_dump_json(indent=2))\n",
    "print(\"\\n==== Intermediate steps ====\")\n",
    "print(out[\"intermediate_steps\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b97f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Conduct targeted Google Searches to gather the most recent, credible information on \"price of 5090\" and synthesize it into a verifiable text artifact.\\n\\nInstructions:\\n- Query should ensure that the most current information is gathered. The current date is June 20, 2025.\\n- Conduct multiple, diverse searches to gather comprehensive information.\\n- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\\n- The output should be a well-written summary or report based on your search findings. \\n- Only include the information found in the search results, don\\'t make up any information.\\n\\nResearch Topic:\\nprice of 5090\\n', additional_kwargs={}, response_metadata={}, id='c39caa5d-a57b-4679-80ef-3f95c70f821f'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_8040b8c7-8bb9-40ed-ad76-bb933e9bc2c5', 'function': {'arguments': '{\"query\": \"price of NVIDIA RTX 5090 June 2025\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}, {'id': 'call_1_c8b82d98-a86c-4ec1-8ecb-376f54776755', 'function': {'arguments': '{\"query\": \"NVIDIA RTX 5090 release date and price\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 1}, {'id': 'call_2_650d7b1c-d36d-43c3-a6a9-40be06b75188', 'function': {'arguments': '{\"query\": \"RTX 5090 cost and availability June 2025\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 2}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 135, 'prompt_tokens': 1371, 'total_tokens': 1506, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1344}, 'prompt_cache_hit_tokens': 1344, 'prompt_cache_miss_tokens': 27}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--895079a6-7b9f-4786-a336-de34ac5fd987-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'price of NVIDIA RTX 5090 June 2025', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_0_8040b8c7-8bb9-40ed-ad76-bb933e9bc2c5', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'NVIDIA RTX 5090 release date and price', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_1_c8b82d98-a86c-4ec1-8ecb-376f54776755', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'RTX 5090 cost and availability June 2025', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_2_650d7b1c-d36d-43c3-a6a9-40be06b75188', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1371, 'output_tokens': 135, 'total_tokens': 1506, 'input_token_details': {'cache_read': 1344}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='{\"query\": \"price of NVIDIA RTX 5090 June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/\", \"title\": \"GeForce RTX 5090 Drops Below $2800 For The First Time In Japan\", \"content\": \"![Geizhals RTX 5090 price June Graph](https://cdn.wccftech.com/wp-content/uploads/2025/06/Geizhals-RTX-5090-price-June-Graph.png)\\\\n\\\\nIn EU regions, we can see most RTX 5090 editions dropping into the €2,400-€2,500 range in June, which was over €2,600 in May. It is still far from the MSRP of $1999, but hopefully, we can see sub-$2500 prices in the coming weeks. We recommend our readers wait until the price drops even further since the RTX 5090 isn\\'t worth the $2500+ price tag. [...] Both the GPUs are currently listed for 398,000 Yen or US$2775, which is a roughly $275 price reduction. Despite computer parts usually being more expensive in Japan than in NA, the RTX 5090 seems to be selling for a comparatively lower price than in the NA market. The situation is surely improving in the NA and EU regions as well, but most of them are still listed for around $3000.\\\\n\\\\n![RTX 5090 Newegg June](https://cdn.wccftech.com/wp-content/uploads/2025/06/RTX-5090-Newegg-June.png) [...] ## Products mentioned\\\\n\\\\n![GIGABYTE GeForce RTX 5090](https://m.media-amazon.com/images/I/41jXf59ha-L._SL160_.jpg)\\\\n\\\\n### [GIGABYTE GeForce RTX 5090](https://www.amazon.com/dp/B0DVCBDJBJ?tag=wccftechplug-20&linkCode=ogi&th=1&psc=1)\\\\n\\\\n## Deal of the Day\\\\n\\\\n![](https://cdn.wccftech.com/wp-content/uploads/2025/06/Article-banner-1118x628-1.png)\\\\n![](https://cdn.wccftech.com/wp-content/uploads/2025/06/Article-banner-600x500-1.jpg )\\\\n\\\\n### Further Reading\", \"score\": 0.93762916, \"raw_content\": null}, {\"url\": \"https://www.reddit.com/r/gluk/comments/1ldfykm/nvidia_rtx_5080_and_rtx_5090_prices_in_australia/\", \"title\": \"Nvidia RTX 5080 and RTX 5090 Prices in Australia - June 2025\", \"content\": \"And RTX 5090 is priced in Australian shops coincidently at the same minimal price at $5299 which is 31.2% higher then Nvidia\\'s MRSP. Nobody\\'s responded to this\", \"score\": 0.9291904, \"raw_content\": null}, {\"url\": \"https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134\", \"title\": \"Nvidia RTX 5080 and RTX 5090 Prices in Australia — June 2025\", \"content\": \"<https://www.msy.com.au/search.php?keywords=rtx+5090&cat_id=1386&mystock=1-6>\\\\n\\\\n![]()\\\\n\\\\n**Mwave** has Palit GeForce RTX 5090 GameRock for **$5299** and ASUS TUF Gaming GeForce RTX 5090 for **$5599**, Right!\\\\n\\\\n<https://www.mwave.com.au/graphics-cards/geforce-rtx-5090?sortid=1&display=box&filteroptions=0%3Din-stock-at-mwave&filter=0%3Davailability>\\\\n\\\\n![]()\\\\n\\\\n**Pccasegear** has ZOTAC Gaming GeForce RTX 5090 Solid OC for **$5299** and ASUS GeForce RTX 5090 TUF Gaming for **$5549**, incredible! [...] # Winter time in Australia (TL;DR)\\\\n\\\\nI’m getting all this price information in Melbourne on cold dark evening in the middle of June.\\\\n\\\\nThe URLs are all here, check by yourselves, maybe something has changed.\\\\n\\\\nI observe that RTX 5080 is priced in Australian shops similar or slightly higher than Nvidia recommends — @**~$2000**.\\\\n\\\\nAnd RTX 5090 is priced in Australian shops ***coincidently*** at the same minimal price at **$5299** which is **31.2%** higher then Nvidia’s MRSP. [...] **Centrecom** has Palit GameRock GeForce RTX 5090 for **$5299** and Asus TUF Gaming GeForce RTX 5090 for **$5399**, awesome!\\\\n\\\\n[https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101,2096](https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101%2C2096)\\\\n\\\\n![]()\\\\n\\\\n**Msy** has PNY GeForce RTX 5090 ARGB Epic-X Triple Fan OC for **$5299** and Asus TUF GeForce RTX 5090 for **$5459**, ARGB should be loking exciting!\", \"score\": 0.9203972, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=szb-XiIfhFY\", \"title\": \"At Last: MSRP!! GPU Price Watch 2025 - June - YouTube\", \"content\": \"► TIMESTAMPS\\\\n0:00 Welcome to Paul’s Hardware - GPU Price Watch, June 2025\\\\n0:59 The “Short Version” - Full June Chart and Best Deals \\\\n6:50 Quick Note on Methodology\\\\n8:47 Current Prices: NVIDIA RTX 40 Series GPUs\\\\n9:34 Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090\\\\n11:06 Current Prices: AMD Radeon RX 9060 XT, RX 9070, RX 9070 XT, RX 7900 XT/XTX\\\\n11:58 Current Prices: Intel Arc B580 and B570\\\\n12:22 Conclusion and Overall Recommendations [...] like a 4060 Ti 8 gig even for its lowest price of\\xa0\\xa0 $440 is not a good buy when a 5060 Ti 8 gig is\\xa0\\\\navailable for $380 so pretty much any 40 series\\xa0\\xa0 GPU among these listings is going to have a better\\xa0\\\\noption that you can buy that\\'s newer and has more\\xa0\\xa0 features with the 50 series or an AMD Radeon\\xa0\\\\noption for that matter so that brings us down\\xa0\\xa0 Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090 to the 50 series and um I feel like in my quick\", \"score\": 0.7732339, \"raw_content\": null}, {\"url\": \"https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy\", \"title\": \"NVIDIA RTX 50 Series GPUs at MSRP in the Most Unexpected Place\", \"content\": \"Those boxes contained multiple RTX 5070 and RTX 5080 cards, along with a single RTX 5090, all priced at their suggested MSRPs of $550, $999, and $1,999, respectively. A quick online search of the part numbers confirmed that the top‑end card was indeed the Founders Edition model. After applying applicable discounts and card rewards, Accomplished‑Feed123 walked away, paying only $1,900 out of pocket. Access to NEX is restricted to active and retired military members and their families, operating\", \"score\": 0.76596165, \"raw_content\": null}], \"response_time\": 2.87}', name='tavily_search', id='f5a1eee7-48d1-4b8d-af5e-8e08893327eb', tool_call_id='call_0_8040b8c7-8bb9-40ed-ad76-bb933e9bc2c5'),\n",
       "  ToolMessage(content='{\"query\": \"NVIDIA RTX 5090 release date and price\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.newegg.com/msi-rtx-5090-32g-ventus-3x-oc-geforce-rtx-5090-32gb-graphics-card/p/N82E16814137920?srsltid=AfmBOooinJC5lZil6aQr2bDcuvTtoFk_i_X0yAC0f9NIkHjPiQY_gx74\", \"title\": \"MSI Ventus GeForce RTX 5090 32GB GDDR7 PCI ... - Newegg\", \"content\": \"Overall Review: highly recommend , great price per value for 5090. I ... Date First Available, January 06, 2025. View Moreexpand_moreView Lessexpand_less.\", \"score\": 0.7760977, \"raw_content\": null}, {\"url\": \"https://www.amazon.com/MSI-GeForce-RTX-5090-32G/dp/B0DYK4FGLH\", \"title\": \"MSI GeForce RTX 5090 32G Vanguard SOC Graphics Board VD8999\", \"content\": \"Price go crazy. Reviewed in the United States on June 16, 2025. Style: 2) RTX 5090 VANGUARD Regular Model. I actually spent $3k on a gpu, never thought i would\", \"score\": 0.7500592, \"raw_content\": null}, {\"url\": \"https://tech.yahoo.com/computing/articles/theres-never-perfect-time-buy-200016216.html\", \"title\": \"There\\'s Never a \\\\\"Perfect\\\\\" Time to Buy a GPU - Yahoo! Tech\", \"content\": \"Yes, the ultra-high-end is insanely priced, with the RTX 5090 having a $1,999 MSRP. However, mid-range is the new high-end when it comes to pricing. NVIDIA\", \"score\": 0.7213709, \"raw_content\": null}, {\"url\": \"https://www.ign.com/articles/alienware-area-51-nvidia-rtx-5090-prebuilt-gaming-pc-deal-price-drop-to-under-5k-price-drop\", \"title\": \"The Alienware Area-51 RTX 5090 Gaming PC With Upgraded ... - IGN\", \"content\": \"If you\\'re seeking the absolute best of the best in PC gaming performance, look no further. Dell has just dropped the price of its flagship [Alienware Area-51](https://zdcs.link/Q47DqA?object_uuid=48e79046-723f-4f4a-9a03-8773960d3129&t=article) prebuilt gaming PC, equipped with the Nvidia GeForce RTX 5090 graphics card to $4,849.99 with free shipping. This is a competitive price - especially for an Alienware computer - compared to the similar off-the-shelf prebuilts on Amazon. The RTX 5090 is [...] compared to the 4090. This GPU is extremely difficult to find at retail price and [is currently selling for $3,500-$4,000 on eBay](https://www.ebay.com/sch/27386/i.html?_nkw=5090&_from=R40&LH_Sold=1&LH_Complete=1). [...] ## Alienware Area-51 RTX 5090 Gaming PC for $4,849.99\\\\n\\\\n![Alienware Area-51 Intel Core Ultra 9 285K RTX 5090 Gaming PC (64GB/4TB)](https://assets-prd.ignimgs.com/2025/04/02/alienwarearea51pc-1743610123388.jpg?width=220&auto=webp&quality=20&dpr=0.05)\\\\n\\\\n### Alienware Area-51 Intel Core Ultra 9 285K RTX 5090 Gaming PC (64GB/4TB)\", \"score\": 0.68420124, \"raw_content\": null}, {\"url\": \"https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy\", \"title\": \"NVIDIA RTX 50 Series GPUs at MSRP in the Most Unexpected Place\", \"content\": \"Those boxes contained multiple RTX 5070 and RTX 5080 cards, along with a single RTX 5090, all priced at their suggested MSRPs of $550, $999, and $1,999, respectively. A quick online search of the part numbers confirmed that the top‑end card was indeed the Founders Edition model. After applying applicable discounts and card rewards, Accomplished‑Feed123 walked away, paying only $1,900 out of pocket. Access to NEX is restricted to active and retired military members and their families, operating [...] The US Navy Exchange (NEX) store has become a surprising platform for acquiring NVIDIA\\'s RTX 50-series graphics cards at their manufacturer\\'s suggested retail prices. A Reddit user, known as Accomplished-Feed123, shared that by combining various store promotions and credit card rewards, they managed to purchase a GeForce RTX 5090 Founders Edition for just $1,900, which is significantly below the typical retail price. Savvy shoppers have long discovered open‑box electronics and gaming hardware [...] * Jan 3rd 2025 [NVIDIA GeForce RTX 5090 Features 575 W TDP, RTX 5080 Carries 360 W TDP](/330459/nvidia-geforce-rtx-5090-features-575-w-tdp-rtx-5080-carries-360-w-tdp) (217)\\\\n* Dec 28th 2024 [Potential RTX 5090 and RTX 5080 Pricing in China Leaks](/330284/potential-rtx-5090-and-rtx-5080-pricing-in-china-leaks) (173)\", \"score\": 0.6786044, \"raw_content\": null}], \"response_time\": 2.85}', name='tavily_search', id='7b2a0891-ae0f-465c-bf1e-0aea99565fa9', tool_call_id='call_1_c8b82d98-a86c-4ec1-8ecb-376f54776755'),\n",
       "  ToolMessage(content='{\"query\": \"RTX 5090 cost and availability June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134\", \"title\": \"Nvidia RTX 5080 and RTX 5090 Prices in Australia — June 2025\", \"content\": \"<https://www.msy.com.au/search.php?keywords=rtx+5090&cat_id=1386&mystock=1-6>\\\\n\\\\n![]()\\\\n\\\\n**Mwave** has Palit GeForce RTX 5090 GameRock for **$5299** and ASUS TUF Gaming GeForce RTX 5090 for **$5599**, Right!\\\\n\\\\n<https://www.mwave.com.au/graphics-cards/geforce-rtx-5090?sortid=1&display=box&filteroptions=0%3Din-stock-at-mwave&filter=0%3Davailability>\\\\n\\\\n![]()\\\\n\\\\n**Pccasegear** has ZOTAC Gaming GeForce RTX 5090 Solid OC for **$5299** and ASUS GeForce RTX 5090 TUF Gaming for **$5549**, incredible! [...] **Centrecom** has Palit GameRock GeForce RTX 5090 for **$5299** and Asus TUF Gaming GeForce RTX 5090 for **$5399**, awesome!\\\\n\\\\n[https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101,2096](https://www.centrecom.com.au/nvidia-amd-graphics-cards?orderby=10&specs=2101%2C2096)\\\\n\\\\n![]()\\\\n\\\\n**Msy** has PNY GeForce RTX 5090 ARGB Epic-X Triple Fan OC for **$5299** and Asus TUF GeForce RTX 5090 for **$5459**, ARGB should be loking exciting! [...] # Winter time in Australia (TL;DR)\\\\n\\\\nI’m getting all this price information in Melbourne on cold dark evening in the middle of June.\\\\n\\\\nThe URLs are all here, check by yourselves, maybe something has changed.\\\\n\\\\nI observe that RTX 5080 is priced in Australian shops similar or slightly higher than Nvidia recommends — @**~$2000**.\\\\n\\\\nAnd RTX 5090 is priced in Australian shops ***coincidently*** at the same minimal price at **$5299** which is **31.2%** higher then Nvidia’s MRSP.\", \"score\": 0.91175514, \"raw_content\": null}, {\"url\": \"https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/\", \"title\": \"GeForce RTX 5090 Drops Below $2800 For The First Time In Japan\", \"content\": \"GeForce RTX 5090 Drops Below $2800 For The First Time In Japan; Sees Noticeable Price Cuts In Other Regions As Well. Sarfraz Khan • Jun 14, 2025 at 03:27pm EDT\", \"score\": 0.84918517, \"raw_content\": null}, {\"url\": \"https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy\", \"title\": \"NVIDIA RTX 50 Series GPUs at MSRP in the Most Unexpected Place\", \"content\": \"Those boxes contained multiple RTX 5070 and RTX 5080 cards, along with a single RTX 5090, all priced at their suggested MSRPs of $550, $999, and $1,999,\", \"score\": 0.7060491, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=szb-XiIfhFY\", \"title\": \"At Last: MSRP!! GPU Price Watch 2025 - June - YouTube\", \"content\": \"► TIMESTAMPS\\\\n0:00 Welcome to Paul’s Hardware - GPU Price Watch, June 2025\\\\n0:59 The “Short Version” - Full June Chart and Best Deals \\\\n6:50 Quick Note on Methodology\\\\n8:47 Current Prices: NVIDIA RTX 40 Series GPUs\\\\n9:34 Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090\\\\n11:06 Current Prices: AMD Radeon RX 9060 XT, RX 9070, RX 9070 XT, RX 7900 XT/XTX\\\\n11:58 Current Prices: Intel Arc B580 and B570\\\\n12:22 Conclusion and Overall Recommendations [...] like a 4060 Ti 8 gig even for its lowest price of\\xa0\\xa0 $440 is not a good buy when a 5060 Ti 8 gig is\\xa0\\\\navailable for $380 so pretty much any 40 series\\xa0\\xa0 GPU among these listings is going to have a better\\xa0\\\\noption that you can buy that\\'s newer and has more\\xa0\\xa0 features with the 50 series or an AMD Radeon\\xa0\\\\noption for that matter so that brings us down\\xa0\\xa0 Current Prices: NVIDIA RTX 5060, 5060 Ti, 5070, 5070 Ti, 5080, 5090 to the 50 series and um I feel like in my quick [...] The “best” GPU deals right now – \\\\nOnix Odyssey Arc B580 12GB ($300, Newegg) - https://tinyurl.com/ymwf8w8t\\\\nRX 9060 XT 16GB ($370, Newegg) - https://tinyurl.com/y2n6zv2b \\\\nRX 9070 16GB ($620, Newegg) - https://tinyurl.com/yyhuxkzw \\\\n$300 RTX 5060 8GB - https://geni.us/NzgZ \\\\n$430 5060 Ti 16GB - https://www.bestbuy.com/site/gigabyte-nvidia-geforce-rtx-5060-ti-windforce-16g-gddr7-pci-express-5-0-graphics-card-black/6629370.p\", \"score\": 0.68318754, \"raw_content\": null}, {\"url\": \"https://itc.ua/en/news/this-nvidia-rtx-5090-costs-24-000-what-s-so-special-about-it/\", \"title\": \"This NVIDIA RTX 5090 costs $24,000 — what\\'s so special about it\", \"content\": \"This NVIDIA RTX 5090 costs $24,000 — what\\'s so special about it ... Asus RTX 5090 ROG Astral Dhahab Edition is one of the most expensive NVIDIA graphics cards,\", \"score\": 0.6342494, \"raw_content\": null}], \"response_time\": 2.66}', name='tavily_search', id='90d25597-5028-4d25-9802-70444a33024c', tool_call_id='call_2_650d7b1c-d36d-43c3-a6a9-40be06b75188'),\n",
       "  AIMessage(content=\"Here is a synthesized report on the current price and availability of the NVIDIA RTX 5090 as of June 2025, based on credible sources:\\n\\n---\\n\\n### **NVIDIA RTX 5090 Price and Availability Report (June 2025)**\\n\\n#### **Key Findings:**\\n1. **Global Pricing Trends:**\\n   - **Japan:** The RTX 5090 has dropped below **$2,800** for the first time, with prices around **398,000 Yen (approximately $2,775)**. This represents a significant reduction from earlier prices.  \\n     - *Source:* [Wccftech](https://wccftech.com/geforce-rtx-5090-drops-below-2800-for-the-first-time-in-japan/)\\n   - **Australia:** Prices remain high, with the RTX 5090 listed at **AUD $5,299** (approximately **$3,500 USD**), which is **31.2% above NVIDIA's MSRP**.  \\n     - *Source:* [Medium](https://medium.com/@rosgluk/nvidia-rtx-5080-and-rtx-5090-prices-in-australia-june-2025-70fba640c134)\\n   - **United States:** The Founders Edition MSRP is **$1,999**, but retail prices are often inflated. For example, the Alienware Area-51 prebuilt PC with an RTX 5090 is priced at **$4,849.99**.  \\n     - *Source:* [IGN](https://www.ign.com/articles/alienware-area-51-nvidia-rtx-5090-prebuilt-gaming-pc-deal-price-drop-to-under-5k-price-drop)\\n\\n2. **MSRP Availability:**\\n   - The **US Navy Exchange (NEX)** store has been reported to sell the RTX 5090 at MSRP (**$1,999**), with discounts bringing the price down to **$1,900** for eligible buyers.  \\n     - *Source:* [TechPowerUp](https://www.techpowerup.com/338078/nvidia-rtx-50-series-gpus-at-msrp-in-the-most-unexpected-place-us-navy)\\n\\n3. **Regional Availability:**\\n   - **Japan and EU:** Prices are gradually decreasing, with some models available for **€2,400-€2,500** in Europe.  \\n   - **Australia:** Retailers like Mwave, Pccasegear, and Centrecom list the RTX 5090 between **AUD $5,299 and $5,599**.  \\n   - **US:** Availability is limited, with prices often exceeding **$3,000** on platforms like eBay.\\n\\n4. **Special Editions:**\\n   - High-end custom models, such as the **Asus RTX 5090 ROG Astral Dhahab Edition**, are priced exorbitantly at **$24,000**.  \\n     - *Source:* [ITC.ua](https://itc.ua/en/news/this-nvidia-rtx-5090-costs-24-000-what-s-so-special-about-it/)\\n\\n#### **Conclusion:**\\nThe NVIDIA RTX 5090 remains a premium product with significant price variations across regions. While the MSRP is **$1,999**, actual retail prices are often higher due to demand and regional markups. Shoppers in Japan and the US Navy Exchange have reported the best deals, while Australian buyers face steep premiums. \\n\\nFor the most up-to-date pricing, checking local retailers and authorized sellers is recommended. \\n\\n--- \\n\\nThis report is based on verified sources as of June 20, 2025. Let me know if you'd like further details or additional regions covered!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 784, 'prompt_tokens': 6288, 'total_tokens': 7072, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1472}, 'prompt_cache_hit_tokens': 1472, 'prompt_cache_miss_tokens': 4816}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run--dd8c3930-d6eb-4cb6-a7ae-b322e5ba0caa-0', usage_metadata={'input_tokens': 6288, 'output_tokens': 784, 'total_tokens': 7072, 'input_token_details': {'cache_read': 1472}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a53d7a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"query\": \"latest updates on RTX 5090 pricing June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://x.com/USRestocks/status/1932361271782863013\", \"title\": \"US Restocks RTX5090/60/60Ti § Switch2\", \"content\": \"RTX 5090 in Stock! | Cart Link: https://amzn.to/4bPc14X June 10, 2025 at 01:56AM PT #ad MSI Gaming RTX 5090 32G Gaming Trio OC Graphics Card (32GB GDDR7,\", \"score\": 0.79254496, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=l641VkblkfY\", \"title\": \"Best GPUs to Buy for Gaming RIGHT NOW! [June/July 2025]\", \"content\": \"Newegg (US) [PAID LINKS]:\\nB570: https://newegg.io/nc0f72caf3\\nB580: https://newegg.io/ncb8aa2818\\nRTX 5060: https://newegg.io/nc2d2d6cb4\\nRTX 5060 Ti 16GB: https://newegg.io/nce151063f\\nRX 9070: https://newegg.io/nc6c904af2\\nRTX 5070 Ti: https://newegg.io/ncc8d843aa\\nRX 9070 XT: https://newegg.io/ncd7924039\\nRTX 5080: https://newegg.io/nc45487d71\\nRTX 5090: https://newegg.io/nc60c8042e [...] Amazon (UK) [PAID LINKS]:\\nB570: https://amzlink.to/az0zJQpeqq2Js\\nB580: https://amzlink.to/az0LAlIxFBfKo\\nRTX 5060: https://amzlink.to/az0hIVbEZrI6B\\nRTX 5060 Ti 16GB: https://amzlink.to/az0HkaR5MIpvR\\nRX 9070: https://amzlink.to/az0syS72HTuPw\\nRTX 5070 Ti: https://amzlink.to/az0pZ6PXayEAU\\nRX 9070 XT: https://amzlink.to/az0LwqrQy9bK1\\nRTX 5080: https://amzlink.to/az0n4hQDRq9rx\\nRTX 5090: https://amzlink.to/az0HXuNlzKZWX [...] Amazon (US) [PAID LINKS]:\\nB570: https://amzlink.to/az0HOxxNV4OF8\\nB580: https://amzlink.to/az0u4cH6r0fB2\\nRTX 5060: https://amzlink.to/az0zbM77NOV2Z\\nRTX 5060 Ti 16GB: https://amzlink.to/az0YZkOnMFXY3\\nRX 9070: https://amzlink.to/az03UwkWLMGmH\\nRTX 5070 Ti: https://amzlink.to/az0AItZVPbPNO\\nRX 9070 XT: https://amzlink.to/az0oOI9UxwEay\\nRTX 5080: https://amzlink.to/az0SSNK8AQuzo\\nRTX 5090: https://amzlink.to/az0aj8ecrctEC\", \"score\": 0.73023266, \"raw_content\": null}, {\"url\": \"https://en.gamegpu.com/iron/msi-and-gigabyte-are-delaying-rtx-5090-deliveries-to-susa-until-power-rates-are-up-by-july-9\", \"title\": \"MSI and Gigabyte RTX 5090 Shipments to US Ahead of Tariffs ...\", \"content\": \"# MSI and Gigabyte RTX 5090 Shipments to US Ahead of Tariffs Coming into Effect on July 9\\n\\nAuthor [Maximum Games](https://en.gamegpu.com/view-user-profile?user=41287), 10 2025 June. Published in [Hardware](/backgammon/news/iron/) [...] ![rtx 5090 gigabyte](https://gamegpu.com/images/1_2025/NEWS/q2/f123/9600/rtx_5090_gigabyte.jpg)\\n\\n![rtx 5090 gigabyte](https://gamegpu.com/images/1_2025/NEWS/q2/f123/9600/rtx_5090_gigabyte.jpg) [...] Experts suggest that **NVIDIA's AIB Partners Will Hold Back RTX 5090 Stock**, waiting for the official return of tariffs. This will give the opportunity to raise prices after the deadline if agreements between the countries are not reached. A similar scheme was used in 2016-2017, when companies massively imported video cards before the start of trade restrictions. **RTX 5090 Availability May Worsen in July**, especially if tariffs are reintroduced and companies decide to pass the costs on to\", \"score\": 0.65173227, \"raw_content\": null}, {\"url\": \"https://www.notebookcheck.net/2025-Lenovo-Legion-Pro-7i-with-RTX-5090-and-Core-Ultra-9-275HX-gets-another-price-cut.1033540.0.html\", \"title\": \"2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX ...\", \"content\": \"Deal | 2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX gets another price cut ... It goes without saying that the top-end RTX 5090 configuration of\", \"score\": 0.64719695, \"raw_content\": null}, {\"url\": \"https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since\", \"title\": \"Cheapest 5090 ever? Lucky PC builder finds RTX 5090 for 'just ...\", \"content\": \"Redditor Sufficient\\\\_Crazy7758 took to the platform to hail their purchase of the \\\"Cheapest 5090 ever?\\\", after scooping a PNY GeForce RTX 5090 from Walmart for the relatively low price of $1,679.99. The attached images reveal that the card was discounted by over $1,500 on May 25, having previously been discounted on May 13.\\n\\n\\\"Just so all of you know, I bought this on that date and it has worked flawlessly ever since,\\\" they said triumphantly. [...] In the ever-evolving world of insane GPU prices, tariffs, and frightful stock shortages, one intrepid PC builder has managed to swipe an Nvidia RTX 5090 from Walmart for \\\"just\\\" $1,679, more than $200 below MSRP. [...] even the [Founders Edition still retails for the same price](https://goto.walmart.com/c/1943169/565706/9383?subId1=tomshardware-us-9572975325724004555&sharedId=tomshardware-us&u=https%3A%2F%2Fwww.walmart.com%2Fip%2FNVIDIA-GeForce-RTX-5090-Graphic-Card-32GB-GDDR7%2F15176552726%3FclassType%3DREGULAR%26from%3D%2Fsearch), way over the $1,999 MSRP.\", \"score\": 0.6016175, \"raw_content\": null}], \"response_time\": 2.98}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response['messages'][4].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c12011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the price of 5090?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the price of 5090?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": user_input},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cea72b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from backend.src.agent.tools_and_schemas import SearchQueryList, Reflection\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import START, END\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from google.genai import Client\n",
    "\n",
    "from backend.src.agent.state import (\n",
    "    OverallState,\n",
    "    QueryGenerationState,\n",
    "    ReflectionState,\n",
    "    WebSearchState,\n",
    ")\n",
    "from backend.src.agent.configuration import Configuration\n",
    "from backend.src.agent.prompts import (\n",
    "    get_current_date,\n",
    "    query_writer_instructions,\n",
    "    web_searcher_instructions,\n",
    "    reflection_instructions,\n",
    "    answer_instructions,\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "from backend.src.agent.utils import (\n",
    "    get_citations,\n",
    "    get_research_topic,\n",
    "    insert_citation_markers,\n",
    "    resolve_urls,\n",
    ")\n",
    "from typing import TypedDict, List, Annotated, Literal, Dict, Union, Optional \n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7ffec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your goal is to generate sophisticated and diverse web search queries. These queries are intended for an advanced automated web research tool capable of analyzing complex results, following links, and synthesizing information.\\n\\nInstructions: \\n- think what you need to know to answer the question first, your query can be incremental, the firsr query answer can be used to generate the second query.\\n- Always prefer a single search query, only add another query if the original question requests multiple aspects or elements and one query is not enough.\\n- Each query should focus on one specific aspect of the original question.\\n- Don\\'t produce more than {number_queries} queries.\\n- Queries should be diverse, if the topic is broad, generate more than 1 query.\\n- Don\\'t generate multiple similar queries, 1 is enough.\\n- Query should ensure that the most current information is gathered. The current date is {current_date}.\\n\\nFormat: \\n- Format your response as a JSON object with ALL three of these exact keys:\\n   - \"rationale\": Brief explanation of why these queries are relevant\\n   - \"query\": A list of search queries\\n   - \"plan\": Brief plan about steps about what yu want to know to answer the question\\n\\nExample:\\n\\nTopic: What revenue grew more last year apple stock or the number of people buying an iphone\\n```json\\n{{\\n    \"rationale\": \"To answer this comparative growth question accurately, we need specific data points on Apple\\'s stock performance and iPhone sales metrics. These queries target the precise financial information needed: company revenue trends, product-specific unit sales figures, and stock price movement over the same fiscal period for direct comparison.\",\\n    \"query\": [\"Apple total revenue growth fiscal year 2024\", \"iPhone unit sales growth fiscal year 2024\", \"Apple stock price growth fiscal year 2024\"],\\n    \"plan\": \"1, gather data on Apple\\'s stock market capitalization growth in 2024 to understand revenue growth from stock appreciation. 2, retrieve iPhone unit sales growth rates for the same period to compare with stock revenue growth. 3, Analyze both datasets to determine which metric experienced higher growth.\"\\n}}\\n```\\n\\nContext: {research_topic}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_writer_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997dcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_query(state: OverallState, config: RunnableConfig)->QueryGenerationState :\n",
    "    \"\"\"LangGraph node that generates a search queries based on the User's question.\n",
    "\n",
    "    Uses Gemini 2.0 Flash to create an optimized search query for web research based on\n",
    "    the User's question.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the User's question\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated query\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # check for custom initial search query count\n",
    "    if state.get(\"initial_search_query_count\") is None:\n",
    "        state[\"initial_search_query_count\"] = configurable.number_of_initial_queries\n",
    "\n",
    "    # init Gemini 2.0 Flash\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=configurable.query_generator_model,\n",
    "    #     temperature=1.0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(SearchQueryList)\n",
    "    print(get_research_topic(state[\"messages\"]),)\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = query_writer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        number_queries=state[\"initial_search_query_count\"],\n",
    "    )\n",
    "    # Generate the search queries\n",
    "    result = structured_llm.invoke(formatted_prompt)\n",
    "    # state['plan'] = result.plan\n",
    "    print(result)\n",
    "    return {\"plan\": result.plan, \"query_list\": result.query}\n",
    "\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "# builder.add_conditional_edges(\n",
    "#     \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    "# )\n",
    "builder.add_edge(\"generate_query\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "254e9cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me\n",
      "query=['RTX 5090 GPU models comparison heat dissipation and price June 2025'] rationale='To recommend the best GPU based on heat dissipation and price, we need to gather current information on the latest RTX 5090 models from different brands, focusing on their cooling solutions and pricing. This will allow for a comparison of performance and value.' plan='1. Identify the latest RTX 5090 models available from different brands. 2. Compare their heat dissipation technologies and cooling solutions. 3. Analyze their current pricing to determine the best value for money. 4. Recommend the GPU that offers the best balance of cooling efficiency and affordability.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5895e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content='{\\n    \"rationale\": \"To recommend a GPU based on heat dissipation and price for the RTX 5090 models, two distinct data points are required: comprehensive thermal performance comparisons of various brands to evaluate cooling efficiency, and current market prices to assess value. These queries ensure coverage of technical reviews and real-time pricing for informed decision-making.\",\\n    \"query\": [\\n        \"RTX 5090 custom models thermal performance comparison 2025\",\\n        \"RTX 5090 prices by brand June 2025\"\\n    ]\\n}' additional_kwargs={'refusal': None, 'reasoning_content': 'We are given: current price of 5090 with different brand, and the user wants to buy a new GPU considering heat dissipation function and price.\\n The user is specifically mentioning the \"5090\", which likely refers to the NVIDIA RTX 5090, a high-end graphics card. However, note that as of June 18, 2025, the RTX 5090 may or may not have been released (since NVIDIA\\'s next-gen after RTX 40 series is expected around 2024-2025). We need to check the latest information.\\n\\n The user\\'s requirements:\\n   - Heat dissipation function (cooling performance)\\n   - Price\\n\\n We are to recommend one GPU (presumably among the RTX 5090 models from different brands) that balances these two factors.\\n\\n Steps:\\n 1. We need to gather current models of RTX 5090 from various brands (like ASUS, MSI, Gigabyte, Zotac, etc.) along with their cooling solutions and prices.\\n 2. We need to compare these models based on:\\n    - Cooling performance (which can be assessed through reviews that measure temperatures and noise levels under load)\\n    - Price (the user has provided a current price context, but we need up-to-date pricing and deals)\\n\\n However, note: the user says \"current price of 5090 with different brand\", meaning they are aware of the existence of different brands and their varying prices. They want a recommendation based on heat dissipation and price.\\n\\n Approach for queries:\\n Since we are to generate one or a few queries (max 5) and they should be specific and not redundant:\\n\\n Option 1: We can do one query that aims to get a comparison of RTX 5090 models from different brands, focusing on cooling and price.\\n\\n But note: the user might also be open to other GPUs? The question says \"I want to buy a new GPU\" and they are considering the 5090, but they might be open to other high-end models? However, the context specifically says \"current price of 5090 with different brand\", so it\\'s clear they are focusing on the RTX 5090.\\n\\n However, let\\'s stick to the context: they are considering the RTX 5090 from different brands.\\n\\n How about:\\n\\n Query 1: \"RTX 5090 models cooling performance comparison 2025\"\\n   - This would help in getting reviews that compare the thermal performance of different custom models.\\n\\n Query 2: \"RTX 5090 prices by brand June 2025\"\\n   - This would get the current prices.\\n\\n But wait: the user wants a recommendation. We are to generate queries that will help an automated tool to gather the necessary information to make that recommendation.\\n\\n However, note the instruction: \"think what you need to know to answer the question first\". We need to know:\\n   - The available RTX 5090 models and their cooling solutions (and how effective they are)\\n   - The current prices of these models\\n\\n But we can also look for a source that already does a comparison that includes both. So:\\n\\n Alternative: One query that covers both aspects? It might be hard to get one page that has both up-to-date prices and a detailed cooling comparison. Therefore, two queries might be necessary.\\n\\n However, let\\'s consider: the current date is June 18, 2025. We can also look for the latest reviews and then separately look for the latest prices.\\n\\n But note: the instruction says \"prefer a single search query\" unless the question requests multiple aspects. Here we have two aspects: heat dissipation and price. So two queries are acceptable.\\n\\n But also, we might get a review that includes both performance (including thermal) and the MSRP. However, actual prices in the market may vary and may be found on retailer sites. So:\\n\\n Query 1: For cooling performance: \"RTX 5090 thermal performance comparison 2025\"\\n   - This should return review roundups that test multiple models.\\n\\n Query 2: For current prices: \"RTX 5090 current prices June 2025\"\\n   - This should return the latest prices from retailers or price comparison sites.\\n\\n However, note that we are limited to 5 queries and we should only add if necessary. Two queries seem sufficient.\\n\\n But wait: the user might also be interested in the overall value (price to performance including cooling). We might need to combine the two. However, the tool can do that if we get the two sets of data.\\n\\n Also, note: the user might be open to other GPUs? The context says they are considering the 5090, but if we are to strictly follow, we are focusing on the 5090. However, the question does not explicitly rule out other models. But the context of \"current price of 5090 with different brand\" suggests that the user is comparing within the 5090 models.\\n\\n Therefore, we generate two queries:\\n\\n  1. To get the thermal performance data of various RTX 5090 models.\\n  2. To get the current prices of these models.\\n\\n But note: we might also need to know the brand and model names to cross-reference. The first query should return models by brand (like ASUS ROG Strix, MSI Suprim, etc.). The second query should also have the same models.\\n\\n However, we can also do one comprehensive query: \"RTX 5090 models comparison 2025: cooling and price\". But that might not be as effective.\\n\\n Considering the above, I propose two queries:\\n\\n   Query 1: \"RTX 5090 custom models thermal performance review roundup 2025\"\\n   Query 2: \"RTX 5090 prices by model June 2025\"\\n\\n But note: the tool is advanced and can follow links and synthesize. So with these two, it can gather the thermal data and the price data and then combine to recommend the model with the best cooling in a reasonable price range (or the best value for cooling).\\n\\n However, we might also consider: what if the user wants the best cooling regardless of price? Or the best value? The question says \"considering heat dissipation function and price\". So we need both.\\n\\n Therefore, two queries.\\n\\n But wait, the instruction says: \"Don\\'t generate multiple similar queries, 1 is enough.\" if one query can cover. However, these two are distinct. They are about two different aspects.\\n\\n However, let\\'s see if we can do with one:\\n\\n   Query: \"RTX 5090 models comparison 2025: cooling and current prices\"\\n\\n This might work? But it\\'s possible that a single page might not have both in-depth thermal analysis and the very latest prices (which change frequently). So two queries might be more effective.\\n\\n Considering the instructions, we are allowed to have more than one if the question has multiple aspects. This one does. So two queries.\\n\\n But note: we must not exceed 5. Two is safe.\\n\\n Rationale: We need to compare different brands of the RTX 5090 based on their cooling performance and current prices to recommend the best option that balances these two factors. The first query targets thermal performance reviews to evaluate cooling efficiency, while the second query gathers up-to-date pricing information for the same models.\\n\\n Therefore:\\n\\n   \"rationale\": \"To recommend an RTX 5090 model that balances heat dissipation and price, we need two distinct data points: comprehensive reviews comparing the cooling performance of various custom models, and current market prices for these models. These queries target the two critical factors independently to allow cross-referencing and value assessment.\",\\n   \"query\": [\\n        \"RTX 5090 custom models thermal performance review roundup 2025\",\\n        \"RTX 5090 current prices by model June 2025\"\\n   ]\\n\\n However, note: the user might also be interested in other factors? But the question specifically says \"Heat dissipation function and price\". So we focus on these.\\n\\n But wait: the user might also care about noise? Often, cooling performance is tied to noise. But the question says \"heat dissipation\", so we focus on thermal performance. However, if the reviews measure temperatures, that\\'s the key.\\n\\n Also, note: the model names must be consistent between the two queries. The first query should return model names (like ASUS ROG Strix, MSI Suprim X, etc.) and the second query should use the same naming.\\n\\n We are generating two queries. We are not generating more because two aspects are covered.\\n\\n Let\\'s write the JSON accordingly.'} response_metadata={'token_usage': {'completion_tokens': 1862, 'prompt_tokens': 398, 'total_tokens': 2260, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 1752, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 334}, 'model_name': 'deepseek-reasoner', 'system_fingerprint': 'fp_393bca965e_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None} id='run--474f9824-8478-4634-966c-e979126eb49c-0' usage_metadata={'input_tokens': 398, 'output_tokens': 1862, 'total_tokens': 2260, 'input_token_details': {'cache_read': 64}, 'output_token_details': {'reasoning': 1752}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745ab583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='current price of 5090 with different brand,I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me', additional_kwargs={}, response_metadata={}, id='6056e78c-5d95-4b32-969c-2f90137c0996')],\n",
       " 'search_query': [],\n",
       " 'plan': '1. Retrieve the latest pricing and cooling solutions for the NVIDIA RTX 5090 across different brands. 2. Compare the heat dissipation efficiency and price to identify the best option. 3. Recommend the GPU with the optimal balance of cooling performance and affordability.',\n",
       " 'web_research_result': [],\n",
       " 'sources_gathered': [],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3125633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_to_web_research(state: QueryGenerationState):\n",
    "    \"\"\"LangGraph node that sends the search queries to the web research node.\n",
    "\n",
    "    This is used to spawn n number of web research nodes, one for each search query.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        Send(\"web_research\", {\"search_query\": search_query, \"id\": int(idx)})\n",
    "        for idx, search_query in enumerate(state[\"query_list\"])\n",
    "    ]\n",
    "\n",
    "\n",
    "# def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
    "#     \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
    "\n",
    "#     Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
    "\n",
    "#     Args:\n",
    "#         state: Current graph state containing the search query and research loop count\n",
    "#         config: Configura\"tion for the runnable, including search API settings\n",
    "\n",
    "#     Returns:\n",
    "#         Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "#     \"\"\"\n",
    "#     # Configure\n",
    "#     configurable = Configuration.from_runnable_config(config)\n",
    "#     formatted_prompt = web_searcher_instructions.format(\n",
    "#         current_date=get_current_date(),\n",
    "#         research_topic=state[\"search_query\"],\n",
    "#     )\n",
    "#     llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-chat\",\n",
    "#     temperature=1,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     )\n",
    "\n",
    "#     # Create the agent with the formatted prompt as system message\n",
    "#     # agent = create_react_agent(\n",
    "#     #     llm,\n",
    "#     #     [tavily_search_tool],\n",
    "#     #     prompt=formatted_prompt\n",
    "#     # )\n",
    "#     # Uses the google genai client as the langchain client doesn't return grounding metadata\n",
    "#     genai_client = Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "#     response = genai_client.models.generate_content(\n",
    "#         model=configurable.query_generator_model,\n",
    "#         contents=formatted_prompt,\n",
    "#         config={\n",
    "#             \"tools\": [{\"google_search\": {}}],\n",
    "#             \"temperature\": 0,\n",
    "#         },\n",
    "#     )\n",
    "#     print('search results:')\n",
    "\n",
    "#     print(response)\n",
    "    \n",
    "#     # resolve the urls to short urls for saving tokens and time\n",
    "#     resolved_urls = resolve_urls(\n",
    "#         response.candidates[0].grounding_metadata.grounding_chunks, state[\"id\"]\n",
    "#     )\n",
    "#     # Gets the citations and adds them to the generated text\n",
    "#     citations = get_citations(response, resolved_urls)\n",
    "#     modified_text = insert_citation_markers(response.text, citations)\n",
    "#     sources_gathered = [item for citation in citations for item in citation[\"segments\"]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     return {\n",
    "#         \"sources_gathered\": sources_gathered,\n",
    "#         \"search_query\": [state[\"search_query\"]],\n",
    "#         \"web_research_result\": [modified_text],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958f97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Citation(BaseModel):\n",
    "    label: str = Field(\n",
    "        ...,\n",
    "        description=\"The name of the website.\",\n",
    "    )\n",
    "    source_id: str = Field(\n",
    "        ...,\n",
    "        description=\"The url of a SPECIFIC source which justifies the answer.\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        ...,\n",
    "        description=\"The VERBATIM quote from the specified source that justifies the answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and return all the sources used.\"\"\"\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources. Include any relevant sources in the answer as markdown hyperlinks. For example: 'This is a sample text ([url website](url))'\"\n",
    "    )\n",
    "    citations: List[Citation] = Field(\n",
    "        ..., description=\"Citations from the given sources that justify the answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
    "    \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
    "\n",
    "    Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configura\"tion for the runnable, including search API settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    # Configure\n",
    "    load_dotenv()\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize Tavily Search Tool\n",
    "    tavily_search_tool = TavilySearch(\n",
    "        max_results=5,\n",
    "        topic=\"general\",\n",
    "    )\n",
    "    tool_calling_llm = llm.bind_tools([tavily_search_tool])\n",
    "    # agent = create_react_agent(llm, [tavily_search_tool])\n",
    "\n",
    "    # user_input = \"What nation hosted the Euro 2024?\"\n",
    "    user_input = state[\"search_query\"]\n",
    "    # formatted_prompt = web_searcher_instructions.format(\n",
    "    #     current_date=get_current_date(),\n",
    "    #     research_topic='price of 5090',\n",
    "    # )\n",
    "\n",
    "    web_searcher_instructions = \"\"\"Use your search tool to conduct targeted Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
    "\n",
    "    Instructions:\n",
    "    - Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
    "    - Conduct multiple, diverse searches to gather comprehensive information.\n",
    "    - Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
    "    - The output should be a well-written summary or report based on your search findings. \n",
    "    - Only include the information found in the search results, don't make up any information.\n",
    "\n",
    "    Research Topic:\n",
    "    {research_topic}\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_prompt = web_searcher_instructions.format(\n",
    "        current_date=get_current_date(),\n",
    "        research_topic=user_input,\n",
    "    ) + \"\\n\\nIMPORTANT: Use the search tool provided to find the most up-to-date information, and choose the right arguments for the search tool.\"\n",
    "\n",
    "\n",
    "    def run_tool(response_msg):\n",
    "        if \"tool_calls\" in response_msg.additional_kwargs:\n",
    "            for tool_call in response_msg.additional_kwargs[\"tool_calls\"]:\n",
    "                tool_name = tool_call[\"function\"][\"name\"]\n",
    "                arguments = tool_call[\"function\"][\"arguments\"]\n",
    "                parsed_args = json.loads(arguments)\n",
    "                if tool_name == \"tavily_search\":\n",
    "                    return {\"tool_result\": tavily_search_tool.invoke(parsed_args)}\n",
    "        return {\"tool_result\": \"No tool call made.\"}\n",
    "\n",
    "    # === Final LLM with structured output ===\n",
    "    final_llm = llm.with_structured_output(QuotedAnswer)\n",
    "    # Step 3: Combine it with the LLM output step\n",
    "    chain = (\n",
    "        tool_calling_llm |\n",
    "        RunnableLambda(run_tool) |\n",
    "        (lambda inputs: final_llm.invoke(f\"Based on this search result: {inputs['tool_result']}, answer the user question.\"))\n",
    "    )\n",
    "\n",
    "    result = chain.invoke(formatted_prompt)\n",
    "    web_research_result = result.answer + \"\\n---\\n\\n\".join([citation.source_id for citation in result.citations])\n",
    "    citations_list = []\n",
    "    for citation in result.citations:\n",
    "        citations_dict = {}\n",
    "        citations_dict['label'] = citation.label\n",
    "        citations_dict['short_url'] = citation.source_id\n",
    "        citations_dict['value'] = citation.quote\n",
    "        citations_list.append(citations_dict)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"sources_gathered\": citations_list,\n",
    "        \"search_query\": [state[\"search_query\"]],\n",
    "        \"web_research_result\": [web_research_result],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3888798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "builder.add_edge(\"web_research\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0c4611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent price of 5090 with different brand,\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mI want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\u001b[39m\u001b[38;5;124m\"\u001b[39m}], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_research_loops\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_search_query_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2721\u001b[0m     config,\n\u001b[1;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[1;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2729\u001b[0m ):\n\u001b[1;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2734\u001b[0m         ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2441\u001b[0m         ):\n\u001b[1;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     run_with_retry(\n\u001b[1;32m    162\u001b[0m         t,\n\u001b[1;32m    163\u001b[0m         retry_policy,\n\u001b[1;32m    164\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    165\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[1;32m    166\u001b[0m                 _call,\n\u001b[1;32m    167\u001b[0m                 weakref\u001b[38;5;241m.\u001b[39mref(t),\n\u001b[1;32m    168\u001b[0m                 retry\u001b[38;5;241m=\u001b[39mretry_policy,\n\u001b[1;32m    169\u001b[0m                 futures\u001b[38;5;241m=\u001b[39mweakref\u001b[38;5;241m.\u001b[39mref(futures),\n\u001b[1;32m    170\u001b[0m                 schedule_task\u001b[38;5;241m=\u001b[39mschedule_task,\n\u001b[1;32m    171\u001b[0m                 submit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[1;32m    172\u001b[0m             ),\n\u001b[1;32m    173\u001b[0m         },\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[12], line 43\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m     37\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m query_writer_instructions\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     38\u001b[0m     current_date\u001b[38;5;241m=\u001b[39mcurrent_date,\n\u001b[1;32m     39\u001b[0m     research_topic\u001b[38;5;241m=\u001b[39mget_research_topic(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     40\u001b[0m     number_queries\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_search_query_count\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Generate the search queries\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m structured_llm\u001b[38;5;241m.\u001b[39minvoke(formatted_prompt)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# state['plan'] = result.plan\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3045\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   3044\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3045\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3047\u001b[0m         input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5423\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5429\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m   5431\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5432\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5433\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5434\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    777\u001b[0m                 m,\n\u001b[1;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    781\u001b[0m             )\n\u001b[1;32m    782\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:925\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 925\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    916\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    917\u001b[0m             {\n\u001b[1;32m    918\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    919\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    920\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m    921\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    924\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    928\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m    949\u001b[0m             },\n\u001b[1;32m    950\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    951\u001b[0m         ),\n\u001b[1;32m    952\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    953\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    954\u001b[0m         ),\n\u001b[1;32m    955\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    956\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    957\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    958\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    920\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    921\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    922\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    923\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    924\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    925\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    956\u001b[0m         request,\n\u001b[1;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    959\u001b[0m     )\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 922\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_bytes())\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:367\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:363\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    364\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:349\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:341\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 341\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:210\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    207\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "408ee220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me', additional_kwargs={}, response_metadata={}, id='2ea6b91f-93c8-43e4-a46f-b3b407c59c7b')],\n",
       " 'search_query': ['NVIDIA RTX 5090 price comparison June 2025',\n",
       "  'NVIDIA RTX 5090 heat dissipation performance reviews June 2025'],\n",
       " 'plan': '1. Retrieve the latest pricing for the NVIDIA RTX 5090 from different brands to identify cost-effective options. 2. Gather reviews or benchmarks on heat dissipation performance to ensure the GPU meets cooling requirements. 3. Synthesize the data to recommend the best option balancing price and heat dissipation.',\n",
       " 'web_research_result': ['As of June 2025, the NVIDIA RTX 5090 is priced at approximately $1,999 USD for the Founders Edition, with third-party variants ranging from $2,099 to $2,499 depending on the manufacturer and additional features like overclocking or enhanced cooling solutions. Retailers such as Amazon, Newegg, and Best Buy are offering competitive pricing, with occasional discounts or bundle deals. For example, Newegg currently lists the ASUS ROG Strix RTX 5090 at $2,299 with a free game bundle ([Newegg](https://www.newegg.com)).https://www.newegg.com',\n",
       "  'The NVIDIA RTX 5090 heat dissipation performance reviews for June 2025 are not yet available in the sources I have access to. Please check back later or provide specific sources for me to analyze.'],\n",
       " 'sources_gathered': [{'label': 'Newegg',\n",
       "   'short_url': 'https://www.newegg.com',\n",
       "   'value': 'ASUS ROG Strix RTX 5090 priced at $2,299 with a free game bundle.'}],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea88855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:\n",
    "    \"\"\"LangGraph node that identifies knowledge gaps and generates potential follow-up queries.\n",
    "\n",
    "    Analyzes the current summary to identify areas for further research and generates\n",
    "    potential follow-up queries. Uses structured output to extract\n",
    "    the follow-up query in JSON format.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated follow-up query\n",
    "    \"\"\"\n",
    "    # configurable = Configuration.from_runnable_config(config)\n",
    "    # Increment the research loop count and get the reasoning model\n",
    "    state[\"research_loop_count\"] = state.get(\"research_loop_count\", 0) + 1\n",
    "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
    "\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = reflection_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        summaries=\"\\n\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
    "        plan=state[\"plan\"],\n",
    "    )\n",
    "    # init Reasoning Model\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=reasoning_model,\n",
    "    #     temperature=1.0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    result = llm.with_structured_output(Reflection).invoke(formatted_prompt)\n",
    "\n",
    "    return {\n",
    "        \"is_sufficient\": result.is_sufficient,\n",
    "        \"knowledge_gap\": result.knowledge_gap,\n",
    "        \"follow_up_queries\": result.follow_up_queries,\n",
    "        \"research_loop_count\": state[\"research_loop_count\"],\n",
    "        \"number_of_ran_queries\": len(state[\"search_query\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_research(\n",
    "    state: ReflectionState,\n",
    "    config: RunnableConfig,\n",
    ") -> OverallState:\n",
    "    \"\"\"LangGraph routing function that determines the next step in the research flow.\n",
    "\n",
    "    Controls the research loop by deciding whether to continue gathering information\n",
    "    or to finalize the summary based on the configured maximum number of research loops.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the research loop count\n",
    "        config: Configuration for the runnable, including max_research_loops setting\n",
    "\n",
    "    Returns:\n",
    "        String literal indicating the next node to visit (\"web_research\" or \"finalize_summary\")\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    max_research_loops = (\n",
    "        state.get(\"max_research_loops\")\n",
    "        if state.get(\"max_research_loops\") is not None\n",
    "        else configurable.max_research_loops\n",
    "    )\n",
    "    if state[\"is_sufficient\"] or state[\"research_loop_count\"] >= max_research_loops:\n",
    "        return \"finalize_answer\"\n",
    "    else:\n",
    "        return [\n",
    "            Send(\n",
    "                \"web_research\",\n",
    "                {\n",
    "                    \"search_query\": follow_up_query,\n",
    "                    \"id\": state[\"number_of_ran_queries\"] + int(idx),\n",
    "                },\n",
    "            )\n",
    "            for idx, follow_up_query in enumerate(state[\"follow_up_queries\"])\n",
    "        ]\n",
    "\n",
    "\n",
    "def finalize_answer(state: OverallState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that finalizes the research summary.\n",
    "\n",
    "    Prepares the final output by deduplicating and formatting sources, then\n",
    "    combining them with the running summary to create a well-structured\n",
    "    research report with proper citations.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and sources gathered\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the formatted final summary with sources\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
    "\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = answer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        summaries=\"\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
    "    )\n",
    "\n",
    "    # init Reasoning Model, default to Gemini 2.5 Flash\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=reasoning_model,\n",
    "    #     temperature=0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    result = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # Replace the short urls with the original urls and add all used urls to the sources_gathered\n",
    "    unique_sources = []\n",
    "    for source in state[\"sources_gathered\"]:\n",
    "        if source[\"short_url\"] in result.content:\n",
    "            result.content = result.content.replace(\n",
    "                source[\"short_url\"], source[\"value\"]\n",
    "            )\n",
    "            unique_sources.append(source)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=result.content)],\n",
    "        \"sources_gathered\": unique_sources,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create our Agent Graph\n",
    "builder = StateGraph(OverallState, config_schema=Configuration)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_node(\"reflection\", reflection)\n",
    "builder.add_node(\"finalize_answer\", finalize_answer)\n",
    "\n",
    "# Set the entrypoint as `generate_query`\n",
    "# This means that this node is the first one called\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "# Add conditional edge to continue with search queries in a parallel branch\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "# Reflect on the web research\n",
    "builder.add_edge(\"web_research\", \"reflection\")\n",
    "# Evaluate the research\n",
    "builder.add_conditional_edges(\n",
    "    \"reflection\", evaluate_research, [\"web_research\", \"finalize_answer\"]\n",
    ")\n",
    "# Finalize the answer\n",
    "builder.add_edge(\"finalize_answer\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c7d18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\n",
      "query=['RTX 5090 GPU models price comparison June 2025', 'RTX 5090 GPU thermal performance and cooling solutions June 2025'] rationale='To recommend the best GPU based on heat dissipation and price, we need to gather current pricing and thermal performance data for the RTX 5090 models from different brands. This will allow for a comparison of cost-effectiveness and cooling efficiency.' plan='1. Retrieve the latest pricing information for RTX 5090 GPUs from various brands to identify cost-effective options. 2. Gather data on thermal performance and cooling solutions for these models to evaluate heat dissipation efficiency. 3. Compare the collected data to recommend the best GPU based on the balance between price and cooling performance.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f00d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTX 5090 and Switch2, the difference of the GPU performance,    and tell me how many times 5090 is faster than Switch2\n",
      "query=['RTX 5090 GPU benchmarks and specifications 2025', 'Nintendo Switch2 GPU performance and specifications 2025', 'RTX 5090 vs Nintendo Switch2 GPU performance comparison 2025'] rationale=\"To compare the GPU performance between the RTX 5090 and Switch2, we need specific benchmarks and technical specifications for both GPUs. The first query will gather general performance metrics for the RTX 5090, while the second query will focus on the Switch2's GPU capabilities. The third query will aim to find direct comparisons or benchmarks between the two GPUs to determine the performance difference.\" plan=\"1. Retrieve the latest benchmarks and specifications for the RTX 5090 to understand its performance capabilities. 2. Gather similar data for the Nintendo Switch2's GPU to establish its performance baseline. 3. Find direct comparisons or benchmarks between the two GPUs to quantify how many times faster the RTX 5090 is compared to the Switch2.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"RTX 5090 and Switch2, the difference of the GPU performance,\\\n",
    "    and tell me how many times 5090 is faster than Switch2\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e1b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='RTX 5090 and Switch2, the difference of the GPU performance,    and tell me how many times 5090 is faster than Switch2', additional_kwargs={}, response_metadata={}, id='b0219157-c571-4721-8ca5-2ae461647a06'),\n",
       "  AIMessage(content=\"Based on the available specifications and performance metrics for both GPUs, here's a direct comparison:\\n\\n**NVIDIA GeForce RTX 5090 (Desktop GPU):**\\n- **CUDA Cores:** 21,760 \\n- **Memory:** 32GB GDDR7  \\n- **Memory Bandwidth:** 1.34 TB/s  \\n- **Architecture:** Blackwell (TSMC 3nm)  \\n- **TDP:** 575 W  \\n*(Sources: [TechPowerUp](NVIDIA GeForce RTX 5090 Features 575 W TDP, RTX 5080 Carries 360 W TDP), [TechPowerUp Specs](Memory Size 24 GB Memory Type GDDR7 Memory Bus 384 bit Bandwidth 1.34 TB/s), [GameMaxPC](The RTX 5090, built on NVIDIA's cutting-edge Blackwell architecture, ushers in a new era of gaming performance. Fabricated on TSMC's 3nm process, this monolithic marvel packs 92 billion transistors, 21,760 CUDA cores, and 680 fifth-generation Tensor Cores. Coupled with 32GB of GDDR7 memory (1,792GB/s bandwidth), it redefines the boundaries of compute density and energy efficiency.))*\\n\\n**Nintendo Switch 2 GPU (Custom Mobile Chip):**  \\n- **CUDA Cores:** 1,536 (Ampere-based)  \\n- **Performance:** 3.07 TFLOPs (docked mode)  \\n- **Memory Bandwidth:** 102 GB/s (docked)  \\n- **Clock Speeds:** Up to 1.4 GHz (theoretical max)  \\n*(Sources: [Eurogamer](For the GPU, T239 features 1,536 CUDA cores based on Nvidia's Ampere architecture, as found in the RTX 30-series line of graphics cards, supporting machine learning and ray tracing. The GPU clocks at 561MHz in handheld mode, rising to 1007MHz in performance mode (typically for docked play). Constrained for thermal and battery life reasons, theoretically the GPU can max at 1.4GHz.), [AInvest](The Switch 2's hardware is its most compelling feature. Powered by NVIDIA's Tegra T239 SoC, the console boasts an octa-core ARM Cortex-A78C CPU and an Ampere GPU with 1,536 CUDA cores. This architecture delivers **3.07 TFLOPs of performance in docked mode**, a significant leap from the original Switch's 1.0 TFLOPs.))*\\n\\n### Performance Difference:\\n1. **Theoretical Raw Power (TFLOPs):**  \\n   - While the RTX 5090's exact TFLOPs aren't provided, its predecessor (RTX 4090) achieves ~82 TFLOPs. The RTX 5090's architectural improvements (Blackwell, 3nm) and increased CUDA cores suggest **at least 100+ TFLOPs**.  \\n   - Switch 2: **3.07 TFLOPs** (docked).  \\n   - **Estimated Difference:** The RTX 5090 is **roughly 30–35 times faster** in raw compute performance.  \\n\\n2. **Architectural & Feature Gap:**  \\n   - The RTX 5090 uses GDDR7 memory with **13× higher bandwidth** (1.34 TB/s vs. 102 GB/s) and **14× more CUDA cores** (21,760 vs. 1,536).  \\n   - It supports advanced ray tracing, DLSS 4, and is optimized for 4K/8K gaming, while the Switch 2 targets 1080p/4K with hybrid mobile constraints.  \\n\\n### Key Considerations:\\n- **No Direct Benchmark Exists:** No official tests compare these GPUs directly, as they target entirely different platforms (desktop vs. handheld console) ([TechPowerUp](Surprise Reversal: GeForce RTX 5090 Found with Too Many ROPs, Matches RTX Pro 6000, +8% Performance)).  \\n- **Real-World Gaming:** The RTX 5090 will deliver significantly higher frame rates and fidelity, but the Switch 2 is optimized for efficiency and portability.  \\n\\n### Conclusion:  \\nBased on hardware specifications and architectural analysis, the **RTX 5090 is approximately 30–35 times faster** than the Switch 2 GPU in raw theoretical performance. Actual gaming performance differences will vary due to the Switch 2's game-specific optimizations and lower rendering targets.  \\n\\n*(All citations derived from provided summaries.)*\", additional_kwargs={}, response_metadata={}, id='caeec3a6-28a2-493d-baf5-e83eaf46a988')],\n",
       " 'search_query': ['RTX 5090 GPU benchmarks and specifications 2025',\n",
       "  'Nintendo Switch2 GPU performance and specifications 2025',\n",
       "  'RTX 5090 vs Nintendo Switch2 GPU performance comparison 2025',\n",
       "  \"What are the performance benchmarks comparing the NVIDIA GeForce RTX 5090 and the Nintendo Switch2's GPU in terms of TFLOPs, CUDA cores, and memory bandwidth?\"],\n",
       " 'plan': \"1. Retrieve the latest benchmarks and specifications for the RTX 5090 to understand its performance capabilities. 2. Gather similar data for the Nintendo Switch2's GPU to establish its performance baseline. 3. Find direct comparisons or benchmarks between the two GPUs to quantify how many times faster the RTX 5090 is compared to the Switch2.\",\n",
       " 'web_research_result': ['The NVIDIA GeForce RTX 5090, expected in 2025, features a 575 W TDP and is based on the GB202 GPU with 21,760 CUDA cores and 32GB of GDDR7 memory. It has shown an 8% performance increase over previous models and matches the RTX Pro 6000 in some benchmarks. A variant, the RTX 5090DD, has been teased with reduced VRAM (24GB) but retains gaming performance. The GPU is also available in mobile versions, such as in the ASUS ROG Strix SCAR 18, with 10,496 CUDA cores for laptops.https://www.techpowerup.com/330459/nvidia-geforce-rtx-5090-features-575-w-tdp-rtx-5080-carries-360-w-tdp\\n---\\n\\nhttps://www.techpowerup.com/334901/surprise-reversal-geforce-rtx-5090-found-with-too-many-rops-matches-rtx-pro-6000-8-performance\\n---\\n\\nhttps://www.tweaktown.com/news/105880/nvidia-geforce-rtx-5090-dd-teased-more-than-handful-in-terms-of-gpu-performance/index.html\\n---\\n\\nhttps://me.pcmag.com/en/laptops/30494/asus-rog-strix-scar-18-2025-review-rtx-5090-powered-performance-in-a-monster-gaming-laptop',\n",
       "  'The Nintendo Switch 2, expected in 2025, features significant GPU performance improvements over its predecessor. Here are the key specifications and performance details:\\n\\n1. **GPU Performance**: Nvidia claims the Switch 2 has \"10x the graphics performance\" of the original Switch ([Nintendo Life](https://www.nintendolife.com/news/2025/04/nvidia-switch-2-has-10x-the-graphics-performance-of-the-nintendo-switch)).\\n2. **GPU Architecture**: The Switch 2 uses an Ampere-based GPU with 1,536 CUDA cores, supporting machine learning and ray tracing ([Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review)).\\n3. **Clock Speeds**: The GPU clocks at 561MHz in handheld mode and 1007MHz in docked mode, with a theoretical maximum of 1.4GHz ([Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review)).\\n4. **Memory Bandwidth**: The Switch 2 offers 102GB/s bandwidth in docked mode and 68GB/s in handheld mode, a significant upgrade from the original Switch ([Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review)).\\n5. **Performance Metrics**: The GPU delivers 3.07 TFLOPs in docked mode, a substantial leap from the original Switch\\'s 1.0 TFLOPs ([AInvest](https://www.ainvest.com/news/nintendo-switch-2-strategic-buy-gaming-hardware-race-2506/)).\\n6. **Display Support**: The Switch 2 supports up to 4K resolution when docked and 1080p in handheld mode ([TechRadar](https://www.techradar.com/gaming/nintendo/nintendo-switch-2-review)).https://www.nintendolife.com/news/2025/04/nvidia-switch-2-has-10x-the-graphics-performance-of-the-nintendo-switch\\n---\\n\\nhttps://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review\\n---\\n\\nhttps://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review\\n---\\n\\nhttps://www.ainvest.com/news/nintendo-switch-2-strategic-buy-gaming-hardware-race-2506/\\n---\\n\\nhttps://www.techradar.com/gaming/nintendo/nintendo-switch-2-review',\n",
       "  \"Based on the search results, there is no direct comparison available between the RTX 5090 and the Nintendo Switch2 GPU performance for 2025. The sources primarily discuss the specifications and variants of the RTX 5090, such as the RTX 5090 DD for the Chinese market, but do not mention the Nintendo Switch2's GPU or any performance comparisons between the two.\",\n",
       "  \"The NVIDIA GeForce RTX 5090, expected to be released in 2025, features impressive specifications. It includes **21,760 CUDA cores**, **32GB of GDDR7 memory**, and a **memory bandwidth of 1.34 TB/s**. The GPU is built on NVIDIA's Blackwell architecture and fabricated on TSMC's 3nm process, offering significant advancements in performance and energy efficiency ([TechPowerUp](https://www.techpowerup.com/gpu-specs/geforce-rtx-5090-dd.c4310), [GameMaxPC](https://gamemaxpc.com/pc-case-news/5917.html)).https://www.techpowerup.com/gpu-specs/geforce-rtx-5090-dd.c4310\\n---\\n\\nhttps://gamemaxpc.com/pc-case-news/5917.html\"],\n",
       " 'sources_gathered': [{'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/330459/nvidia-geforce-rtx-5090-features-575-w-tdp-rtx-5080-carries-360-w-tdp',\n",
       "   'value': 'NVIDIA GeForce RTX 5090 Features 575 W TDP, RTX 5080 Carries 360 W TDP'},\n",
       "  {'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/334901/surprise-reversal-geforce-rtx-5090-found-with-too-many-rops-matches-rtx-pro-6000-8-performance',\n",
       "   'value': 'Surprise Reversal: GeForce RTX 5090 Found with Too Many ROPs, Matches RTX Pro 6000, +8% Performance'},\n",
       "  {'label': 'TweakTown',\n",
       "   'short_url': 'https://www.tweaktown.com/news/105880/nvidia-geforce-rtx-5090-dd-teased-more-than-handful-in-terms-of-gpu-performance/index.html',\n",
       "   'value': 'NVIDIA launched its cut-down GeForce RTX 5090 back in January 2025, tweaked to meet US export controls, but its AI TOPs power was sliced down, but the GPU retained its same GB202 GPU with 21760 CUDA cores and 32GB of GDDR7 memory. This new RTX 5090DD has the VRAM cut down from 32GB to 24GB, a big difference, but retains all of its gaming power.'},\n",
       "  {'label': 'PCMag',\n",
       "   'short_url': 'https://me.pcmag.com/en/laptops/30494/asus-rog-strix-scar-18-2025-review-rtx-5090-powered-performance-in-a-monster-gaming-laptop',\n",
       "   'value': 'The RTX 5090 Laptop GPU features 10,496 CUDA cores across 82 Streaming Multiprocessors, delivering top-tier gaming and creative performance in a mobile package.'},\n",
       "  {'label': 'Nintendo Life',\n",
       "   'short_url': 'https://www.nintendolife.com/news/2025/04/nvidia-switch-2-has-10x-the-graphics-performance-of-the-nintendo-switch',\n",
       "   'value': 'Nvidia claims that Switch 2 has \"10x the graphics performance\" of the original Switch.'},\n",
       "  {'label': 'Eurogamer',\n",
       "   'short_url': 'https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review',\n",
       "   'value': \"For the GPU, T239 features 1,536 CUDA cores based on Nvidia's Ampere architecture, as found in the RTX 30-series line of graphics cards, supporting machine learning and ray tracing. The GPU clocks at 561MHz in handheld mode, rising to 1007MHz in performance mode (typically for docked play). Constrained for thermal and battery life reasons, theoretically the GPU can max at 1.4GHz.\"},\n",
       "  {'label': 'Eurogamer',\n",
       "   'short_url': 'https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review',\n",
       "   'value': '12GB of LPDDR5X memory runs at 6400MT/s while docked for 102GB/s of bandwidth in performance mode, which is [...] |  | Switch 2: Nvidia T239 | Switch 1: Nvidia Tegra X1 |'},\n",
       "  {'label': 'AInvest',\n",
       "   'short_url': 'https://www.ainvest.com/news/nintendo-switch-2-strategic-buy-gaming-hardware-race-2506/',\n",
       "   'value': \"The Switch 2's hardware is its most compelling feature. Powered by NVIDIA's Tegra T239 SoC, the console boasts an octa-core ARM Cortex-A78C CPU and an Ampere GPU with 1,536 CUDA cores. This architecture delivers **3.07 TFLOPs of performance in docked mode**, a significant leap from the original Switch's 1.0 TFLOPs.\"},\n",
       "  {'label': 'TechRadar',\n",
       "   'short_url': 'https://www.techradar.com/gaming/nintendo/nintendo-switch-2-review',\n",
       "   'value': 'Resolution (docked)\\n\\nUp to 4K\\n\\nResolution (handheld)\\n\\nUp to 1080p'},\n",
       "  {'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/gpu-specs/geforce-rtx-5090-dd.c4310',\n",
       "   'value': 'Memory Size 24 GB Memory Type GDDR7 Memory Bus 384 bit Bandwidth 1.34 TB/s'},\n",
       "  {'label': 'GameMaxPC',\n",
       "   'short_url': 'https://gamemaxpc.com/pc-case-news/5917.html',\n",
       "   'value': \"The RTX 5090, built on NVIDIA's cutting-edge Blackwell architecture, ushers in a new era of gaming performance. Fabricated on TSMC's 3nm process, this monolithic marvel packs 92 billion transistors, 21,760 CUDA cores, and 680 fifth-generation Tensor Cores. Coupled with 32GB of GDDR7 memory (1,792GB/s bandwidth), it redefines the boundaries of compute density and energy efficiency.\"},\n",
       "  {'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/330459/nvidia-geforce-rtx-5090-features-575-w-tdp-rtx-5080-carries-360-w-tdp',\n",
       "   'value': 'NVIDIA GeForce RTX 5090 Features 575 W TDP, RTX 5080 Carries 360 W TDP'},\n",
       "  {'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/334901/surprise-reversal-geforce-rtx-5090-found-with-too-many-rops-matches-rtx-pro-6000-8-performance',\n",
       "   'value': 'Surprise Reversal: GeForce RTX 5090 Found with Too Many ROPs, Matches RTX Pro 6000, +8% Performance'},\n",
       "  {'label': 'Eurogamer',\n",
       "   'short_url': 'https://www.eurogamer.net/digitalfoundry-2025-nintendo-switch-2-the-digital-foundry-hardware-review',\n",
       "   'value': \"For the GPU, T239 features 1,536 CUDA cores based on Nvidia's Ampere architecture, as found in the RTX 30-series line of graphics cards, supporting machine learning and ray tracing. The GPU clocks at 561MHz in handheld mode, rising to 1007MHz in performance mode (typically for docked play). Constrained for thermal and battery life reasons, theoretically the GPU can max at 1.4GHz.\"},\n",
       "  {'label': 'AInvest',\n",
       "   'short_url': 'https://www.ainvest.com/news/nintendo-switch-2-strategic-buy-gaming-hardware-race-2506/',\n",
       "   'value': \"The Switch 2's hardware is its most compelling feature. Powered by NVIDIA's Tegra T239 SoC, the console boasts an octa-core ARM Cortex-A78C CPU and an Ampere GPU with 1,536 CUDA cores. This architecture delivers **3.07 TFLOPs of performance in docked mode**, a significant leap from the original Switch's 1.0 TFLOPs.\"},\n",
       "  {'label': 'TechPowerUp',\n",
       "   'short_url': 'https://www.techpowerup.com/gpu-specs/geforce-rtx-5090-dd.c4310',\n",
       "   'value': 'Memory Size 24 GB Memory Type GDDR7 Memory Bus 384 bit Bandwidth 1.34 TB/s'},\n",
       "  {'label': 'GameMaxPC',\n",
       "   'short_url': 'https://gamemaxpc.com/pc-case-news/5917.html',\n",
       "   'value': \"The RTX 5090, built on NVIDIA's cutting-edge Blackwell architecture, ushers in a new era of gaming performance. Fabricated on TSMC's 3nm process, this monolithic marvel packs 92 billion transistors, 21,760 CUDA cores, and 680 fifth-generation Tensor Cores. Coupled with 32GB of GDDR7 memory (1,792GB/s bandwidth), it redefines the boundaries of compute density and energy efficiency.\"}],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5,\n",
       " 'research_loop_count': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab31a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/05/rumour-a-nintendo-direct-may-drop-around-the-switch-2s-launch',\n",
       "  'value': 'Meanwhile, the Switch 2 itself is launching worldwide on 5th June 2025, alongside launch games such as Mario Kart World, Cyberpunk 2077: Ultimate Edition, Street Fighter 6: Years 1-2 Fighters Edition, and more.'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/05/pokemon-legends-z-a-secures-switch-and-switch-2-release-date',\n",
       "  'value': 'The Pokémon Company has surprised us all with the announcement that Pokémon Legends: Z-A will arrive on Switch and Switch 2 on 16th October 2025.'},\n",
       " {'label': 'Nintendo Everything',\n",
       "  'short_url': 'https://nintendoeverything.com/devils-third-interview-wii-u-tomonobu-itagaki/',\n",
       "  'value': \"Image 17: Famitsu's most wanted games - June 8, 2025 - Metroid Prime 4 - Nintendo Switch 2 Edition appears\"},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/nintendo-survey-asks-switch-2-users-about-their-experience-so-far',\n",
       "  'value': 'Image 92: Review: Mario Kart World (Switch 2) - The Perfect Introduction To A New Console Generation'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/rumble-has-been-turned-off-due-to-prolonged-use-dont-worry-your-switch-2-joy-con-probably-arent-broken',\n",
       "  'value': 'Review: Fast Fusion (Switch 2) - The Most Accomplish...'},\n",
       " {'label': 'Nintendo Everything',\n",
       "  'short_url': 'https://nintendoeverything.com/nintendo-switch-2-firmware-update-carbon-engine-games-fixed/',\n",
       "  'value': 'Rune Factory: Guardians of Azuma review for Nintendo Switch – also coming to Switch 2'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/misc-a-tiny-tale-looks-super-smooth-on-switch-2-thanks-to-a-dev-hunch',\n",
       "  'value': \"'Misc. A Tiny Tale' Looks Super Smooth On Switch 2, Thanks To A Dev Hunch\"},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/rumble-has-been-turned-off-due-to-prolonged-use-dont-worry-your-switch-2-joy-con-probably-arent-broken',\n",
       "  'value': 'Review: Cyberpunk 2077: Ultimate Edition (Switch 2) ...'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/rumble-has-been-turned-off-due-to-prolonged-use-dont-worry-your-switch-2-joy-con-probably-arent-broken',\n",
       "  'value': 'Image 56: Zelda: Tears Of The Kingdom And Breath Of The Wild Updates Now Live, Here Are The Full Patch Notes'},\n",
       " {'label': 'Passionategeekz',\n",
       "  'short_url': 'https://www.instagram.com/p/DLBmSmMMW2R/',\n",
       "  'value': 'Nintendo Switch 2 game consoles were stolen, each worth about US$500 (Passionategeekz Note: the current exchange rate is about RMB 3594).'},\n",
       " {'label': 'TechRadar',\n",
       "  'short_url': 'https://www.techradar.com/gaming/nintendo/best-nintendo-switch-2-games',\n",
       "  'value': '\"The Legend of Zelda: Tears of the Kingdom leaps forward on what was offered in 2017’s Breath of the Wild, filling out the world’s sandbox with innovative new tools and abilities, letting you approach challenges in inventive new ways.\" - Julian Benson, TechRadar Gaming reviewer.'},\n",
       " {'label': 'TechRadar',\n",
       "  'short_url': 'https://www.techradar.com/gaming/nintendo/best-nintendo-switch-2-games',\n",
       "  'value': '\"The Legend of Zelda: Echoes of Wisdom is a charming follow-up to Link\\'s Awakening that builds on that game’s beautiful aesthetic while introducing just enough new mechanics to feel truly distinct. The dubious performance and repetitive combat can drag, but this is largely an excellent adventure throughout.\" - Dashiell Wood, TechRadar Gaming Hardware Writer.'},\n",
       " {'label': 'ScreenRant',\n",
       "  'short_url': 'https://screenrant.com/nintendo-switch-2-review/',\n",
       "  'value': 'The Nintendo Switch 2 is the successor to Nintendo Switch, scheduled for release in 2025. Confirmed as backwards compatible, it will play both physical and digital Nintendo Switch games.'},\n",
       " {'label': 'TheGamer',\n",
       "  'short_url': 'https://www.thegamer.com/nintendo-switch-2-review/',\n",
       "  'value': 'The Nintendo Switch 2 is the successor to Nintendo Switch, scheduled for release on June 5, 2025. Confirmed as backwards compatible, it will play both physical and digital Nintendo Switch games.'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/05/pokemon-legends-z-a-secures-switch-and-switch-2-release-date',\n",
       "  'value': 'The Pokémon Company has surprised us all with the announcement that Pokémon Legends: Z-A will arrive on Switch and Switch 2 on 16th October 2025.'},\n",
       " {'label': 'Nintendo Everything',\n",
       "  'short_url': 'https://nintendoeverything.com/devils-third-interview-wii-u-tomonobu-itagaki/',\n",
       "  'value': \"Image 17: Famitsu's most wanted games - June 8, 2025 - Metroid Prime 4 - Nintendo Switch 2 Edition appears\"},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/nintendo-survey-asks-switch-2-users-about-their-experience-so-far',\n",
       "  'value': 'Image 92: Review: Mario Kart World (Switch 2) - The Perfect Introduction To A New Console Generation'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/rumble-has-been-turned-off-due-to-prolonged-use-dont-worry-your-switch-2-joy-con-probably-arent-broken',\n",
       "  'value': 'Review: Fast Fusion (Switch 2) - The Most Accomplish...'},\n",
       " {'label': 'Nintendo Life',\n",
       "  'short_url': 'https://www.nintendolife.com/news/2025/06/misc-a-tiny-tale-looks-super-smooth-on-switch-2-thanks-to-a-dev-hunch',\n",
       "  'value': \"'Misc. A Tiny Tale' Looks Super Smooth On Switch 2, Thanks To A Dev Hunch\"},\n",
       " {'label': 'Passionategeekz',\n",
       "  'short_url': 'https://www.instagram.com/p/DLBmSmMMW2R/',\n",
       "  'value': 'Nintendo Switch 2 game consoles were stolen, each worth about US$500 (Passionategeekz Note: the current exchange rate is about RMB 3594).'},\n",
       " {'label': 'TechRadar',\n",
       "  'short_url': 'https://www.techradar.com/gaming/nintendo/best-nintendo-switch-2-games',\n",
       "  'value': '\"The Legend of Zelda: Tears of the Kingdom leaps forward on what was offered in 2017’s Breath of the Wild, filling out the world’s sandbox with innovative new tools and abilities, letting you approach challenges in inventive new ways.\" - Julian Benson, TechRadar Gaming reviewer.'},\n",
       " {'label': 'ScreenRant',\n",
       "  'short_url': 'https://screenrant.com/nintendo-switch-2-review/',\n",
       "  'value': 'The Nintendo Switch 2 is the successor to Nintendo Switch, scheduled for release in 2025. Confirmed as backwards compatible, it will play both physical and digital Nintendo Switch games.'},\n",
       " {'label': 'TheGamer',\n",
       "  'short_url': 'https://www.thegamer.com/nintendo-switch-2-review/',\n",
       "  'value': 'The Nintendo Switch 2 is the successor to Nintendo Switch, scheduled for release on June 5, 2025. Confirmed as backwards compatible, it will play both physical and digital Nintendo Switch games.'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state['sources_gathered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923ac252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/pp1kndqj2vq4xbyb_12t2lqm0000gn/T/ipykernel_18419/3638439461.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from backend.src.agent.graph_v1 import graph\n"
     ]
    }
   ],
   "source": [
    "from backend.src.agent.graph_v1 import graph\n",
    "import os \n",
    "os.environ['HTTP_PROXY']=\"http://uxe2sgh:56178988zXV!@rb-proxy-unix-apac.bosch.com:8080\"\n",
    "os.environ['HTTPS_PROXY']=\"http://uxe2sgh:56178988zXV!@rb-proxy-unix-apac.bosch.com:8080\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624f6d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b78de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "{'think': \"\\nAnalyzing question: 'What is the capital of France?'. Determining if web search is necessary...\\n\"}\n",
      "{'think': '\\nQuestion can be answered directly without web search.\\n'}\n",
      "{'think': \"\\nProviding direct answer to: 'What is the capital of France?'\\n\"}\n",
      "{'think': '\\nGenerating direct answer using DeepSeek...\\n'}\n",
      "{'normal': \"\\nThe capital of France is **Paris**.  \\n\\nLet me know if you'd like more information about Paris or France!\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "async for event in graph.astream(input=inputs, stream_mode=\"custom\"):\n",
    "                print(event)\n",
    "                think_content = event.get(\"think\", None)\n",
    "                normal_content = event.get(\"normal\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "035cdd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the available specifications and performance metrics for both GPUs, here's a direct comparison:\n",
       "\n",
       "**NVIDIA GeForce RTX 5090 (Desktop GPU):**\n",
       "- **CUDA Cores:** 21,760 \n",
       "- **Memory:** 32GB GDDR7  \n",
       "- **Memory Bandwidth:** 1.34 TB/s  \n",
       "- **Architecture:** Blackwell (TSMC 3nm)  \n",
       "- **TDP:** 575 W  \n",
       "*(Sources: [TechPowerUp](NVIDIA GeForce RTX 5090 Features 575 W TDP, RTX 5080 Carries 360 W TDP), [TechPowerUp Specs](Memory Size 24 GB Memory Type GDDR7 Memory Bus 384 bit Bandwidth 1.34 TB/s), [GameMaxPC](The RTX 5090, built on NVIDIA's cutting-edge Blackwell architecture, ushers in a new era of gaming performance. Fabricated on TSMC's 3nm process, this monolithic marvel packs 92 billion transistors, 21,760 CUDA cores, and 680 fifth-generation Tensor Cores. Coupled with 32GB of GDDR7 memory (1,792GB/s bandwidth), it redefines the boundaries of compute density and energy efficiency.))*\n",
       "\n",
       "**Nintendo Switch 2 GPU (Custom Mobile Chip):**  \n",
       "- **CUDA Cores:** 1,536 (Ampere-based)  \n",
       "- **Performance:** 3.07 TFLOPs (docked mode)  \n",
       "- **Memory Bandwidth:** 102 GB/s (docked)  \n",
       "- **Clock Speeds:** Up to 1.4 GHz (theoretical max)  \n",
       "*(Sources: [Eurogamer](For the GPU, T239 features 1,536 CUDA cores based on Nvidia's Ampere architecture, as found in the RTX 30-series line of graphics cards, supporting machine learning and ray tracing. The GPU clocks at 561MHz in handheld mode, rising to 1007MHz in performance mode (typically for docked play). Constrained for thermal and battery life reasons, theoretically the GPU can max at 1.4GHz.), [AInvest](The Switch 2's hardware is its most compelling feature. Powered by NVIDIA's Tegra T239 SoC, the console boasts an octa-core ARM Cortex-A78C CPU and an Ampere GPU with 1,536 CUDA cores. This architecture delivers **3.07 TFLOPs of performance in docked mode**, a significant leap from the original Switch's 1.0 TFLOPs.))*\n",
       "\n",
       "### Performance Difference:\n",
       "1. **Theoretical Raw Power (TFLOPs):**  \n",
       "   - While the RTX 5090's exact TFLOPs aren't provided, its predecessor (RTX 4090) achieves ~82 TFLOPs. The RTX 5090's architectural improvements (Blackwell, 3nm) and increased CUDA cores suggest **at least 100+ TFLOPs**.  \n",
       "   - Switch 2: **3.07 TFLOPs** (docked).  \n",
       "   - **Estimated Difference:** The RTX 5090 is **roughly 30–35 times faster** in raw compute performance.  \n",
       "\n",
       "2. **Architectural & Feature Gap:**  \n",
       "   - The RTX 5090 uses GDDR7 memory with **13× higher bandwidth** (1.34 TB/s vs. 102 GB/s) and **14× more CUDA cores** (21,760 vs. 1,536).  \n",
       "   - It supports advanced ray tracing, DLSS 4, and is optimized for 4K/8K gaming, while the Switch 2 targets 1080p/4K with hybrid mobile constraints.  \n",
       "\n",
       "### Key Considerations:\n",
       "- **No Direct Benchmark Exists:** No official tests compare these GPUs directly, as they target entirely different platforms (desktop vs. handheld console) ([TechPowerUp](Surprise Reversal: GeForce RTX 5090 Found with Too Many ROPs, Matches RTX Pro 6000, +8% Performance)).  \n",
       "- **Real-World Gaming:** The RTX 5090 will deliver significantly higher frame rates and fidelity, but the Switch 2 is optimized for efficiency and portability.  \n",
       "\n",
       "### Conclusion:  \n",
       "Based on hardware specifications and architectural analysis, the **RTX 5090 is approximately 30–35 times faster** than the Switch 2 GPU in raw theoretical performance. Actual gaming performance differences will vary due to the Switch 2's game-specific optimizations and lower rendering targets.  \n",
       "\n",
       "*(All citations derived from provided summaries.)*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state['messages'][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a34829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here’s a comprehensive answer to your question about the current pricing of the RTX 5090 across different brands and regions as of June 2025:\n",
       "\n",
       "### **RTX 5090 Pricing by Brand (June 2025)**  \n",
       "1. **NVIDIA Founders Edition**: $1,599 ([TechRadar](The base model is priced at $1,599.))  \n",
       "2. **ASUS ROG Strix**: $1,699 ([Tom's Hardware](The ASUS variant is listed at $1,699.))  \n",
       "3. **MSI Gaming X Trio**: $1,649 ([PC Gamer](MSI's offering is priced at $1,649.))  \n",
       "4. **Gigabyte AORUS**: $1,679 ([AnandTech](The Gigabyte model is available for $1,679.))  \n",
       "\n",
       "### **Regional Pricing and Promotions**  \n",
       "- **North America**:  \n",
       "  - Founders Edition: $1,999  \n",
       "  - ASUS/MSI models: $2,099–$2,299  \n",
       "  - Newegg promotion: $100 discount on select models ([Newegg](Newegg is currently running a promotion with a $100 discount on select models.)).  \n",
       "\n",
       "- **Europe**:  \n",
       "  - Germany: Founders Edition at €2,199; MSI models with €150 discount ([Amazon Germany](Amazon Germany is offering a limited-time €150 discount on MSI models.)).  \n",
       "  - France: Founders Edition at €2,249.  \n",
       "\n",
       "- **Asia**:  \n",
       "  - Japan: Founders Edition at ¥320,000; discounts up to ¥20,000 at Bic Camera ([Bic Camera](In Japan, the RTX 5090 is priced at ¥320,000 for the Founders Edition, with discounts of up to ¥20,000 on select models at Bic Camera.)).  \n",
       "  - China: ¥14,999 with a ¥500 discount on JD.com ([JD.com](In China, the card is priced at ¥14,999, with JD.com offering a ¥500 discount for a limited time.)).  \n",
       "\n",
       "- **Australia**:  \n",
       "  - Founders Edition: AUD 3,299 with free game bundle at Scorptec ([Scorptec](Retailers like Scorptec offering a free game bundle with purchase.)).  \n",
       "\n",
       "### **Performance Comparison**  \n",
       "- **ASUS ROG Strix**: Highest performance (5–10% over Founders Edition) with triple-fan cooling ([Tom's Hardware](The ASUS variant is listed at $1,699.)).  \n",
       "- **MSI Gaming X Trio**: Quiet operation, slightly outperforms Founders Edition ([Guru3D](It offers competitive performance, slightly edging out the Founders Edition in synthetic benchmarks but trailing the ROG Strix in gaming performance.)).  \n",
       "- **Gigabyte AORUS**: Matches ASUS in clock speeds but louder under load ([AnandTech](The Gigabyte model is available for $1,679.)).  \n",
       "\n",
       "Prices and promotions are subject to change. For the latest updates, check retailer links or official brand pages.  \n",
       "\n",
       "**Citations**:  \n",
       "[TechRadar](The base model is priced at $1,599.), [Tom's Hardware](The ASUS variant is listed at $1,699.), [PC Gamer](MSI's offering is priced at $1,649.), [AnandTech](The Gigabyte model is available for $1,679.), [Newegg](Newegg is currently running a promotion with a $100 discount on select models.), [Amazon Germany](Amazon Germany is offering a limited-time €150 discount on MSI models.), [Bic Camera](In Japan, the RTX 5090 is priced at ¥320,000 for the Founders Edition, with discounts of up to ¥20,000 on select models at Bic Camera.), [JD.com](In China, the card is priced at ¥14,999, with JD.com offering a ¥500 discount for a limited time.), [Scorptec](Retailers like Scorptec offering a free game bundle with purchase.), [Guru3D](It offers competitive performance, slightly edging out the Founders Edition in synthetic benchmarks but trailing the ROG Strix in gaming performance.)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state['messages'][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef21ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, config_schema=Configuration)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "\n",
    "builder.add_edge(\"finalize_answer\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1fc64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'ModelMetaclass' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m web_searcher_instructions\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m     current_date\u001b[38;5;241m=\u001b[39mget_current_date(),\n\u001b[1;32m     17\u001b[0m     research_topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice of 5090\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39mformatted_prompt)]\n\u001b[0;32m---> 21\u001b[0m query_generation_response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     22\u001b[0m     messages,\n\u001b[1;32m     23\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[LLMGeneratedSearchQueries]\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m generated_queries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_generation_response\u001b[38;5;241m.\u001b[39mtool_calls:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    777\u001b[0m                 m,\n\u001b[1;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    781\u001b[0m             )\n\u001b[1;32m    782\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:891\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    888\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    889\u001b[0m     )\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m--> 891\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    892\u001b[0m generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:946\u001b[0m, in \u001b[0;36mBaseChatOpenAI._get_request_payload\u001b[0;34m(self, input_, stop, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m    945\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_responses_api(payload):\n\u001b[1;32m    947\u001b[0m     payload \u001b[38;5;241m=\u001b[39m _construct_responses_api_payload(messages, payload)\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:932\u001b[0m, in \u001b[0;36mBaseChatOpenAI._use_responses_api\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_responses_api\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _use_responses_api(payload)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2866\u001b[0m, in \u001b[0;36m_use_responses_api\u001b[0;34m(payload)\u001b[0m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_responses_api\u001b[39m(payload: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m-> 2866\u001b[0m     uses_builtin_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   2867\u001b[0m         _is_builtin_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2868\u001b[0m     )\n\u001b[1;32m   2869\u001b[0m     responses_only_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(uses_builtin_tools \u001b[38;5;129;01mor\u001b[39;00m responses_only_args\u001b[38;5;241m.\u001b[39mintersection(payload))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2867\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_responses_api\u001b[39m(payload: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2866\u001b[0m     uses_builtin_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m-> 2867\u001b[0m         _is_builtin_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2868\u001b[0m     )\n\u001b[1;32m   2869\u001b[0m     responses_only_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(uses_builtin_tools \u001b[38;5;129;01mor\u001b[39;00m responses_only_args\u001b[38;5;241m.\u001b[39mintersection(payload))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2862\u001b[0m, in \u001b[0;36m_is_builtin_tool\u001b[0;34m(tool)\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_builtin_tool\u001b[39m(tool: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool \u001b[38;5;129;01mand\u001b[39;00m tool[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'ModelMetaclass' is not iterable"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "class LLMGeneratedSearchQueries(BaseModel):\n",
    "    \"\"\"Schema for the LLM to generate a list of search queries.\"\"\"\n",
    "    search_queries: list[str] = Field(description=\"A list of search queries to find relevant information based on the research topic.\")\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "\n",
    "messages = [HumanMessage(content=formatted_prompt)]\n",
    "\n",
    "query_generation_response = llm.invoke(\n",
    "    messages,\n",
    "    tools=[LLMGeneratedSearchQueries]\n",
    ")\n",
    "\n",
    "generated_queries = []\n",
    "if query_generation_response.tool_calls:\n",
    "    for tool_call in query_generation_response.tool_calls:\n",
    "        if tool_call['name'] == LLMGeneratedSearchQueries.__name__:\n",
    "            generated_queries.extend(tool_call['args'].get('search_queries', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34382436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
