{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f633dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "\n",
    "# pass your API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or getpass(\n",
    "    \"Enter Google API Key: \"\n",
    ")\n",
    "# initialize our client\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a42bbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemini refers to a few different things, but most commonly it refers to **Google's large language model.** Here's a breakdown:\n",
       "\n",
       "**1. Gemini (The Google AI Model):**\n",
       "\n",
       "*   **What it is:** Gemini is a multimodal AI model developed by Google AI. It's designed to be Google's most capable and general AI model, surpassing previous models like LaMDA and PaLM.\n",
       "*   **Capabilities:** It can understand and generate text, images, audio, video, and code. This \"multimodal\" nature means it can process and understand information from various sources simultaneously. It's designed to be highly adaptable and perform well on a wide range of tasks.\n",
       "*   **Versions:** There are different versions of Gemini optimized for various use cases:\n",
       "    *   **Gemini Ultra:** The most powerful version, designed for highly complex tasks.\n",
       "    *   **Gemini Pro:** A more balanced version, suitable for a wide range of applications, including powering Google's Bard (now Gemini) chatbot.\n",
       "    *   **Gemini Nano:** A lightweight version designed to run on devices like smartphones and other edge devices.\n",
       "*   **Use Cases:** Gemini is being integrated into various Google products and services, including:\n",
       "    *   **Search:** Improving search results and providing more comprehensive answers.\n",
       "    *   **Gmail & Workspace:** Helping with email composition, summarizing documents, and generating ideas.\n",
       "    *   **Bard/Gemini Chatbot:** Providing more natural and helpful conversational AI.\n",
       "    *   **Coding:** Assisting developers with code generation, debugging, and understanding code.\n",
       "    *   **Creative Content:** Helping with writing, image generation, and other creative tasks.\n",
       "\n",
       "**2. Gemini (The Zodiac Sign):**\n",
       "\n",
       "*   In astrology, Gemini is the third sign of the zodiac, associated with people born between approximately May 21 and June 20. It's an air sign often associated with communication, curiosity, and adaptability.\n",
       "\n",
       "**3. Project Gemini (NASA):**\n",
       "\n",
       "*   In the 1960s, Project Gemini was a NASA human spaceflight program that served as a bridge between Project Mercury (the first US human spaceflight program) and Project Apollo (the program that landed humans on the Moon). Gemini developed techniques for rendezvous, docking, and spacewalking that were crucial for the success of Apollo.\n",
       "\n",
       "**In summary, when someone mentions \"Gemini\" today, they are most likely referring to the Google AI model.**  To avoid confusion, it's helpful to consider the context in which the word is used.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, contents='What is Gemini?'\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cc352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai.types import Tool, GoogleSearch\n",
    "\n",
    "search_tool = Tool(google_search=GoogleSearch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef846338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentConfig(http_options=None, system_instruction='You are a helpful assistant that provides up to date information to help the user in their research.', temperature=0.0, top_p=None, top_k=None, candidate_count=1, max_output_tokens=None, stop_sequences=None, response_logprobs=None, logprobs=None, presence_penalty=None, frequency_penalty=None, seed=None, response_mime_type=None, response_schema=None, routing_config=None, model_selection_config=None, safety_settings=None, tools=[Tool(retrieval=None, google_search=GoogleSearch(), google_search_retrieval=None, enterprise_web_search=None, google_maps=None, code_execution=None, function_declarations=None)], tool_config=None, labels=None, cached_content=None, response_modalities=['TEXT'], media_resolution=None, speech_config=None, audio_timestamp=None, automatic_function_calling=None, thinking_config=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.genai.types import GenerateContentConfig\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "config = GenerateContentConfig(\n",
    "    system_instruction=(\n",
    "        \"You are a helpful assistant that provides up to date information \"\n",
    "        \"to help the user in their research.\"\n",
    "    ),\n",
    "    tools=[search_tool],\n",
    "    response_modalities=[\"TEXT\"],\n",
    "    temperature=0.0,  # likely default\n",
    "    candidate_count=1,  # likely default\n",
    "\n",
    ")\n",
    "config\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=\"Tell me the latest news in AI\",\n",
    "    config=config\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9009a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer='The current price of the NVIDIA RTX 5090 is $1,999 as of June 2025, according to official NVIDIA pricing and retailer listings. This price reflects the base model, with potential variations based on custom designs from third-party manufacturers.' citations=[Citation(label='NVIDIA Official Website', source_id='https://www.nvidia.com', quote='The NVIDIA RTX 5090 is priced at $1,999 for the base model, as confirmed on our official product page.'), Citation(label='Tech Retailer', source_id='https://www.newegg.com', quote='Newegg lists the NVIDIA RTX 5090 at $1,999, with availability starting June 2025.')]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import Field\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List, Annotated, Literal, Dict, Union, Optional \n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    label: str = Field(\n",
    "        ...,\n",
    "        description=\"The name of the website.\",\n",
    "    )\n",
    "    source_id: str = Field(\n",
    "        ...,\n",
    "        description=\"The url of a SPECIFIC source which justifies the answer.\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        ...,\n",
    "        description=\"The VERBATIM quote from the specified source that justifies the answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and return all the sources used.\"\"\"\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources. Include any relevant sources in the answer as markdown hyperlinks. For example: 'This is a sample text ([url website](url))'\"\n",
    "    )\n",
    "    citations: List[Citation] = Field(\n",
    "        ..., description=\"Citations from the given sources that justify the answer.\"\n",
    "    )\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize Tavily Search Tool\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "structured_llm = llm.bind_tools([tavily_search_tool]).with_structured_output(QuotedAnswer)\n",
    "# agent = create_react_agent(llm, [tavily_search_tool])\n",
    "\n",
    "# user_input = \"What nation hosted the Euro 2024?\"\n",
    "user_input = \"current price of 5090\"\n",
    "# formatted_prompt = web_searcher_instructions.format(\n",
    "#     current_date=get_current_date(),\n",
    "#     research_topic='price of 5090',\n",
    "# )\n",
    "\n",
    "web_searcher_instructions = \"\"\"Use your search tool to conduct targeted Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
    "\n",
    "Instructions:\n",
    "- Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
    "- Conduct multiple, diverse searches to gather comprehensive information.\n",
    "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
    "- The output should be a well-written summary or report based on your search findings. \n",
    "- Only include the information found in the search results, don't make up any information.\n",
    "\n",
    "Research Topic:\n",
    "{research_topic}\n",
    "\"\"\"\n",
    "\n",
    "formatted_prompt = web_searcher_instructions.format(\n",
    "    current_date=get_current_date(),\n",
    "    research_topic=user_input,\n",
    ") + \"\\n\\nIMPORTANT: Use the search tool provided to find the most up-to-date information, and choose the right arguments for the search tool.\"\n",
    "\n",
    "\n",
    "# for step in agent.stream(\n",
    "#     {\"messages\": user_input},\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "result = structured_llm.invoke(formatted_prompt)\n",
    "web_research_result = result.answer + \"\\n---\\n\\n\".join([citation.source_id for citation in result.citations])\n",
    "for citation in result.citations:\n",
    "    citations_dict = {}\n",
    "    citations_dict['label'] = citation.label\n",
    "    citations_dict['short_url'] = citation.source_id\n",
    "    citations_dict['value'] = citation.quote\n",
    "    citations_list.append(citations_dict)\n",
    "\n",
    "# print(result)\n",
    "# https://github.com/tavily-ai/use-cases/blob/main/company-research/company_research.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f862b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Citation(label='NVIDIA Official Website', source_id='https://www.nvidia.com', quote='The NVIDIA RTX 5090 is priced at $1,999 for the base model, as confirmed on our official product page.'),\n",
       " Citation(label='Tech Retailer', source_id='https://www.newegg.com', quote='Newegg lists the NVIDIA RTX 5090 at $1,999, with availability starting June 2025.')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "web_research_result = result.answer + \"\\n---\\n\\n\".join([citation.source_id for citation in result.citations])\n",
    "for citation in result.citations:\n",
    "    citations_dict = {}\n",
    "    citations_dict['label'] = citation.label\n",
    "    citations_dict['short_url'] = citation.source_id\n",
    "    citations_dict['value'] = citation.quote\n",
    "    citations_list.append(citations_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba5de9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The current price of the NVIDIA GeForce RTX 5090, as of June 16, 2025, is not yet officially announced by NVIDIA. However, industry rumors and leaks suggest a potential price range of $1,800 to $2,000 based on speculation from tech analysts. For the most accurate and up-to-date information, it is recommended to check NVIDIA's official website or trusted tech news outlets.\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e7a25d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.newegg.com'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.citations[1].source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "faf0e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'search_query': ['Euro 2024 winner'],\n",
    "#  'web_research_result': [\"Based on the search results, here's a summary of the Euro 2024 winner:\\n\\n**Spain won Euro 2024**, defeating England 2-1 in the final held in Berlin on July 14, 2024. [olympics](https://vertexaisearch.cloud.google.com/id/0-0) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [uefa](https://vertexaisearch.cloud.google.com/id/0-2) [uefa](https://vertexaisearch.cloud.google.com/id/0-3) This victory marks Spain's record-breaking fourth European Championship title. [uefa](https://vertexaisearch.cloud.google.com/id/0-3) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [youtube](https://vertexaisearch.cloud.google.com/id/0-5) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-6) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) Spain won all seven of their matches during the tournament. [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) England has now lost back-to-back Euro finals. [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) The final score was 2-1. [olympics](https://vertexaisearch.cloud.google.com/id/0-0) [youtube](https://vertexaisearch.cloud.google.com/id/0-1) [uefa](https://vertexaisearch.cloud.google.com/id/0-2) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-6) [soccerway](https://vertexaisearch.cloud.google.com/id/0-8) [uefa](https://vertexaisearch.cloud.google.com/id/0-3) [aljazeera](https://vertexaisearch.cloud.google.com/id/0-4) [wikipedia](https://vertexaisearch.cloud.google.com/id/0-7) Nico Williams and Mikel Oyarzabal scored for Spain in the final. [youtube](https://vertexaisearch.cloud.google.com/id/0-1)\\n\"],\n",
    "#  'sources_gathered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e6f5369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Conduct targeted Google Searches to gather the most recent, credible information on \"price of 5090\" and synthesize it into a verifiable text artifact.\n",
      "\n",
      "Instructions:\n",
      "- Query should ensure that the most current information is gathered. The current date is June 13, 2025.\n",
      "- Conduct multiple, diverse searches to gather comprehensive information.\n",
      "- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
      "- The output should be a well-written summary or report based on your search findings. \n",
      "- Only include the information found in the search results, don't make up any information.\n",
      "\n",
      "Research Topic:\n",
      "price of 5090\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_6abbc5f6-fc30-455c-b0fc-453678cfd960)\n",
      " Call ID: call_0_6abbc5f6-fc30-455c-b0fc-453678cfd960\n",
      "  Args:\n",
      "    query: price of 5090 June 2025\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "  tavily_search (call_1_5230ad1b-97b7-4700-8577-b20c4d41e380)\n",
      " Call ID: call_1_5230ad1b-97b7-4700-8577-b20c4d41e380\n",
      "  Args:\n",
      "    query: 5090 product price latest update\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "  tavily_search (call_2_46647bad-6883-45a9-93e3-d9c81511a97a)\n",
      " Call ID: call_2_46647bad-6883-45a9-93e3-d9c81511a97a\n",
      "  Args:\n",
      "    query: 5090 cost June 2025\n",
      "    search_depth: advanced\n",
      "    time_range: week\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"5090 cost June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.extremetech.com/deals/best-graphics-card-gpu-deals\", \"title\": \"Best Graphics Card (GPU) Deals for June 2025 | Extremetech\", \"content\": \"Gigabyte GeForce RTX 5070 Graphics Card for $699.99 (list price $819.99). MSI GeForce RTX 5090 Trio Graphics Card for $3,305.60 (list price $3,968.99). EVGA\", \"score\": 0.83452857, \"raw_content\": null}, {\"url\": \"https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/\", \"title\": \"RTX 5090 is currently available for less than its MSRP at a popular ...\", \"content\": \"![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20503'%3E%3C/svg%3E)\\n![](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-MSRP-1024x503.jpg) [...] ![](https://www.pcguide.com/wp-content/uploads/2023/10/IMG_8117-96x96.jpg)\\n![RTX 5090 is currently available for less than its MSRP at a popular online retailer](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-available-for-less-than-MSRP.jpg)\\n\\n#### Table of Contents [...] ### [New upcoming RPG game is a mix of The Witcher 3 and Skyrim, and you can try it for free now](https://www.pcguide.com/news/new-upcoming-rpg-game-is-a-mix-of-the-witcher-3-and-skyrim-and-you-can-try-it-for-free-now/)\\n\\n![](https://www.pcguide.com/wp-content/uploads/2025/06/Zen-7.png)\", \"score\": 0.72019166, \"raw_content\": null}, {\"url\": \"https://www.amazon.com/MSI-GeForce-Gaming-28Gbps-512-bit/dp/B0DT6Q3BXM\", \"title\": \"MSI GeForce RTX 5090 32G Gaming Trio OC 32GB GDDR7 ...\", \"content\": \"Buy New. -18% $3,259.95$3,259.95. FREE delivery June 18 - 23. Ships from: Assurant Technologies. Sold by: Assurant Technologies · Return this item for free.\", \"score\": 0.6786044, \"raw_content\": null}, {\"url\": \"https://www.facebook.com/groups/ASUSPCDIY/posts/oh-look-a-price-drop-on-the-asus-rog-astral-geforce-rtx-5090-for-the-low-low-pri/23929610940028668/\", \"title\": \"Oh look, a price drop on the ASUS ROG Astral GeForce RTX 5090 ...\", \"content\": \"Oh look, a price drop on the ASUS ROG Astral GeForce RTX 5090 for the low-low price of $3359.99 (for Prime members). https://amzn.to/4jNesHq.\", \"score\": 0.657297, \"raw_content\": null}, {\"url\": \"https://sea.ign.com/hp-omen/228586/deal/grab-the-hp-omen-max-16-rtx-5090-gaming-laptop-for-an-incredible-price-update-another-big-price-drop\", \"title\": \"Grab the HP Omen Max 16 RTX 5090 Gaming Laptop for an ...\", \"content\": \"**Update:** The price has dropped yet again to $2,559.99 shipped.\\n\\n## HP Omen Max 16\\\" RTX 5090 Gaming Laptop for $2,559.99 [...] For a very limited time, HP is offering its newest and most powerful gaming laptop at a pretty hefty discount. The [Omen Max 16 GeForce RTX 5090 Gaming Laptop](https://zdcs.link/Q47vxk) drops to just $2,559.99 with free shipping when you apply 20% off coupon code \\\"**LEVELUP20**\\\". That is easily best price for an RTX 5090 gaming laptop anywhere by over $1,000. The RTX 5090 is currently the most powerful mobile GPU available with tons of VRAM and DLSS 4 support. [...] ![](https://www.facebook.com/tr?id=1337053969811135&ev=PageView)\\n![*](https://sb.scorecardresearch.com/p?c1=2&c2=3000068&c4=)\\n\\n### More\\n\\n![]()\\n\\n# Grab the HP Omen Max 16 RTX 5090 Gaming Laptop for an Incredible Price (Update: Another Big Price Drop)\\n\\n### Pick up HP's most power gaming laptop for just $2,560.\\n\\n![Eric Song](https://assets-prd.ignimgs.com/avatars/5899f7808f03070f86dd09fe/fish-1674247883206.jpg)\", \"score\": 0.65676886, \"raw_content\": null}], \"response_time\": 2.34}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is a synthesized report on the current pricing of the \"5090\" (assumed to be the NVIDIA GeForce RTX 5090 graphics card) as of June 13, 2025, based on credible sources:\n",
      "\n",
      "---\n",
      "\n",
      "### **Current Pricing of NVIDIA GeForce RTX 5090 (June 2025)**\n",
      "\n",
      "#### **1. Standalone Graphics Card Prices**\n",
      "- **MSI GeForce RTX 5090 Trio**:  \n",
      "  - **Price**: $3,305.60 (list price $3,968.99)  \n",
      "  - **Source**: [Extremetech](https://www.extremetech.com/deals/best-graphics-card-gpu-deals)  \n",
      "  - **Note**: This is a discounted price as of June 2025.\n",
      "\n",
      "- **PNY GeForce RTX 5090**:  \n",
      "  - **Price**: $1,679.99 (discounted from $3,199.99 at Walmart)  \n",
      "  - **Source**: [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since)  \n",
      "  - **Note**: A rare discount, with the card reportedly working flawlessly.\n",
      "\n",
      "- **Zotac Nvidia GeForce RTX 5090 SOLID 32GB**:  \n",
      "  - **Price**: £1,874.99 (below MSRP of £1,889)  \n",
      "  - **Source**: [PCGuide](https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/)  \n",
      "  - **Note**: Partner models typically cost more, making this a solid deal.\n",
      "\n",
      "- **MSI RTX 5090 Gaming Trio OC**:  \n",
      "  - **Price**: $3,259.95 (Amazon)  \n",
      "  - **Source**: [Amazon](https://www.amazon.com/MSI-GeForce-Gaming-28Gbps-512-bit/dp/B0DT6Q3BXM)  \n",
      "\n",
      "#### **2. Special Editions and Auctions**\n",
      "- **ASUS ROG Astral GeForce RTX 5090 Dhahab OC Edition**:  \n",
      "  - **Price**: $22,990 (gold-plated, sold on eBay)  \n",
      "  - **Source**: [HotHardware](https://hothardware.com/news/gold-plateted-geforce-rtx-5090-23k)  \n",
      "\n",
      "#### **3. Laptops Featuring RTX 5090**\n",
      "- **Lenovo Legion Pro 7i (RTX 5090 + Core Ultra 9 275HX)**:  \n",
      "  - **Price**: $3,699 (down from MSRP)  \n",
      "  - **Source**: [NotebookCheck](https://www.notebookcheck.net/2025-Lenovo-Legion-Pro-7i-with-RTX-5090-and-Core-Ultra-9-275HX-gets-another-price-cut.1033540.0.html)  \n",
      "\n",
      "- **HP Omen Max 16 (RTX 5090)**:  \n",
      "  - **Price**: $2,559.99 (with coupon code \"LEVELUP20\")  \n",
      "  - **Source**: [IGN](https://sea.ign.com/hp-omen/228586/deal/grab-the-hp-omen-max-16-rtx-5090-gaming-laptop-for-an-incredible-price-update-another-big-price-drop)  \n",
      "\n",
      "---\n",
      "\n",
      "### **Key Takeaways**\n",
      "- The **standalone RTX 5090** prices range from **$1,679.99 (discounted)** to **$3,305.60 (MSRP)**.\n",
      "- **Special editions** like the gold-plated ASUS model can fetch exorbitant prices (e.g., $22,990).\n",
      "- **Laptops with RTX 5090** are available for as low as **$2,559.99**, offering significant savings compared to standalone GPUs.\n",
      "\n",
      "### **Verifiable Sources**\n",
      "1. [Extremetech](https://www.extremetech.com/deals/best-graphics-card-gpu-deals)  \n",
      "2. [Tom's Hardware](https://www.tomshardware.com)  \n",
      "3. [PCGuide](https://www.pcguide.com)  \n",
      "4. [Amazon](https://www.amazon.com)  \n",
      "5. [HotHardware](https://hothardware.com)  \n",
      "6. [NotebookCheck](https://www.notebookcheck.net)  \n",
      "7. [IGN](https://sea.ign.com)  \n",
      "\n",
      "This report consolidates the latest and most credible pricing information available as of June 2025. Prices are subject to change based on retailer promotions and availability.\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "from backend.src.agent.prompts import (\n",
    "    get_current_date,\n",
    "    query_writer_instructions,\n",
    "    web_searcher_instructions,\n",
    "    reflection_instructions,\n",
    "    answer_instructions,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "# Create a ReAct agent with the web searcher system prompt and Tavily search tool\n",
    "formatted_prompt = web_searcher_instructions.format(\n",
    "    current_date=get_current_date(),\n",
    "    research_topic='price of 5090',\n",
    ")\n",
    "tavily_search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "# Create the agent with the formatted prompt as system message\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    [tavily_search_tool],\n",
    "    \n",
    ")\n",
    "prompt=formatted_prompt\n",
    "# Create a runnable chain from the agent\n",
    "# search_chain = agent.get_chain()\n",
    "\n",
    "# agent.invoke({\"messages\": [HumanMessage(content=\"What is the price of 5090?\")]}).pretty_print()\n",
    "\n",
    "# user_input = \"What is the price of 5090?\"\n",
    "# response = agent.invoke({\"messages\": prompt})\n",
    "for step in agent.stream(\n",
    "    {\"messages\": prompt},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b97f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Conduct targeted Google Searches to gather the most recent, credible information on \"price of 5090\" and synthesize it into a verifiable text artifact.\\n\\nInstructions:\\n- Query should ensure that the most current information is gathered. The current date is June 13, 2025.\\n- Conduct multiple, diverse searches to gather comprehensive information.\\n- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\\n- The output should be a well-written summary or report based on your search findings. \\n- Only include the information found in the search results, don\\'t make up any information.\\n\\nResearch Topic:\\nprice of 5090\\n', additional_kwargs={}, response_metadata={}, id='25a1015f-d63a-4ae0-a427-adeef3aa5299'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_6abbc5f6-fc30-455c-b0fc-453678cfd960', 'function': {'arguments': '{\"query\": \"price of 5090 June 2025\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}, {'id': 'call_1_5230ad1b-97b7-4700-8577-b20c4d41e380', 'function': {'arguments': '{\"query\": \"5090 product price latest update\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 1}, {'id': 'call_2_46647bad-6883-45a9-93e3-d9c81511a97a', 'function': {'arguments': '{\"query\": \"5090 cost June 2025\", \"search_depth\": \"advanced\", \"time_range\": \"week\"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 2}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 1371, 'total_tokens': 1493, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1280}, 'prompt_cache_hit_tokens': 1280, 'prompt_cache_miss_tokens': 91}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--76d1e3b9-a8ee-42fd-8d96-3b59e9943b3a-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'price of 5090 June 2025', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_0_6abbc5f6-fc30-455c-b0fc-453678cfd960', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': '5090 product price latest update', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_1_5230ad1b-97b7-4700-8577-b20c4d41e380', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': '5090 cost June 2025', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 'call_2_46647bad-6883-45a9-93e3-d9c81511a97a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1371, 'output_tokens': 122, 'total_tokens': 1493, 'input_token_details': {'cache_read': 1280}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='{\"query\": \"price of 5090 June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.extremetech.com/deals/best-graphics-card-gpu-deals\", \"title\": \"Best Graphics Card (GPU) Deals for June 2025 | Extremetech\", \"content\": \"Gigabyte GeForce RTX 5070 Graphics Card for $699.99 (list price $819.99). MSI GeForce RTX 5090 Trio Graphics Card for $3,305.60 (list price $3,968.99). EVGA\", \"score\": 0.8335554, \"raw_content\": null}, {\"url\": \"https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since\", \"title\": \"Cheapest 5090 ever? Lucky PC builder finds RTX 5090 for \\'just ...\", \"content\": \"Published Time: 2025-06-06T12:14:31+00:00\\\\n\\\\nCheapest 5090 ever? Lucky PC builder finds RTX 5090 for \\'just\\' $1,679 at Walmart, saving $1,520 — card has worked \\'flawlessly\\' ever since | Tom\\'s Hardware\\\\n\\\\n===============\\\\n[Skip to main content](https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since#main)\\\\n\\\\nOpen menu Close menu \\\\n\\\\n[Tom\\'s Hardware](https://www.tomshardware.com/) [...] Redditor Sufficient_Crazy7758 took to the platform to hail their purchase of the \\\\\"Cheapest 5090 ever?\\\\\", after scooping a PNY GeForce RTX 5090 from Walmart for the relatively low price of $1,679.99. The attached images reveal that the card was discounted by over $1,500 on May 25, having previously been discounted on May 13.\\\\n\\\\n\\\\\"Just so all of you know, I bought this on that date and it has worked flawlessly ever since,\\\\\" they said triumphantly.\\\\n\\\\nLatest Videos From Tom\\'s Hardware [...] even the [Founders Edition still retails for the same price](https://goto.walmart.com/c/1943169/565706/9383?subId1=tomshardware-us-9626551282836866081&sharedId=tomshardware-us&u=https%3A%2F%2Fwww.walmart.com%2Fip%2FNVIDIA-GeForce-RTX-5090-Graphic-Card-32GB-GDDR7%2F15176552726%3FclassType%3DREGULAR%26from%3D%2Fsearch), way over the $1,999 MSRP.\", \"score\": 0.7703443, \"raw_content\": null}, {\"url\": \"https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/\", \"title\": \"RTX 5090 is currently available for less than its MSRP at a popular ...\", \"content\": \"![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%201024%20503\\'%3E%3C/svg%3E)\\\\n![](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-MSRP-1024x503.jpg) [...] ![](https://www.pcguide.com/wp-content/uploads/2023/10/IMG_8117-96x96.jpg)\\\\n![RTX 5090 is currently available for less than its MSRP at a popular online retailer](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-available-for-less-than-MSRP.jpg)\\\\n\\\\n#### Table of Contents [...] £1,969.99](https://www.scan.co.uk/products/nda-zotac-nvidia-geforce-rtx-5090-solid-oc-32gb-gddr7-graphics-card). Although these prices are a bit above MSRP, they\\'re still reasonable considering how much it was being sold for a while ago. This pricing will definitely allow gamers to upgrade their setups without worrying about paying extra for the card. However, it\\'s unclear how long these prices will last. So if you’re planning to buy one, it\\'s best to act fast. [Nvidia is also giving away two\", \"score\": 0.72418857, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=rxk_JL-lRVk\", \"title\": \"MSI RTX 5090 Hits Lowest-Ever Price on Amazon! (June 2025 Deal ...\", \"content\": \"MSI RTX 5090 Lowest Price Alert on Amazon! Looking for the MSI Gaming RTX 5090 32G Gaming Trio? Great news—it\\'s at its lowest-ever price right now on\", \"score\": 0.71758664, \"raw_content\": null}, {\"url\": \"https://www.notebookcheck.net/2025-Lenovo-Legion-Pro-7i-with-RTX-5090-and-Core-Ultra-9-275HX-gets-another-price-cut.1033540.0.html\", \"title\": \"2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX ...\", \"content\": \"Published Time: 2025-06-09T22:38:00+02:00\\\\n\\\\n2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX gets another price cut - NotebookCheck.net News\\\\n\\\\n===============\\\\n\\\\n[![Image 1: Notebookcheck Logo](https://www.notebookcheck.net/fileadmin/templates/nbc_v5/images/logo_alone_header.svg)![Image 2: Notebookcheck Logo](https://www.notebookcheck.net/fileadmin/templates/nbc_v5/images/logo_simplified_unicolor_t.svg)](https://www.notebookcheck.net/ \\\\\"Notebookcheck Home\\\\\") [...] >[Expert Reviews and News on Laptops, Smartphones and Tech Innovations](https://www.notebookcheck.net/Expert-Reviews-and-News-on-Laptops-Smartphones-and-Tech-Innovations.48.0.html)>[News](https://www.notebookcheck.net/News.152.0.html)>[News Archive](https://www.notebookcheck.net/News-Archive.45592.0.html)>[Newsarchive 2025 06](https://www.notebookcheck.net/Newsarchive-2025-06.1028223.0.html)> 2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX gets another price cut [...] Laptop](https://www.notebookcheck.net/Nvidia-GeForce-RTX-5090-Laptop-Benchmarks-and-Specs.934947.0.html) GPU, the New York City-based retailer [B&H Photo Video](https://www.bhphotovideo.com/c/product/1875947-REG/lenovo_83f50018us_16_legion_pro_7i.html) has now undercut that deal by another $100 and is selling the gaming laptop for $3,699 including free shipping. This results in savings of roughly 7% compared to MSRP. On top of that, this particular configuration of Lenovo\\'s 16-inch machine has\", \"score\": 0.6947383, \"raw_content\": null}], \"response_time\": 2.7}', name='tavily_search', id='34adf8ca-1433-4f0d-a80e-7f74e1b04b45', tool_call_id='call_0_6abbc5f6-fc30-455c-b0fc-453678cfd960'),\n",
       "  ToolMessage(content='{\"query\": \"5090 product price latest update\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.tweaktown.com/news/105759/asuss-gold-rog-astral-geforce-rtx-5090-charity-auction-enters-final-day-with-20k-highest-bid/index.html\", \"title\": \"ASUS\\'s gold ROG ASTRAL GeForce RTX 5090 charity auction ...\", \"content\": \"ASUS GeForce RTX 5090, RTX 5080 launch pricing is here: ROG Astral PC RTX 5090 costs $3099 ... news, fresh reviews, and the latest updates - delivered straight to\", \"score\": 0.7672197, \"raw_content\": null}, {\"url\": \"https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/\", \"title\": \"RTX 5090 is currently available for less than its MSRP at a popular ...\", \"content\": \"If you head over to SCAN’s official website, you’ll find the [Zotac Nvidia GeForce RTX 5090 SOLID 32GB listed for £1,874.99](https://www.scan.co.uk/products/nda-zotac-nvidia-geforce-rtx-5090-solid-32gb-gddr7-graphics-card). It was previously available for £1,928.99, but thanks to an ongoing discount, you can save £54. This brings the price below the MSRP of £1,889 for the Founders Edition. Partner models usually cost more due to extra features, so this is a solid deal. [...] £1,969.99](https://www.scan.co.uk/products/nda-zotac-nvidia-geforce-rtx-5090-solid-oc-32gb-gddr7-graphics-card). Although these prices are a bit above MSRP, they\\'re still reasonable considering how much it was being sold for a while ago. This pricing will definitely allow gamers to upgrade their setups without worrying about paying extra for the card. However, it\\'s unclear how long these prices will last. So if you’re planning to buy one, it\\'s best to act fast. [Nvidia is also giving away two [...] Aside from that, three other RTX 5090 models are also listed at decent prices. The [MSI RTX 5090 Ventus 3X OC](https://www.scan.co.uk/products/msi-nvidia-geforce-rtx-5090-ventus-3x-oc-32gb-gddr7-ray-tracing-graphics-card-21760-core-2437-mhz) and [Palit RTX 5090 Gamerock ARGB are listed for £1,939.99](https://www.scan.co.uk/products/palit-nvidia-geforce-rtx-5090-gamerock-argb-32gb-gddr7-ray-tracing-graphics-card-dlss-4-21760-core-2), while the [Zotac RTX 5090 SOLID OC is available for\", \"score\": 0.6747586, \"raw_content\": null}, {\"url\": \"https://www.pcgamesn.com/nvidia/rog-astral-geforce-rtx-5090-dhahab-scalpers\", \"title\": \"Scalpers now want $23,000 for this gold Nvidia GeForce RTX 5090 ...\", \"content\": \"This gaudy Nvidia RTX 5090 contains 24-carat gold, but was only sold in the Middle East. Now, scalpers are selling it on eBay for $23,000.\", \"score\": 0.66308063, \"raw_content\": null}, {\"url\": \"https://www.amazon.com/MSI-GeForce-Gaming-28Gbps-512-bit/dp/B0DT6Q3BXM\", \"title\": \"MSI GeForce RTX 5090 32G Gaming Trio OC 32GB GDDR7 ...\", \"content\": \"Buy New. -18% $3,259.95$3,259.95. FREE delivery June 18 - 23. Ships from: Assurant Technologies. Sold by: Assurant Technologies · Return this item for free.\", \"score\": 0.6041426, \"raw_content\": null}, {\"url\": \"https://hothardware.com/news/gold-plateted-geforce-rtx-5090-23k\", \"title\": \"Want A Gold-Plated GeForce RTX 5090? Get Ready To Spend Up ...\", \"content\": \"![ASUS ROG Astral GeForce RTX 5090 Dhahab OC Edition card listed on eBay for $22,990.](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)\\\\n![Comments](/content/images/comments.svg)\\\\n![Support Independent Tech Journalism, Become A Patron!](/content/images/become-a-patron.svg) [...] |  |  |  |\\\\n| --- | --- | --- |\\\\n| [Search allLook for all](#)   * [All](javascript:hhsSetArea(\\'all\\')) * [News](javascript:hhsSetArea(\\'news\\')) * [Features](javascript:hhsSetArea(\\'features\\')) * [Blogs](javascript:hhsSetArea(\\'blogs\\')) |  |  |\\\\n\\\\n![Look for all](/content/images/down-arrow-srch.gif)\\\\n![Home](/content/images/nav-home.png)\\\\n![Support Independent Tech Journalism, Become A Patron!](/content/images/patreon-btn.svg)\\\\n\\\\n# Want A Gold-Plated GeForce RTX 5090? Get Ready To Spend Up To $23K [...] /+uj+vk7S2+H+4rH/46P/13b9xG/4iRL/2Yj+0YD7r0n8qzr7kgT+rSH3ix3/0GX/xVNrhbfWAAAAyXRSTlMA1Q4cBAQfGSkKBv5Wdfz8DA79/lX+/hAK/vMV/A0aBvxmCCjcVxcaE/7jxpbAuUg5QDcT/vfq5J0Ob1IjIhYUp39NTC388+20iYV8Y0QeHvbRqIltUSz27a92bF8n+9C+uJuPj35lYF1dUkQ0Lxzg3NHLy6qah21bVTYx5t/IrqSgnpV4Xkb799zYsZB2Evrx7OfDuJpvZWVYP/vt6tzWwLKuqJ5xQfDw0Jl6NPHx782fnm1aS+vh17ePfXr9+ubXp55RPzHnrnvuAjXoAAAOeUlEQVRYw8yVd0wTURjAPzX3HzmTljO9JtBq29TDQSsuikZFCS6kCiIuQI3iRkVUXLjFFfeMcY9o3MY9Ypy5Xm3vajlsra2xKA4MuOcffq+OqjFR/1D50d77vr772l++93gHP2GJvid\", \"score\": 0.56719416, \"raw_content\": null}], \"response_time\": 3.99}', name='tavily_search', id='d02b5dd4-84cf-401c-9a3b-9533a8a72350', tool_call_id='call_1_5230ad1b-97b7-4700-8577-b20c4d41e380'),\n",
       "  ToolMessage(content='{\"query\": \"5090 cost June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.extremetech.com/deals/best-graphics-card-gpu-deals\", \"title\": \"Best Graphics Card (GPU) Deals for June 2025 | Extremetech\", \"content\": \"Gigabyte GeForce RTX 5070 Graphics Card for $699.99 (list price $819.99). MSI GeForce RTX 5090 Trio Graphics Card for $3,305.60 (list price $3,968.99). EVGA\", \"score\": 0.83452857, \"raw_content\": null}, {\"url\": \"https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/\", \"title\": \"RTX 5090 is currently available for less than its MSRP at a popular ...\", \"content\": \"![](data:image/svg+xml,%3Csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20viewBox=\\'0%200%201024%20503\\'%3E%3C/svg%3E)\\\\n![](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-MSRP-1024x503.jpg) [...] ![](https://www.pcguide.com/wp-content/uploads/2023/10/IMG_8117-96x96.jpg)\\\\n![RTX 5090 is currently available for less than its MSRP at a popular online retailer](https://www.pcguide.com/wp-content/uploads/2025/06/RTX-5090-available-for-less-than-MSRP.jpg)\\\\n\\\\n#### Table of Contents [...] ### [New upcoming RPG game is a mix of The Witcher 3 and Skyrim, and you can try it for free now](https://www.pcguide.com/news/new-upcoming-rpg-game-is-a-mix-of-the-witcher-3-and-skyrim-and-you-can-try-it-for-free-now/)\\\\n\\\\n![](https://www.pcguide.com/wp-content/uploads/2025/06/Zen-7.png)\", \"score\": 0.72019166, \"raw_content\": null}, {\"url\": \"https://www.amazon.com/MSI-GeForce-Gaming-28Gbps-512-bit/dp/B0DT6Q3BXM\", \"title\": \"MSI GeForce RTX 5090 32G Gaming Trio OC 32GB GDDR7 ...\", \"content\": \"Buy New. -18% $3,259.95$3,259.95. FREE delivery June 18 - 23. Ships from: Assurant Technologies. Sold by: Assurant Technologies · Return this item for free.\", \"score\": 0.6786044, \"raw_content\": null}, {\"url\": \"https://www.facebook.com/groups/ASUSPCDIY/posts/oh-look-a-price-drop-on-the-asus-rog-astral-geforce-rtx-5090-for-the-low-low-pri/23929610940028668/\", \"title\": \"Oh look, a price drop on the ASUS ROG Astral GeForce RTX 5090 ...\", \"content\": \"Oh look, a price drop on the ASUS ROG Astral GeForce RTX 5090 for the low-low price of $3359.99 (for Prime members). https://amzn.to/4jNesHq.\", \"score\": 0.657297, \"raw_content\": null}, {\"url\": \"https://sea.ign.com/hp-omen/228586/deal/grab-the-hp-omen-max-16-rtx-5090-gaming-laptop-for-an-incredible-price-update-another-big-price-drop\", \"title\": \"Grab the HP Omen Max 16 RTX 5090 Gaming Laptop for an ...\", \"content\": \"**Update:** The price has dropped yet again to $2,559.99 shipped.\\\\n\\\\n## HP Omen Max 16\\\\\" RTX 5090 Gaming Laptop for $2,559.99 [...] For a very limited time, HP is offering its newest and most powerful gaming laptop at a pretty hefty discount. The [Omen Max 16 GeForce RTX 5090 Gaming Laptop](https://zdcs.link/Q47vxk) drops to just $2,559.99 with free shipping when you apply 20% off coupon code \\\\\"**LEVELUP20**\\\\\". That is easily best price for an RTX 5090 gaming laptop anywhere by over $1,000. The RTX 5090 is currently the most powerful mobile GPU available with tons of VRAM and DLSS 4 support. [...] ![](https://www.facebook.com/tr?id=1337053969811135&ev=PageView)\\\\n![*](https://sb.scorecardresearch.com/p?c1=2&c2=3000068&c4=)\\\\n\\\\n### More\\\\n\\\\n![]()\\\\n\\\\n# Grab the HP Omen Max 16 RTX 5090 Gaming Laptop for an Incredible Price (Update: Another Big Price Drop)\\\\n\\\\n### Pick up HP\\'s most power gaming laptop for just $2,560.\\\\n\\\\n![Eric Song](https://assets-prd.ignimgs.com/avatars/5899f7808f03070f86dd09fe/fish-1674247883206.jpg)\", \"score\": 0.65676886, \"raw_content\": null}], \"response_time\": 2.34}', name='tavily_search', id='1f3e7e37-37cf-4f23-972c-d009647a0563', tool_call_id='call_2_46647bad-6883-45a9-93e3-d9c81511a97a'),\n",
       "  AIMessage(content='Here is a synthesized report on the current pricing of the \"5090\" (assumed to be the NVIDIA GeForce RTX 5090 graphics card) as of June 13, 2025, based on credible sources:\\n\\n---\\n\\n### **Current Pricing of NVIDIA GeForce RTX 5090 (June 2025)**\\n\\n#### **1. Standalone Graphics Card Prices**\\n- **MSI GeForce RTX 5090 Trio**:  \\n  - **Price**: $3,305.60 (list price $3,968.99)  \\n  - **Source**: [Extremetech](https://www.extremetech.com/deals/best-graphics-card-gpu-deals)  \\n  - **Note**: This is a discounted price as of June 2025.\\n\\n- **PNY GeForce RTX 5090**:  \\n  - **Price**: $1,679.99 (discounted from $3,199.99 at Walmart)  \\n  - **Source**: [Tom\\'s Hardware](https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since)  \\n  - **Note**: A rare discount, with the card reportedly working flawlessly.\\n\\n- **Zotac Nvidia GeForce RTX 5090 SOLID 32GB**:  \\n  - **Price**: £1,874.99 (below MSRP of £1,889)  \\n  - **Source**: [PCGuide](https://www.pcguide.com/news/rtx-5090-is-currently-available-for-less-than-its-msrp-at-a-popular-online-retailer/)  \\n  - **Note**: Partner models typically cost more, making this a solid deal.\\n\\n- **MSI RTX 5090 Gaming Trio OC**:  \\n  - **Price**: $3,259.95 (Amazon)  \\n  - **Source**: [Amazon](https://www.amazon.com/MSI-GeForce-Gaming-28Gbps-512-bit/dp/B0DT6Q3BXM)  \\n\\n#### **2. Special Editions and Auctions**\\n- **ASUS ROG Astral GeForce RTX 5090 Dhahab OC Edition**:  \\n  - **Price**: $22,990 (gold-plated, sold on eBay)  \\n  - **Source**: [HotHardware](https://hothardware.com/news/gold-plateted-geforce-rtx-5090-23k)  \\n\\n#### **3. Laptops Featuring RTX 5090**\\n- **Lenovo Legion Pro 7i (RTX 5090 + Core Ultra 9 275HX)**:  \\n  - **Price**: $3,699 (down from MSRP)  \\n  - **Source**: [NotebookCheck](https://www.notebookcheck.net/2025-Lenovo-Legion-Pro-7i-with-RTX-5090-and-Core-Ultra-9-275HX-gets-another-price-cut.1033540.0.html)  \\n\\n- **HP Omen Max 16 (RTX 5090)**:  \\n  - **Price**: $2,559.99 (with coupon code \"LEVELUP20\")  \\n  - **Source**: [IGN](https://sea.ign.com/hp-omen/228586/deal/grab-the-hp-omen-max-16-rtx-5090-gaming-laptop-for-an-incredible-price-update-another-big-price-drop)  \\n\\n---\\n\\n### **Key Takeaways**\\n- The **standalone RTX 5090** prices range from **$1,679.99 (discounted)** to **$3,305.60 (MSRP)**.\\n- **Special editions** like the gold-plated ASUS model can fetch exorbitant prices (e.g., $22,990).\\n- **Laptops with RTX 5090** are available for as low as **$2,559.99**, offering significant savings compared to standalone GPUs.\\n\\n### **Verifiable Sources**\\n1. [Extremetech](https://www.extremetech.com/deals/best-graphics-card-gpu-deals)  \\n2. [Tom\\'s Hardware](https://www.tomshardware.com)  \\n3. [PCGuide](https://www.pcguide.com)  \\n4. [Amazon](https://www.amazon.com)  \\n5. [HotHardware](https://hothardware.com)  \\n6. [NotebookCheck](https://www.notebookcheck.net)  \\n7. [IGN](https://sea.ign.com)  \\n\\nThis report consolidates the latest and most credible pricing information available as of June 2025. Prices are subject to change based on retailer promotions and availability.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1035, 'prompt_tokens': 6183, 'total_tokens': 7218, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1472}, 'prompt_cache_hit_tokens': 1472, 'prompt_cache_miss_tokens': 4711}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None}, id='run--57d1e9fc-5163-4d61-a169-032a604d4319-0', usage_metadata={'input_tokens': 6183, 'output_tokens': 1035, 'total_tokens': 7218, 'input_token_details': {'cache_read': 1472}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a53d7a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"query\": \"latest updates on RTX 5090 pricing June 2025\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://x.com/USRestocks/status/1932361271782863013\", \"title\": \"US Restocks RTX5090/60/60Ti § Switch2\", \"content\": \"RTX 5090 in Stock! | Cart Link: https://amzn.to/4bPc14X June 10, 2025 at 01:56AM PT #ad MSI Gaming RTX 5090 32G Gaming Trio OC Graphics Card (32GB GDDR7,\", \"score\": 0.79254496, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=l641VkblkfY\", \"title\": \"Best GPUs to Buy for Gaming RIGHT NOW! [June/July 2025]\", \"content\": \"Newegg (US) [PAID LINKS]:\\nB570: https://newegg.io/nc0f72caf3\\nB580: https://newegg.io/ncb8aa2818\\nRTX 5060: https://newegg.io/nc2d2d6cb4\\nRTX 5060 Ti 16GB: https://newegg.io/nce151063f\\nRX 9070: https://newegg.io/nc6c904af2\\nRTX 5070 Ti: https://newegg.io/ncc8d843aa\\nRX 9070 XT: https://newegg.io/ncd7924039\\nRTX 5080: https://newegg.io/nc45487d71\\nRTX 5090: https://newegg.io/nc60c8042e [...] Amazon (UK) [PAID LINKS]:\\nB570: https://amzlink.to/az0zJQpeqq2Js\\nB580: https://amzlink.to/az0LAlIxFBfKo\\nRTX 5060: https://amzlink.to/az0hIVbEZrI6B\\nRTX 5060 Ti 16GB: https://amzlink.to/az0HkaR5MIpvR\\nRX 9070: https://amzlink.to/az0syS72HTuPw\\nRTX 5070 Ti: https://amzlink.to/az0pZ6PXayEAU\\nRX 9070 XT: https://amzlink.to/az0LwqrQy9bK1\\nRTX 5080: https://amzlink.to/az0n4hQDRq9rx\\nRTX 5090: https://amzlink.to/az0HXuNlzKZWX [...] Amazon (US) [PAID LINKS]:\\nB570: https://amzlink.to/az0HOxxNV4OF8\\nB580: https://amzlink.to/az0u4cH6r0fB2\\nRTX 5060: https://amzlink.to/az0zbM77NOV2Z\\nRTX 5060 Ti 16GB: https://amzlink.to/az0YZkOnMFXY3\\nRX 9070: https://amzlink.to/az03UwkWLMGmH\\nRTX 5070 Ti: https://amzlink.to/az0AItZVPbPNO\\nRX 9070 XT: https://amzlink.to/az0oOI9UxwEay\\nRTX 5080: https://amzlink.to/az0SSNK8AQuzo\\nRTX 5090: https://amzlink.to/az0aj8ecrctEC\", \"score\": 0.73023266, \"raw_content\": null}, {\"url\": \"https://en.gamegpu.com/iron/msi-and-gigabyte-are-delaying-rtx-5090-deliveries-to-susa-until-power-rates-are-up-by-july-9\", \"title\": \"MSI and Gigabyte RTX 5090 Shipments to US Ahead of Tariffs ...\", \"content\": \"# MSI and Gigabyte RTX 5090 Shipments to US Ahead of Tariffs Coming into Effect on July 9\\n\\nAuthor [Maximum Games](https://en.gamegpu.com/view-user-profile?user=41287), 10 2025 June. Published in [Hardware](/backgammon/news/iron/) [...] ![rtx 5090 gigabyte](https://gamegpu.com/images/1_2025/NEWS/q2/f123/9600/rtx_5090_gigabyte.jpg)\\n\\n![rtx 5090 gigabyte](https://gamegpu.com/images/1_2025/NEWS/q2/f123/9600/rtx_5090_gigabyte.jpg) [...] Experts suggest that **NVIDIA's AIB Partners Will Hold Back RTX 5090 Stock**, waiting for the official return of tariffs. This will give the opportunity to raise prices after the deadline if agreements between the countries are not reached. A similar scheme was used in 2016-2017, when companies massively imported video cards before the start of trade restrictions. **RTX 5090 Availability May Worsen in July**, especially if tariffs are reintroduced and companies decide to pass the costs on to\", \"score\": 0.65173227, \"raw_content\": null}, {\"url\": \"https://www.notebookcheck.net/2025-Lenovo-Legion-Pro-7i-with-RTX-5090-and-Core-Ultra-9-275HX-gets-another-price-cut.1033540.0.html\", \"title\": \"2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX ...\", \"content\": \"Deal | 2025 Lenovo Legion Pro 7i with RTX 5090 and Core Ultra 9 275HX gets another price cut ... It goes without saying that the top-end RTX 5090 configuration of\", \"score\": 0.64719695, \"raw_content\": null}, {\"url\": \"https://www.tomshardware.com/pc-components/gpus/cheapest-5090-ever-lucky-pc-builder-finds-rtx-5090-for-just-usd1-679-at-walmart-saving-usd1-520-card-has-worked-flawlessly-ever-since\", \"title\": \"Cheapest 5090 ever? Lucky PC builder finds RTX 5090 for 'just ...\", \"content\": \"Redditor Sufficient\\\\_Crazy7758 took to the platform to hail their purchase of the \\\"Cheapest 5090 ever?\\\", after scooping a PNY GeForce RTX 5090 from Walmart for the relatively low price of $1,679.99. The attached images reveal that the card was discounted by over $1,500 on May 25, having previously been discounted on May 13.\\n\\n\\\"Just so all of you know, I bought this on that date and it has worked flawlessly ever since,\\\" they said triumphantly. [...] In the ever-evolving world of insane GPU prices, tariffs, and frightful stock shortages, one intrepid PC builder has managed to swipe an Nvidia RTX 5090 from Walmart for \\\"just\\\" $1,679, more than $200 below MSRP. [...] even the [Founders Edition still retails for the same price](https://goto.walmart.com/c/1943169/565706/9383?subId1=tomshardware-us-9572975325724004555&sharedId=tomshardware-us&u=https%3A%2F%2Fwww.walmart.com%2Fip%2FNVIDIA-GeForce-RTX-5090-Graphic-Card-32GB-GDDR7%2F15176552726%3FclassType%3DREGULAR%26from%3D%2Fsearch), way over the $1,999 MSRP.\", \"score\": 0.6016175, \"raw_content\": null}], \"response_time\": 2.98}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response['messages'][4].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c12011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the price of 5090?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is the price of 5090?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": user_input},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea72b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from backend.src.agent.tools_and_schemas import SearchQueryList, Reflection\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import START, END\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from google.genai import Client\n",
    "\n",
    "from backend.src.agent.state import (\n",
    "    OverallState,\n",
    "    QueryGenerationState,\n",
    "    ReflectionState,\n",
    "    WebSearchState,\n",
    ")\n",
    "from backend.src.agent.configuration import Configuration\n",
    "from backend.src.agent.prompts import (\n",
    "    get_current_date,\n",
    "    query_writer_instructions,\n",
    "    web_searcher_instructions,\n",
    "    reflection_instructions,\n",
    "    answer_instructions,\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "from backend.src.agent.utils import (\n",
    "    get_citations,\n",
    "    get_research_topic,\n",
    "    insert_citation_markers,\n",
    "    resolve_urls,\n",
    ")\n",
    "from typing import TypedDict, List, Annotated, Literal, Dict, Union, Optional \n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_tavily import TavilySearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7ffec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your goal is to generate sophisticated and diverse web search queries. These queries are intended for an advanced automated web research tool capable of analyzing complex results, following links, and synthesizing information.\\n\\nInstructions: \\n- think what you need to know to answer the question first, your query can be incremental, the firsr query answer can be used to generate the second query.\\n- Always prefer a single search query, only add another query if the original question requests multiple aspects or elements and one query is not enough.\\n- Each query should focus on one specific aspect of the original question.\\n- Don\\'t produce more than {number_queries} queries.\\n- Queries should be diverse, if the topic is broad, generate more than 1 query.\\n- Don\\'t generate multiple similar queries, 1 is enough.\\n- Query should ensure that the most current information is gathered. The current date is {current_date}.\\n\\nFormat: \\n- Format your response as a JSON object with ALL three of these exact keys:\\n   - \"rationale\": Brief explanation of why these queries are relevant\\n   - \"query\": A list of search queries\\n   - \"plan\": Brief plan about steps about what yu want to know to answer the question\\n\\nExample:\\n\\nTopic: What revenue grew more last year apple stock or the number of people buying an iphone\\n```json\\n{{\\n    \"rationale\": \"To answer this comparative growth question accurately, we need specific data points on Apple\\'s stock performance and iPhone sales metrics. These queries target the precise financial information needed: company revenue trends, product-specific unit sales figures, and stock price movement over the same fiscal period for direct comparison.\",\\n    \"query\": [\"Apple total revenue growth fiscal year 2024\", \"iPhone unit sales growth fiscal year 2024\", \"Apple stock price growth fiscal year 2024\"],\\n    \"plan\": \"1, gather data on Apple\\'s stock market capitalization growth in 2024 to understand revenue growth from stock appreciation. 2, retrieve iPhone unit sales growth rates for the same period to compare with stock revenue growth. 3, Analyze both datasets to determine which metric experienced higher growth.\"\\n}}\\n```\\n\\nContext: {research_topic}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_writer_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997dcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_query(state: OverallState, config: RunnableConfig)->QueryGenerationState :\n",
    "    \"\"\"LangGraph node that generates a search queries based on the User's question.\n",
    "\n",
    "    Uses Gemini 2.0 Flash to create an optimized search query for web research based on\n",
    "    the User's question.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the User's question\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated query\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # check for custom initial search query count\n",
    "    if state.get(\"initial_search_query_count\") is None:\n",
    "        state[\"initial_search_query_count\"] = configurable.number_of_initial_queries\n",
    "\n",
    "    # init Gemini 2.0 Flash\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=configurable.query_generator_model,\n",
    "    #     temperature=1.0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(SearchQueryList)\n",
    "    print(get_research_topic(state[\"messages\"]),)\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = query_writer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        number_queries=state[\"initial_search_query_count\"],\n",
    "    )\n",
    "    # Generate the search queries\n",
    "    result = structured_llm.invoke(formatted_prompt)\n",
    "    # state['plan'] = result.plan\n",
    "    print(result)\n",
    "    return {\"plan\": result.plan, \"query_list\": result.query}\n",
    "\n",
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "# builder.add_conditional_edges(\n",
    "#     \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    "# )\n",
    "builder.add_edge(\"generate_query\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "254e9cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me\n",
      "query=['RTX 5090 GPU models comparison heat dissipation and price June 2025'] rationale='To recommend the best GPU based on heat dissipation and price, we need to gather current information on the latest RTX 5090 models from different brands, focusing on their cooling solutions and pricing. This will allow for a comparison of performance and value.' plan='1. Identify the latest RTX 5090 models available from different brands. 2. Compare their heat dissipation technologies and cooling solutions. 3. Analyze their current pricing to determine the best value for money. 4. Recommend the GPU that offers the best balance of cooling efficiency and affordability.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5895e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content='{\\n    \"rationale\": \"To recommend a GPU based on heat dissipation and price for the RTX 5090 models, two distinct data points are required: comprehensive thermal performance comparisons of various brands to evaluate cooling efficiency, and current market prices to assess value. These queries ensure coverage of technical reviews and real-time pricing for informed decision-making.\",\\n    \"query\": [\\n        \"RTX 5090 custom models thermal performance comparison 2025\",\\n        \"RTX 5090 prices by brand June 2025\"\\n    ]\\n}' additional_kwargs={'refusal': None, 'reasoning_content': 'We are given: current price of 5090 with different brand, and the user wants to buy a new GPU considering heat dissipation function and price.\\n The user is specifically mentioning the \"5090\", which likely refers to the NVIDIA RTX 5090, a high-end graphics card. However, note that as of June 18, 2025, the RTX 5090 may or may not have been released (since NVIDIA\\'s next-gen after RTX 40 series is expected around 2024-2025). We need to check the latest information.\\n\\n The user\\'s requirements:\\n   - Heat dissipation function (cooling performance)\\n   - Price\\n\\n We are to recommend one GPU (presumably among the RTX 5090 models from different brands) that balances these two factors.\\n\\n Steps:\\n 1. We need to gather current models of RTX 5090 from various brands (like ASUS, MSI, Gigabyte, Zotac, etc.) along with their cooling solutions and prices.\\n 2. We need to compare these models based on:\\n    - Cooling performance (which can be assessed through reviews that measure temperatures and noise levels under load)\\n    - Price (the user has provided a current price context, but we need up-to-date pricing and deals)\\n\\n However, note: the user says \"current price of 5090 with different brand\", meaning they are aware of the existence of different brands and their varying prices. They want a recommendation based on heat dissipation and price.\\n\\n Approach for queries:\\n Since we are to generate one or a few queries (max 5) and they should be specific and not redundant:\\n\\n Option 1: We can do one query that aims to get a comparison of RTX 5090 models from different brands, focusing on cooling and price.\\n\\n But note: the user might also be open to other GPUs? The question says \"I want to buy a new GPU\" and they are considering the 5090, but they might be open to other high-end models? However, the context specifically says \"current price of 5090 with different brand\", so it\\'s clear they are focusing on the RTX 5090.\\n\\n However, let\\'s stick to the context: they are considering the RTX 5090 from different brands.\\n\\n How about:\\n\\n Query 1: \"RTX 5090 models cooling performance comparison 2025\"\\n   - This would help in getting reviews that compare the thermal performance of different custom models.\\n\\n Query 2: \"RTX 5090 prices by brand June 2025\"\\n   - This would get the current prices.\\n\\n But wait: the user wants a recommendation. We are to generate queries that will help an automated tool to gather the necessary information to make that recommendation.\\n\\n However, note the instruction: \"think what you need to know to answer the question first\". We need to know:\\n   - The available RTX 5090 models and their cooling solutions (and how effective they are)\\n   - The current prices of these models\\n\\n But we can also look for a source that already does a comparison that includes both. So:\\n\\n Alternative: One query that covers both aspects? It might be hard to get one page that has both up-to-date prices and a detailed cooling comparison. Therefore, two queries might be necessary.\\n\\n However, let\\'s consider: the current date is June 18, 2025. We can also look for the latest reviews and then separately look for the latest prices.\\n\\n But note: the instruction says \"prefer a single search query\" unless the question requests multiple aspects. Here we have two aspects: heat dissipation and price. So two queries are acceptable.\\n\\n But also, we might get a review that includes both performance (including thermal) and the MSRP. However, actual prices in the market may vary and may be found on retailer sites. So:\\n\\n Query 1: For cooling performance: \"RTX 5090 thermal performance comparison 2025\"\\n   - This should return review roundups that test multiple models.\\n\\n Query 2: For current prices: \"RTX 5090 current prices June 2025\"\\n   - This should return the latest prices from retailers or price comparison sites.\\n\\n However, note that we are limited to 5 queries and we should only add if necessary. Two queries seem sufficient.\\n\\n But wait: the user might also be interested in the overall value (price to performance including cooling). We might need to combine the two. However, the tool can do that if we get the two sets of data.\\n\\n Also, note: the user might be open to other GPUs? The context says they are considering the 5090, but if we are to strictly follow, we are focusing on the 5090. However, the question does not explicitly rule out other models. But the context of \"current price of 5090 with different brand\" suggests that the user is comparing within the 5090 models.\\n\\n Therefore, we generate two queries:\\n\\n  1. To get the thermal performance data of various RTX 5090 models.\\n  2. To get the current prices of these models.\\n\\n But note: we might also need to know the brand and model names to cross-reference. The first query should return models by brand (like ASUS ROG Strix, MSI Suprim, etc.). The second query should also have the same models.\\n\\n However, we can also do one comprehensive query: \"RTX 5090 models comparison 2025: cooling and price\". But that might not be as effective.\\n\\n Considering the above, I propose two queries:\\n\\n   Query 1: \"RTX 5090 custom models thermal performance review roundup 2025\"\\n   Query 2: \"RTX 5090 prices by model June 2025\"\\n\\n But note: the tool is advanced and can follow links and synthesize. So with these two, it can gather the thermal data and the price data and then combine to recommend the model with the best cooling in a reasonable price range (or the best value for cooling).\\n\\n However, we might also consider: what if the user wants the best cooling regardless of price? Or the best value? The question says \"considering heat dissipation function and price\". So we need both.\\n\\n Therefore, two queries.\\n\\n But wait, the instruction says: \"Don\\'t generate multiple similar queries, 1 is enough.\" if one query can cover. However, these two are distinct. They are about two different aspects.\\n\\n However, let\\'s see if we can do with one:\\n\\n   Query: \"RTX 5090 models comparison 2025: cooling and current prices\"\\n\\n This might work? But it\\'s possible that a single page might not have both in-depth thermal analysis and the very latest prices (which change frequently). So two queries might be more effective.\\n\\n Considering the instructions, we are allowed to have more than one if the question has multiple aspects. This one does. So two queries.\\n\\n But note: we must not exceed 5. Two is safe.\\n\\n Rationale: We need to compare different brands of the RTX 5090 based on their cooling performance and current prices to recommend the best option that balances these two factors. The first query targets thermal performance reviews to evaluate cooling efficiency, while the second query gathers up-to-date pricing information for the same models.\\n\\n Therefore:\\n\\n   \"rationale\": \"To recommend an RTX 5090 model that balances heat dissipation and price, we need two distinct data points: comprehensive reviews comparing the cooling performance of various custom models, and current market prices for these models. These queries target the two critical factors independently to allow cross-referencing and value assessment.\",\\n   \"query\": [\\n        \"RTX 5090 custom models thermal performance review roundup 2025\",\\n        \"RTX 5090 current prices by model June 2025\"\\n   ]\\n\\n However, note: the user might also be interested in other factors? But the question specifically says \"Heat dissipation function and price\". So we focus on these.\\n\\n But wait: the user might also care about noise? Often, cooling performance is tied to noise. But the question says \"heat dissipation\", so we focus on thermal performance. However, if the reviews measure temperatures, that\\'s the key.\\n\\n Also, note: the model names must be consistent between the two queries. The first query should return model names (like ASUS ROG Strix, MSI Suprim X, etc.) and the second query should use the same naming.\\n\\n We are generating two queries. We are not generating more because two aspects are covered.\\n\\n Let\\'s write the JSON accordingly.'} response_metadata={'token_usage': {'completion_tokens': 1862, 'prompt_tokens': 398, 'total_tokens': 2260, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 1752, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 334}, 'model_name': 'deepseek-reasoner', 'system_fingerprint': 'fp_393bca965e_prod0425fp8', 'finish_reason': 'stop', 'logprobs': None} id='run--474f9824-8478-4634-966c-e979126eb49c-0' usage_metadata={'input_tokens': 398, 'output_tokens': 1862, 'total_tokens': 2260, 'input_token_details': {'cache_read': 64}, 'output_token_details': {'reasoning': 1752}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745ab583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='current price of 5090 with different brand,I want to buy a new gpu, and I am considering of Heat dissipation function and price, please recommend one to me', additional_kwargs={}, response_metadata={}, id='6056e78c-5d95-4b32-969c-2f90137c0996')],\n",
       " 'search_query': [],\n",
       " 'plan': '1. Retrieve the latest pricing and cooling solutions for the NVIDIA RTX 5090 across different brands. 2. Compare the heat dissipation efficiency and price to identify the best option. 3. Recommend the GPU with the optimal balance of cooling performance and affordability.',\n",
       " 'web_research_result': [],\n",
       " 'sources_gathered': [],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3125633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_to_web_research(state: QueryGenerationState):\n",
    "    \"\"\"LangGraph node that sends the search queries to the web research node.\n",
    "\n",
    "    This is used to spawn n number of web research nodes, one for each search query.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        Send(\"web_research\", {\"search_query\": search_query, \"id\": int(idx)})\n",
    "        for idx, search_query in enumerate(state[\"query_list\"])\n",
    "    ]\n",
    "\n",
    "\n",
    "# def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
    "#     \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
    "\n",
    "#     Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
    "\n",
    "#     Args:\n",
    "#         state: Current graph state containing the search query and research loop count\n",
    "#         config: Configura\"tion for the runnable, including search API settings\n",
    "\n",
    "#     Returns:\n",
    "#         Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "#     \"\"\"\n",
    "#     # Configure\n",
    "#     configurable = Configuration.from_runnable_config(config)\n",
    "#     formatted_prompt = web_searcher_instructions.format(\n",
    "#         current_date=get_current_date(),\n",
    "#         research_topic=state[\"search_query\"],\n",
    "#     )\n",
    "#     llm = ChatDeepSeek(\n",
    "#     model=\"deepseek-chat\",\n",
    "#     temperature=1,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     )\n",
    "\n",
    "#     # Create the agent with the formatted prompt as system message\n",
    "#     # agent = create_react_agent(\n",
    "#     #     llm,\n",
    "#     #     [tavily_search_tool],\n",
    "#     #     prompt=formatted_prompt\n",
    "#     # )\n",
    "#     # Uses the google genai client as the langchain client doesn't return grounding metadata\n",
    "#     genai_client = Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "#     response = genai_client.models.generate_content(\n",
    "#         model=configurable.query_generator_model,\n",
    "#         contents=formatted_prompt,\n",
    "#         config={\n",
    "#             \"tools\": [{\"google_search\": {}}],\n",
    "#             \"temperature\": 0,\n",
    "#         },\n",
    "#     )\n",
    "#     print('search results:')\n",
    "\n",
    "#     print(response)\n",
    "    \n",
    "#     # resolve the urls to short urls for saving tokens and time\n",
    "#     resolved_urls = resolve_urls(\n",
    "#         response.candidates[0].grounding_metadata.grounding_chunks, state[\"id\"]\n",
    "#     )\n",
    "#     # Gets the citations and adds them to the generated text\n",
    "#     citations = get_citations(response, resolved_urls)\n",
    "#     modified_text = insert_citation_markers(response.text, citations)\n",
    "#     sources_gathered = [item for citation in citations for item in citation[\"segments\"]]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     return {\n",
    "#         \"sources_gathered\": sources_gathered,\n",
    "#         \"search_query\": [state[\"search_query\"]],\n",
    "#         \"web_research_result\": [modified_text],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958f97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Citation(BaseModel):\n",
    "    label: str = Field(\n",
    "        ...,\n",
    "        description=\"The name of the website.\",\n",
    "    )\n",
    "    source_id: str = Field(\n",
    "        ...,\n",
    "        description=\"The url of a SPECIFIC source which justifies the answer.\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        ...,\n",
    "        description=\"The VERBATIM quote from the specified source that justifies the answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and return all the sources used.\"\"\"\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources. Include any relevant sources in the answer as markdown hyperlinks. For example: 'This is a sample text ([url website](url))'\"\n",
    "    )\n",
    "    citations: List[Citation] = Field(\n",
    "        ..., description=\"Citations from the given sources that justify the answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:\n",
    "    \"\"\"LangGraph node that performs web research using the native Google Search API tool.\n",
    "\n",
    "    Executes a web search using the native Google Search API tool in combination with Gemini 2.0 Flash.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configura\"tion for the runnable, including search API settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    # Configure\n",
    "    load_dotenv()\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize Tavily Search Tool\n",
    "    tavily_search_tool = TavilySearch(\n",
    "        max_results=5,\n",
    "        topic=\"general\",\n",
    "    )\n",
    "    structured_llm = llm.bind_tools([tavily_search_tool]).with_structured_output(QuotedAnswer)\n",
    "    # agent = create_react_agent(llm, [tavily_search_tool])\n",
    "\n",
    "    # user_input = \"What nation hosted the Euro 2024?\"\n",
    "    user_input = state[\"search_query\"]\n",
    "    # formatted_prompt = web_searcher_instructions.format(\n",
    "    #     current_date=get_current_date(),\n",
    "    #     research_topic='price of 5090',\n",
    "    # )\n",
    "\n",
    "    web_searcher_instructions = \"\"\"Use your search tool to conduct targeted Searches to gather the most recent, credible information on \"{research_topic}\" and synthesize it into a verifiable text artifact.\n",
    "\n",
    "    Instructions:\n",
    "    - Query should ensure that the most current information is gathered. The current date is {current_date}.\n",
    "    - Conduct multiple, diverse searches to gather comprehensive information.\n",
    "    - Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.\n",
    "    - The output should be a well-written summary or report based on your search findings. \n",
    "    - Only include the information found in the search results, don't make up any information.\n",
    "\n",
    "    Research Topic:\n",
    "    {research_topic}\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_prompt = web_searcher_instructions.format(\n",
    "        current_date=get_current_date(),\n",
    "        research_topic=user_input,\n",
    "    ) + \"\\n\\nIMPORTANT: Use the search tool provided to find the most up-to-date information, and choose the right arguments for the search tool.\"\n",
    "\n",
    "\n",
    "    # for step in agent.stream(\n",
    "    #     {\"messages\": user_input},\n",
    "    #     stream_mode=\"values\",\n",
    "    # ):\n",
    "    #     step[\"messages\"][-1].pretty_print()\n",
    "    result = structured_llm.invoke(formatted_prompt)\n",
    "    web_research_result = result.answer + \"\\n---\\n\\n\".join([citation.source_id for citation in result.citations])\n",
    "    citations_list =[]\n",
    "    for citation in result.citations:\n",
    "        citations_dict = {}\n",
    "        citations_dict['label'] = citation.label\n",
    "        citations_dict['short_url'] = citation.source_id\n",
    "        citations_dict['value'] = citation.quote\n",
    "        citations_list.append(citations_dict)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"sources_gathered\": citations_list,\n",
    "        \"search_query\": [state[\"search_query\"]],\n",
    "        \"web_research_result\": [web_research_result],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3888798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "builder.add_edge(\"web_research\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed0c4611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\n",
      "query=['NVIDIA RTX 5090 price comparison June 2025', 'NVIDIA RTX 5090 heat dissipation performance reviews June 2025'] rationale='To recommend the best GPU based on price and heat dissipation, we need current pricing data for the NVIDIA RTX 5090 across different brands and reviews evaluating its heat dissipation performance. These queries will provide the necessary information to compare options.' plan='1. Retrieve the latest pricing for the NVIDIA RTX 5090 from different brands to identify cost-effective options. 2. Gather reviews or benchmarks on heat dissipation performance to ensure the GPU meets cooling requirements. 3. Synthesize the data to recommend the best option balancing price and heat dissipation.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "408ee220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me', additional_kwargs={}, response_metadata={}, id='2ea6b91f-93c8-43e4-a46f-b3b407c59c7b')],\n",
       " 'search_query': ['NVIDIA RTX 5090 price comparison June 2025',\n",
       "  'NVIDIA RTX 5090 heat dissipation performance reviews June 2025'],\n",
       " 'plan': '1. Retrieve the latest pricing for the NVIDIA RTX 5090 from different brands to identify cost-effective options. 2. Gather reviews or benchmarks on heat dissipation performance to ensure the GPU meets cooling requirements. 3. Synthesize the data to recommend the best option balancing price and heat dissipation.',\n",
       " 'web_research_result': ['As of June 2025, the NVIDIA RTX 5090 is priced at approximately $1,999 USD for the Founders Edition, with third-party variants ranging from $2,099 to $2,499 depending on the manufacturer and additional features like overclocking or enhanced cooling solutions. Retailers such as Amazon, Newegg, and Best Buy are offering competitive pricing, with occasional discounts or bundle deals. For example, Newegg currently lists the ASUS ROG Strix RTX 5090 at $2,299 with a free game bundle ([Newegg](https://www.newegg.com)).https://www.newegg.com',\n",
       "  'The NVIDIA RTX 5090 heat dissipation performance reviews for June 2025 are not yet available in the sources I have access to. Please check back later or provide specific sources for me to analyze.'],\n",
       " 'sources_gathered': [{'label': 'Newegg',\n",
       "   'short_url': 'https://www.newegg.com',\n",
       "   'value': 'ASUS ROG Strix RTX 5090 priced at $2,299 with a free game bundle.'}],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea88855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:\n",
    "    \"\"\"LangGraph node that identifies knowledge gaps and generates potential follow-up queries.\n",
    "\n",
    "    Analyzes the current summary to identify areas for further research and generates\n",
    "    potential follow-up queries. Uses structured output to extract\n",
    "    the follow-up query in JSON format.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated follow-up query\n",
    "    \"\"\"\n",
    "    # configurable = Configuration.from_runnable_config(config)\n",
    "    # Increment the research loop count and get the reasoning model\n",
    "    state[\"research_loop_count\"] = state.get(\"research_loop_count\", 0) + 1\n",
    "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
    "\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = reflection_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        summaries=\"\\n\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
    "        plan=state[\"plan\"],\n",
    "    )\n",
    "    # init Reasoning Model\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=reasoning_model,\n",
    "    #     temperature=1.0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    result = llm.with_structured_output(Reflection).invoke(formatted_prompt)\n",
    "\n",
    "    return {\n",
    "        \"is_sufficient\": result.is_sufficient,\n",
    "        \"knowledge_gap\": result.knowledge_gap,\n",
    "        \"follow_up_queries\": result.follow_up_queries,\n",
    "        \"research_loop_count\": state[\"research_loop_count\"],\n",
    "        \"number_of_ran_queries\": len(state[\"search_query\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_research(\n",
    "    state: ReflectionState,\n",
    "    config: RunnableConfig,\n",
    ") -> OverallState:\n",
    "    \"\"\"LangGraph routing function that determines the next step in the research flow.\n",
    "\n",
    "    Controls the research loop by deciding whether to continue gathering information\n",
    "    or to finalize the summary based on the configured maximum number of research loops.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the research loop count\n",
    "        config: Configuration for the runnable, including max_research_loops setting\n",
    "\n",
    "    Returns:\n",
    "        String literal indicating the next node to visit (\"web_research\" or \"finalize_summary\")\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    max_research_loops = (\n",
    "        state.get(\"max_research_loops\")\n",
    "        if state.get(\"max_research_loops\") is not None\n",
    "        else configurable.max_research_loops\n",
    "    )\n",
    "    if state[\"is_sufficient\"] or state[\"research_loop_count\"] >= max_research_loops:\n",
    "        return \"finalize_answer\"\n",
    "    else:\n",
    "        return [\n",
    "            Send(\n",
    "                \"web_research\",\n",
    "                {\n",
    "                    \"search_query\": follow_up_query,\n",
    "                    \"id\": state[\"number_of_ran_queries\"] + int(idx),\n",
    "                },\n",
    "            )\n",
    "            for idx, follow_up_query in enumerate(state[\"follow_up_queries\"])\n",
    "        ]\n",
    "\n",
    "\n",
    "def finalize_answer(state: OverallState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that finalizes the research summary.\n",
    "\n",
    "    Prepares the final output by deduplicating and formatting sources, then\n",
    "    combining them with the running summary to create a well-structured\n",
    "    research report with proper citations.\n",
    "\n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and sources gathered\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the formatted final summary with sources\n",
    "    \"\"\"\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    # reasoning_model = state.get(\"reasoning_model\") or configurable.reasoning_model\n",
    "\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = answer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=get_research_topic(state[\"messages\"]),\n",
    "        summaries=\"\\n---\\n\\n\".join(state[\"web_research_result\"]),\n",
    "    )\n",
    "\n",
    "    # init Reasoning Model, default to Gemini 2.5 Flash\n",
    "    # llm = ChatGoogleGenerativeAI(\n",
    "    #     model=reasoning_model,\n",
    "    #     temperature=0,\n",
    "    #     max_retries=2,\n",
    "    #     api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    # )\n",
    "    llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "    result = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # Replace the short urls with the original urls and add all used urls to the sources_gathered\n",
    "    unique_sources = []\n",
    "    for source in state[\"sources_gathered\"]:\n",
    "        if source[\"short_url\"] in result.content:\n",
    "            result.content = result.content.replace(\n",
    "                source[\"short_url\"], source[\"value\"]\n",
    "            )\n",
    "            unique_sources.append(source)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=result.content)],\n",
    "        \"sources_gathered\": unique_sources,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create our Agent Graph\n",
    "builder = StateGraph(OverallState, config_schema=Configuration)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_node(\"reflection\", reflection)\n",
    "builder.add_node(\"finalize_answer\", finalize_answer)\n",
    "\n",
    "# Set the entrypoint as `generate_query`\n",
    "# This means that this node is the first one called\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "# Add conditional edge to continue with search queries in a parallel branch\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "# Reflect on the web research\n",
    "builder.add_edge(\"web_research\", \"reflection\")\n",
    "# Evaluate the research\n",
    "builder.add_conditional_edges(\n",
    "    \"reflection\", evaluate_research, [\"web_research\", \"finalize_answer\"]\n",
    ")\n",
    "# Finalize the answer\n",
    "builder.add_edge(\"finalize_answer\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c7d18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current price of 5090 with different brand,I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\n",
      "query=['RTX 5090 GPU models price comparison June 2025', 'RTX 5090 GPU thermal performance and cooling solutions June 2025'] rationale='To recommend the best GPU based on heat dissipation and price, we need to gather current pricing and thermal performance data for the RTX 5090 models from different brands. This will allow for a comparison of cost-effectiveness and cooling efficiency.' plan='1. Retrieve the latest pricing information for RTX 5090 GPUs from various brands to identify cost-effective options. 2. Gather data on thermal performance and cooling solutions for these models to evaluate heat dissipation efficiency. 3. Compare the collected data to recommend the best GPU based on the balance between price and cooling performance.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"current price of 5090 with different brand,\\\n",
    "I want to buy a new gpu, and I am considering Heat dissipation function and price, please recommend one to me\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f00d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is PD-1/PD-L1 a response predictor for early breast cancer patients undergoing neoadjuvant chemotherapy?\n",
      "query=['PD-1/PD-L1 as response predictor neoadjuvant chemotherapy early breast cancer 2024-2025'] rationale='To determine if PD-1/PD-L1 is a response predictor for early breast cancer patients undergoing neoadjuvant chemotherapy, we need to gather recent clinical studies, meta-analyses, or expert reviews that specifically address the role of PD-1/PD-L1 in predicting treatment response in this context. The query focuses on the most current research to ensure relevance and accuracy.' plan='1. Search for recent clinical studies or meta-analyses on the role of PD-1/PD-L1 in predicting treatment response for early breast cancer patients undergoing neoadjuvant chemotherapy. 2. Analyze the findings to determine the predictive value of PD-1/PD-L1 in this specific patient population.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Is PD-1/PD-L1 a response predictor for early breast cancer patients undergoing neoadjuvant chemotherapy?\"}], \"max_research_loops\": 5, \"initial_search_query_count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e1b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Is PD-1/PD-L1 a response predictor for early breast cancer patients undergoing neoadjuvant chemotherapy?', additional_kwargs={}, response_metadata={}, id='cec265fa-61c0-4c71-ba9f-b3dbc5198d58'),\n",
       "  AIMessage(content='Based on the provided summaries, the predictive value of PD-1/PD-L1 as a response marker for early breast cancer patients undergoing neoadjuvant chemotherapy remains inconclusive, with mixed evidence across studies.  \\n\\n1. **Positive Association in TNBC**: Some studies suggest that higher PD-L1 expression correlates with improved pathological complete response (pCR) rates, particularly in triple-negative breast cancer (TNBC) subtypes. This aligns with findings that immune checkpoint markers may play a role in treatment sensitivity in immunogenic tumors like TNBC ([ASCO](Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.)).  \\n\\n2. **Conflicting or Null Findings**: However, other research reports no significant association between PD-1/PD-L1 and pCR, or inconsistent results across breast cancer subtypes. This variability underscores the complexity of using PD-1/PD-L1 as a standalone predictor ([Nature Reviews Clinical Oncology](Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.)).  \\n\\n**Conclusion**: While PD-1/PD-L1 shows promise as a potential biomarker, especially in TNBC, its predictive utility is not yet definitive. Further validation in larger, standardized studies is needed to clarify its role in guiding neoadjuvant therapy decisions.  \\n\\n**Citations**:  \\n- [ASCO](Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.)  \\n- [Nature Reviews Clinical Oncology](Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.)', additional_kwargs={}, response_metadata={}, id='41b5e564-dd80-4af6-87eb-fd27560cab9b')],\n",
       " 'search_query': ['PD-1/PD-L1 as response predictor neoadjuvant chemotherapy early breast cancer 2024-2025',\n",
       "  'What are the findings of recent clinical studies or meta-analyses on the predictive value of PD-1/PD-L1 for treatment response in early breast cancer patients undergoing neoadjuvant chemotherapy?'],\n",
       " 'plan': '1. Search for recent clinical studies or meta-analyses on the role of PD-1/PD-L1 in predicting treatment response for early breast cancer patients undergoing neoadjuvant chemotherapy. 2. Analyze the findings to determine the predictive value of PD-1/PD-L1 in this specific patient population.',\n",
       " 'web_research_result': ['The search tool is not currently available for real-time searches. However, I can guide you on how to conduct this research manually or provide general information based on existing knowledge up to my last update. Would you like assistance with formulating search queries or understanding the topic?',\n",
       "  'Recent clinical studies and meta-analyses on the predictive value of PD-1/PD-L1 for treatment response in early breast cancer patients undergoing neoadjuvant chemotherapy suggest mixed findings. Some studies indicate that higher PD-L1 expression correlates with improved pathological complete response (pCR) rates, particularly in triple-negative breast cancer (TNBC) subtypes. However, other studies report no significant association or conflicting results, highlighting the need for further research.https://ascopubs.org/doi/10.1200/JCO.2025.12345\\n---\\n\\nhttps://www.nature.com/articles/nrclinonc.2025.67890'],\n",
       " 'sources_gathered': [{'label': 'Journal of Clinical Oncology',\n",
       "   'short_url': 'https://ascopubs.org/doi/10.1200/JCO.2025.12345',\n",
       "   'value': 'Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.'},\n",
       "  {'label': 'Nature Reviews Clinical Oncology',\n",
       "   'short_url': 'https://www.nature.com/articles/nrclinonc.2025.67890',\n",
       "   'value': 'Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.'},\n",
       "  {'label': 'Journal of Clinical Oncology',\n",
       "   'short_url': 'https://ascopubs.org/doi/10.1200/JCO.2025.12345',\n",
       "   'value': 'Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.'},\n",
       "  {'label': 'Nature Reviews Clinical Oncology',\n",
       "   'short_url': 'https://www.nature.com/articles/nrclinonc.2025.67890',\n",
       "   'value': 'Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.'}],\n",
       " 'initial_search_query_count': 5,\n",
       " 'max_research_loops': 5,\n",
       " 'research_loop_count': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035cdd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided summaries, the predictive value of PD-1/PD-L1 as a response marker for early breast cancer patients undergoing neoadjuvant chemotherapy remains inconclusive, with mixed evidence across studies.  \n",
       "\n",
       "1. **Positive Association in TNBC**: Some studies suggest that higher PD-L1 expression correlates with improved pathological complete response (pCR) rates, particularly in triple-negative breast cancer (TNBC) subtypes. This aligns with findings that immune checkpoint markers may play a role in treatment sensitivity in immunogenic tumors like TNBC ([ASCO](Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.)).  \n",
       "\n",
       "2. **Conflicting or Null Findings**: However, other research reports no significant association between PD-1/PD-L1 and pCR, or inconsistent results across breast cancer subtypes. This variability underscores the complexity of using PD-1/PD-L1 as a standalone predictor ([Nature Reviews Clinical Oncology](Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.)).  \n",
       "\n",
       "**Conclusion**: While PD-1/PD-L1 shows promise as a potential biomarker, especially in TNBC, its predictive utility is not yet definitive. Further validation in larger, standardized studies is needed to clarify its role in guiding neoadjuvant therapy decisions.  \n",
       "\n",
       "**Citations**:  \n",
       "- [ASCO](Higher PD-L1 expression was associated with improved pCR rates in TNBC patients (p < 0.05), but no significant correlation was observed in hormone receptor-positive subtypes.)  \n",
       "- [Nature Reviews Clinical Oncology](Meta-analyses reveal inconsistent findings regarding PD-1/PD-L1 as a predictive biomarker, underscoring the heterogeneity of breast cancer and the complexity of immune checkpoint interactions.)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state['messages'][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0a34829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here’s a comprehensive answer to your question about the current pricing of the RTX 5090 across different brands and regions as of June 2025:\n",
       "\n",
       "### **RTX 5090 Pricing by Brand (June 2025)**  \n",
       "1. **NVIDIA Founders Edition**: $1,599 ([TechRadar](The base model is priced at $1,599.))  \n",
       "2. **ASUS ROG Strix**: $1,699 ([Tom's Hardware](The ASUS variant is listed at $1,699.))  \n",
       "3. **MSI Gaming X Trio**: $1,649 ([PC Gamer](MSI's offering is priced at $1,649.))  \n",
       "4. **Gigabyte AORUS**: $1,679 ([AnandTech](The Gigabyte model is available for $1,679.))  \n",
       "\n",
       "### **Regional Pricing and Promotions**  \n",
       "- **North America**:  \n",
       "  - Founders Edition: $1,999  \n",
       "  - ASUS/MSI models: $2,099–$2,299  \n",
       "  - Newegg promotion: $100 discount on select models ([Newegg](Newegg is currently running a promotion with a $100 discount on select models.)).  \n",
       "\n",
       "- **Europe**:  \n",
       "  - Germany: Founders Edition at €2,199; MSI models with €150 discount ([Amazon Germany](Amazon Germany is offering a limited-time €150 discount on MSI models.)).  \n",
       "  - France: Founders Edition at €2,249.  \n",
       "\n",
       "- **Asia**:  \n",
       "  - Japan: Founders Edition at ¥320,000; discounts up to ¥20,000 at Bic Camera ([Bic Camera](In Japan, the RTX 5090 is priced at ¥320,000 for the Founders Edition, with discounts of up to ¥20,000 on select models at Bic Camera.)).  \n",
       "  - China: ¥14,999 with a ¥500 discount on JD.com ([JD.com](In China, the card is priced at ¥14,999, with JD.com offering a ¥500 discount for a limited time.)).  \n",
       "\n",
       "- **Australia**:  \n",
       "  - Founders Edition: AUD 3,299 with free game bundle at Scorptec ([Scorptec](Retailers like Scorptec offering a free game bundle with purchase.)).  \n",
       "\n",
       "### **Performance Comparison**  \n",
       "- **ASUS ROG Strix**: Highest performance (5–10% over Founders Edition) with triple-fan cooling ([Tom's Hardware](The ASUS variant is listed at $1,699.)).  \n",
       "- **MSI Gaming X Trio**: Quiet operation, slightly outperforms Founders Edition ([Guru3D](It offers competitive performance, slightly edging out the Founders Edition in synthetic benchmarks but trailing the ROG Strix in gaming performance.)).  \n",
       "- **Gigabyte AORUS**: Matches ASUS in clock speeds but louder under load ([AnandTech](The Gigabyte model is available for $1,679.)).  \n",
       "\n",
       "Prices and promotions are subject to change. For the latest updates, check retailer links or official brand pages.  \n",
       "\n",
       "**Citations**:  \n",
       "[TechRadar](The base model is priced at $1,599.), [Tom's Hardware](The ASUS variant is listed at $1,699.), [PC Gamer](MSI's offering is priced at $1,649.), [AnandTech](The Gigabyte model is available for $1,679.), [Newegg](Newegg is currently running a promotion with a $100 discount on select models.), [Amazon Germany](Amazon Germany is offering a limited-time €150 discount on MSI models.), [Bic Camera](In Japan, the RTX 5090 is priced at ¥320,000 for the Founders Edition, with discounts of up to ¥20,000 on select models at Bic Camera.), [JD.com](In China, the card is priced at ¥14,999, with JD.com offering a ¥500 discount for a limited time.), [Scorptec](Retailers like Scorptec offering a free game bundle with purchase.), [Guru3D](It offers competitive performance, slightly edging out the Founders Edition in synthetic benchmarks but trailing the ROG Strix in gaming performance.)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(state['messages'][1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef21ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, config_schema=Configuration)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate_query\", continue_to_web_research, [\"web_research\"]\n",
    ")\n",
    "\n",
    "builder.add_edge(\"finalize_answer\", END)\n",
    "\n",
    "graph = builder.compile(name=\"pro-search-agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1fc64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'ModelMetaclass' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m web_searcher_instructions\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     16\u001b[0m     current_date\u001b[38;5;241m=\u001b[39mget_current_date(),\n\u001b[1;32m     17\u001b[0m     research_topic\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice of 5090\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39mformatted_prompt)]\n\u001b[0;32m---> 21\u001b[0m query_generation_response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     22\u001b[0m     messages,\n\u001b[1;32m     23\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[LLMGeneratedSearchQueries]\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m generated_queries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_generation_response\u001b[38;5;241m.\u001b[39mtool_calls:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    777\u001b[0m                 m,\n\u001b[1;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    781\u001b[0m             )\n\u001b[1;32m    782\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:891\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    888\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    889\u001b[0m     )\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate_from_stream(stream_iter)\n\u001b[0;32m--> 891\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    892\u001b[0m generation_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:946\u001b[0m, in \u001b[0;36mBaseChatOpenAI._get_request_payload\u001b[0;34m(self, input_, stop, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m    945\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_responses_api(payload):\n\u001b[1;32m    947\u001b[0m     payload \u001b[38;5;241m=\u001b[39m _construct_responses_api_payload(messages, payload)\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:932\u001b[0m, in \u001b[0;36mBaseChatOpenAI._use_responses_api\u001b[0;34m(self, payload)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_responses_api\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _use_responses_api(payload)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2866\u001b[0m, in \u001b[0;36m_use_responses_api\u001b[0;34m(payload)\u001b[0m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_responses_api\u001b[39m(payload: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m-> 2866\u001b[0m     uses_builtin_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   2867\u001b[0m         _is_builtin_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2868\u001b[0m     )\n\u001b[1;32m   2869\u001b[0m     responses_only_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(uses_builtin_tools \u001b[38;5;129;01mor\u001b[39;00m responses_only_args\u001b[38;5;241m.\u001b[39mintersection(payload))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2867\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_use_responses_api\u001b[39m(payload: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2866\u001b[0m     uses_builtin_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m-> 2867\u001b[0m         _is_builtin_tool(tool) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2868\u001b[0m     )\n\u001b[1;32m   2869\u001b[0m     responses_only_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_response_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(uses_builtin_tools \u001b[38;5;129;01mor\u001b[39;00m responses_only_args\u001b[38;5;241m.\u001b[39mintersection(payload))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:2862\u001b[0m, in \u001b[0;36m_is_builtin_tool\u001b[0;34m(tool)\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_builtin_tool\u001b[39m(tool: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tool \u001b[38;5;129;01mand\u001b[39;00m tool[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'ModelMetaclass' is not iterable"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "class LLMGeneratedSearchQueries(BaseModel):\n",
    "    \"\"\"Schema for the LLM to generate a list of search queries.\"\"\"\n",
    "    search_queries: list[str] = Field(description=\"A list of search queries to find relevant information based on the research topic.\")\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "\n",
    "messages = [HumanMessage(content=formatted_prompt)]\n",
    "\n",
    "query_generation_response = llm.invoke(\n",
    "    messages,\n",
    "    tools=[LLMGeneratedSearchQueries]\n",
    ")\n",
    "\n",
    "generated_queries = []\n",
    "if query_generation_response.tool_calls:\n",
    "    for tool_call in query_generation_response.tool_calls:\n",
    "        if tool_call['name'] == LLMGeneratedSearchQueries.__name__:\n",
    "            generated_queries.extend(tool_call['args'].get('search_queries', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34382436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
